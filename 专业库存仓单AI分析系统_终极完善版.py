"""
ä¸“ä¸šåº“å­˜ä»“å•AIåˆ†æç³»ç»Ÿ - ç»ˆæå®Œå–„ç‰ˆ
===========================================

ç»ˆæå®Œå–„äº®ç‚¹ï¼š
1. âœ… å…ƒæ•°æ®ä¿¡æ¯å®Œå…¨åç½®ï¼Œå¼€å¤´ç›´æ¥åˆ†æå†…å®¹
2. âœ… ä¸¥ç¦ä»»ä½•è‹±æ–‡ï¼Œçº¯ä¸­æ–‡ä¸“ä¸šè¡¨è¾¾
3. âœ… ä¸“ä¸šå›¾è¡¨ç”ŸæˆåŠŸèƒ½ï¼ˆåº“å­˜è¶‹åŠ¿+ä»·æ ¼å¯¹æ¯”+åèº«æ€§åˆ†æï¼‰
4. âœ… å®Œå…¨å…¼å®¹Streamlitç³»ç»Ÿè°ƒç”¨
5. âœ… å¤šç»´åº¦æ•°æ®æ•´åˆï¼ˆåº“å­˜+ä»·æ ¼+åŸºå·®+æœŸé™ç»“æ„+æŒä»“ï¼‰
6. âœ… åº“å­˜åèº«æ€§å…³ç³»æ·±åº¦è§£è¯»

æ ¸å¿ƒç‰¹æ€§ï¼š
â€¢ ğŸ¤– DeepSeek V3.1 + Reasoneræ¨ç†æ¨¡å¼
â€¢ ğŸŒ å¼ºåŒ–è”ç½‘æ•°æ®è·å–ï¼Œç¡®ä¿æ—¶æ•ˆæ€§
â€¢ ğŸ“Š äº”ç»´æ•°æ®æ•´åˆ + ä¸“ä¸šå›¾è¡¨ç”Ÿæˆ
â€¢ ğŸ’¡ åº“å­˜åèº«æ€§å…³ç³»æ·±åº¦è§£è¯»
â€¢ ğŸ¯ çº¯ä¸­æ–‡ä¸“ä¸šæŠ•èµ„ç­–ç•¥åˆ¶å®š
â€¢ âš¡ å¤šç»´åº¦äº¤å‰éªŒè¯åˆ†æ

ç‰ˆæœ¬ï¼šv8.0 Ultimate Perfection
ä½œè€…ï¼šAI Trading Assistant
æ›´æ–°ï¼š2025-09-21
"""

import pandas as pd
import numpy as np
import requests
import json
from pathlib import Path
from datetime import datetime, timedelta
from scipy import stats
import warnings
import time
import os
import akshare as ak
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
from matplotlib.font_manager import FontProperties
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'WenQuanYi Micro Hei']
plt.rcParams['axes.unicode_minus'] = False


class UltimatePerfectedInventoryAnalyzer:
    """ä¸“ä¸šåº“å­˜ä»“å•AIåˆ†æç³»ç»Ÿ - ç»ˆæå®Œå–„ç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        # APIé…ç½®
        self.deepseek_api_key = "sk-293dec7fabb54606b4f8d4f606da3383"
        self.serper_api_key = "d3654e36956e0bf331e901886c49c602cea72eb1"
        
        # æ•°æ®è·¯å¾„é…ç½®
        self.base_path = Path(r"D:\Cursor\cursoré¡¹ç›®\TradingAgent\qihuo\database")
        self.inventory_dir = self.base_path / "inventory"
        self.receipt_dir = self.base_path / "receipt" 
        self.technical_dir = self.base_path / "technical_analysis"
        self.term_structure_dir = self.base_path / "term_structure"
        self.basis_dir = self.base_path / "basis"
        self.positioning_dir = self.base_path / "positioning"
        
        # API URL
        self.deepseek_base_url = "https://api.deepseek.com/v1/chat/completions"
        self.serper_base_url = "https://google.serper.dev/search"
        
        # å“ç§æ˜ å°„å’Œç‰¹æ€§
        self.variety_mapping = {
            'èšæ°¯ä¹™çƒ¯': {'code': 'V', 'category': 'åŒ–å·¥', 'unit': 'ä¸‡å¨', 'exchange': 'DCE', 'ak_name': 'PVC', 'chinese_name': 'èšæ°¯ä¹™çƒ¯'},
            'ç™½é“¶': {'code': 'AG', 'category': 'è´µé‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'æ²ªé“¶'},
            'é»„é‡‘': {'code': 'AU', 'category': 'è´µé‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'æ²ªé‡‘'},
            'é“œ': {'code': 'CU', 'category': 'æœ‰è‰²é‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'æ²ªé“œ'},
            'é“': {'code': 'AL', 'category': 'æœ‰è‰²é‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'æ²ªé“'},
            'é”Œ': {'code': 'ZN', 'category': 'æœ‰è‰²é‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'æ²ªé”Œ'},
            'é“…': {'code': 'PB', 'category': 'æœ‰è‰²é‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'æ²ªé“…'},
            'é•': {'code': 'NI', 'category': 'æœ‰è‰²é‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'æ²ªé•'},
            'é”¡': {'code': 'SN', 'category': 'æœ‰è‰²é‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'æ²ªé”¡'},
            'èºçº¹é’¢': {'code': 'RB', 'category': 'é»‘è‰²é‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'èºçº¹é’¢'},
            'é“çŸ¿çŸ³': {'code': 'I', 'category': 'é»‘è‰²é‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'DCE', 'ak_name': 'é“çŸ¿çŸ³'},
            'çƒ­è½§å·æ¿': {'code': 'HC', 'category': 'é»‘è‰²é‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'çƒ­å·'},
            'ç„¦ç‚­': {'code': 'J', 'category': 'é»‘è‰²é‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'DCE', 'ak_name': 'ç„¦ç‚­'},
            'ç„¦ç…¤': {'code': 'JM', 'category': 'é»‘è‰²é‡‘å±', 'unit': 'ä¸‡å¨', 'exchange': 'DCE', 'ak_name': 'ç„¦ç…¤'},
            'çŸ³æ²¹æ²¥é’': {'code': 'BU', 'category': 'èƒ½æºåŒ–å·¥', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'æ²¥é’'},
            'ç‡ƒæ–™æ²¹': {'code': 'FU', 'category': 'èƒ½æºåŒ–å·¥', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'ç‡ƒæ²¹'},
            'å¤©ç„¶æ©¡èƒ¶': {'code': 'RU', 'category': 'å†œäº§å“', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'æ©¡èƒ¶'},
            'çº¸æµ†': {'code': 'SP', 'category': 'å†œäº§å“', 'unit': 'ä¸‡å¨', 'exchange': 'SHFE', 'ak_name': 'çº¸æµ†'},
            'æ£‰èŠ±': {'code': 'CF', 'category': 'å†œäº§å“', 'unit': 'ä¸‡å¨', 'exchange': 'CZCE', 'ak_name': 'æ£‰èŠ±'},
            'ç™½ç³–': {'code': 'SR', 'category': 'å†œäº§å“', 'unit': 'ä¸‡å¨', 'exchange': 'CZCE', 'ak_name': 'ç™½ç³–'},
            'ç»ç’ƒ': {'code': 'FG', 'category': 'å»ºæ', 'unit': 'ä¸‡å¨', 'exchange': 'CZCE', 'ak_name': 'ç»ç’ƒ'},
            'çº¯ç¢±': {'code': 'SA', 'category': 'åŒ–å·¥', 'unit': 'ä¸‡å¨', 'exchange': 'CZCE', 'ak_name': 'çº¯ç¢±'},
            'å¡‘æ–™': {'code': 'L', 'category': 'åŒ–å·¥', 'unit': 'ä¸‡å¨', 'exchange': 'DCE', 'ak_name': 'å¡‘æ–™'},
            'èšä¸™çƒ¯': {'code': 'PP', 'category': 'åŒ–å·¥', 'unit': 'ä¸‡å¨', 'exchange': 'DCE', 'ak_name': 'èšä¸™çƒ¯'},
            'ç”²é†‡': {'code': 'MA', 'category': 'åŒ–å·¥', 'unit': 'ä¸‡å¨', 'exchange': 'CZCE', 'ak_name': 'ç”²é†‡'},
        }
        
        # äº¤æ˜“æ‰€ä»“å•æ¥å£æ˜ å°„
        self.receipt_apis = {
            'SHFE': ak.futures_shfe_warehouse_receipt,
            'CZCE': ak.futures_czce_warehouse_receipt, 
            'DCE': ak.futures_dce_warehouse_receipt,
            'GFEX': ak.futures_gfex_warehouse_receipt
        }
        
        # å›¾è¡¨ä¿å­˜ç›®å½•
        self.charts_dir = Path("analysis_charts")
        self.charts_dir.mkdir(exist_ok=True)
        
        print("ğŸš€ ä¸“ä¸šåº“å­˜ä»“å•AIåˆ†æç³»ç»Ÿï¼ˆç»ˆæå®Œå–„ç‰ˆï¼‰å·²å¯åŠ¨")
        print("âœ… å…ƒæ•°æ®ä¿¡æ¯å®Œå…¨åç½®ï¼Œå¼€å¤´ç›´æ¥åˆ†æå†…å®¹")
        print("âœ… ä¸¥ç¦ä»»ä½•è‹±æ–‡ï¼Œçº¯ä¸­æ–‡ä¸“ä¸šè¡¨è¾¾")
        print("âœ… ä¸“ä¸šå›¾è¡¨ç”ŸæˆåŠŸèƒ½")
        print("âœ… å®Œå…¨å…¼å®¹Streamlitç³»ç»Ÿè°ƒç”¨")
        print("âœ… äº”ç»´æ•°æ®æ•´åˆ + åº“å­˜åèº«æ€§å…³ç³»æ·±åº¦è§£è¯»")
        
    def load_multi_dimensional_data(self, variety_name):
        """åŠ è½½å¤šç»´åº¦æ•°æ®"""
        print(f"ğŸ“Š æ­£åœ¨åŠ è½½{variety_name}çš„å¤šç»´åº¦æ•°æ®...")
        
        variety_info = self.variety_mapping.get(variety_name, {})
        variety_code = variety_info.get('code', variety_name)
        
        data = {
            'variety_info': variety_info,
            'data_sources': [],
            'online_data_used': False
        }
        
        # 1. åº“å­˜æ•°æ®ï¼ˆæœ¬åœ°+è”ç½‘ï¼‰
        inventory_data, inv_sources, inv_online = self.load_inventory_data_enhanced(variety_name)
        data['inventory'] = inventory_data
        data['data_sources'].extend(inv_sources)
        if inv_online:
            data['online_data_used'] = True
        
        # 2. ä»“å•æ•°æ®ï¼ˆå¼ºåŒ–è”ç½‘è·å–ï¼‰
        receipt_data, rec_sources, rec_online = self.load_receipt_data_enhanced(variety_name)
        data['receipt'] = receipt_data
        data['data_sources'].extend(rec_sources)
        if rec_online:
            data['online_data_used'] = True
        
        # 3. ä»·æ ¼æ•°æ®
        price_data, price_sources = self.load_price_data_multi(variety_name)
        data['price'] = price_data
        data['data_sources'].extend(price_sources)
        
        # 4. åŸºå·®æ•°æ®
        basis_data, basis_sources = self.load_basis_data(variety_name)
        data['basis'] = basis_data
        data['data_sources'].extend(basis_sources)
        
        # 5. æœŸé™ç»“æ„æ•°æ®
        term_structure_data, term_sources = self.load_term_structure_data(variety_name)
        data['term_structure'] = term_structure_data
        data['data_sources'].extend(term_sources)
        
        # 6. æŒä»“æ•°æ®
        positioning_data, pos_sources = self.load_positioning_data(variety_name)
        data['positioning'] = positioning_data
        data['data_sources'].extend(pos_sources)
        
        # 7. å¼ºåŒ–è”ç½‘è¡¥å……æ•°æ®
        online_supplement, online_sources, online_flag = self.fetch_online_supplement_data(variety_name)
        data['online_supplement'] = online_supplement
        data['data_sources'].extend(online_sources)
        if online_flag:
            data['online_data_used'] = True
        
        return data
    
    def load_inventory_data_enhanced(self, variety_name):
        """åŠ è½½å¢å¼ºåº“å­˜æ•°æ®"""
        variety_info = self.variety_mapping.get(variety_name, {})
        variety_code = variety_info.get('code', variety_name)
        ak_name = variety_info.get('ak_name', variety_name)
        # è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ“Š å“ç§æ˜ å°„: {variety_name} -> ä»£ç : {variety_code}, Akshareåç§°: {ak_name}")
        
        data_sources = []
        online_used = False
        
        # 1. æœ¬åœ°æ•°æ®
        inventory_file = self.inventory_dir / variety_code / "inventory.csv"
        local_df = None
        if inventory_file.exists():
            try:
                local_df = pd.read_csv(inventory_file)
                local_df['date'] = pd.to_datetime(local_df['date'])
                local_df = local_df.sort_values('date')
                print(f"âœ… æœ¬åœ°åº“å­˜æ•°æ®: {len(local_df)} æ¡è®°å½•")
                data_sources.append(f"æœ¬åœ°å†å²åº“å­˜æ•°æ®ï¼ˆ{len(local_df)}æ¡è®°å½•ï¼‰")
            except Exception as e:
                print(f"âš ï¸ æœ¬åœ°åº“å­˜æ•°æ®è¯»å–å¤±è´¥: {e}")
        
        # 2. å¼ºåŒ–è”ç½‘è·å–
        print(f"ğŸ“¡ å¼ºåŒ–è”ç½‘è·å–{variety_name}åº“å­˜æ•°æ®...")
        online_df = None
        try:
            online_df = ak.futures_inventory_em(symbol=ak_name)
            if online_df is not None and not online_df.empty:
                # æ ‡å‡†åŒ–æ•°æ®
                if 'æ—¥æœŸ' in online_df.columns:
                    online_df = online_df.rename(columns={'æ—¥æœŸ': 'date', 'åº“å­˜': 'value'})
                elif 'æ—¶é—´' in online_df.columns:
                    online_df = online_df.rename(columns={'æ—¶é—´': 'date', 'åº“å­˜': 'value'})
                
                online_df['date'] = pd.to_datetime(online_df['date'])
                online_df['value'] = pd.to_numeric(online_df['value'], errors='coerce')
                online_df = online_df.dropna(subset=['value']).sort_values('date')
                
                fetch_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                data_sources.append(f"è”ç½‘åº“å­˜æ•°æ®ï¼ˆä¸œæ–¹è´¢å¯Œï¼Œè·å–æ—¶é—´ï¼š{fetch_time}ï¼Œ{len(online_df)}æ¡è®°å½•ï¼‰")
                print(f"âœ… è”ç½‘åº“å­˜æ•°æ®: {len(online_df)} æ¡è®°å½•")
                online_used = True
            else:
                print(f"âŒ è”ç½‘åº“å­˜æ•°æ®è·å–å¤±è´¥ï¼šæ— æ•°æ®è¿”å›")
        except Exception as e:
            print(f"âŒ è”ç½‘åº“å­˜æ•°æ®è·å–å¤±è´¥: {e}")
        
        # 3. æ•°æ®æ•´åˆç­–ç•¥
        if online_df is not None and not online_df.empty:
            if local_df is not None and not local_df.empty:
                combined_df = pd.concat([local_df, online_df]).drop_duplicates(subset=['date']).sort_values('date').reset_index(drop=True)
                return combined_df, data_sources, online_used
            else:
                return online_df, data_sources, online_used
        elif local_df is not None:
            return local_df, data_sources, online_used
        else:
            return None, data_sources, online_used
    
    def load_receipt_data_enhanced(self, variety_name):
        """åŠ è½½å¢å¼ºä»“å•æ•°æ®"""
        variety_info = self.variety_mapping.get(variety_name, {})
        variety_code = variety_info.get('code', variety_name)
        exchange = variety_info.get('exchange', 'SHFE')
        
        data_sources = []
        online_used = False
        
        # 1. æœ¬åœ°ä»“å•æ•°æ®
        possible_receipt_dirs = [variety_name, variety_code, f"{variety_name}({variety_code})"]
        local_receipt_df = None
        
        for receipt_dir_name in possible_receipt_dirs:
            receipt_file = self.receipt_dir / receipt_dir_name / "receipt.csv"
            if receipt_file.exists():
                try:
                    local_receipt_df = pd.read_csv(receipt_file)
                    local_receipt_df['date'] = pd.to_datetime(local_receipt_df['date'])
                    local_receipt_df = local_receipt_df.sort_values('date')
                    print(f"âœ… æœ¬åœ°ä»“å•æ•°æ®: {len(local_receipt_df)} æ¡è®°å½•")
                    data_sources.append(f"æœ¬åœ°å†å²ä»“å•æ•°æ®ï¼ˆ{len(local_receipt_df)}æ¡è®°å½•ï¼‰")
                    break
                except Exception as e:
                    print(f"âš ï¸ æœ¬åœ°ä»“å•æ•°æ®è¯»å–å¤±è´¥ ({receipt_dir_name}): {e}")
                    continue
        
        # 2. å¼ºåŒ–è”ç½‘è·å–ä»“å•æ•°æ®
        print(f"ğŸ“¡ å¼ºåŒ–è”ç½‘è·å–{variety_name}ä»“å•æ•°æ®ï¼ˆ{exchange}ï¼‰...")
        online_receipt_df = None
        receipt_success = False
        
        if exchange in self.receipt_apis:
            try:
                receipt_api = self.receipt_apis[exchange]
                today = datetime.now()
                
                # æ‰©å¤§æœç´¢èŒƒå›´ï¼Œå°è¯•æœ€è¿‘30å¤©
                for days_back in range(0, 30):
                    target_date = (today - timedelta(days=days_back)).strftime('%Y%m%d')
                    try:
                        receipt_data = receipt_api(date=target_date)
                        if receipt_data is not None and not receipt_data.empty:
                            # ç­›é€‰ç›®æ ‡å“ç§çš„ä»“å•æ•°æ®
                            variety_data = None
                            for col_name in ['var', 'å“ç§', 'å“ç§ä»£ç ', 'symbol']:
                                if col_name in receipt_data.columns:
                                    variety_data = receipt_data[receipt_data[col_name].str.contains(variety_code, case=False, na=False)]
                                    if not variety_data.empty:
                                        break
                            
                            if variety_data is None or variety_data.empty:
                                variety_data = receipt_data
                            
                            if not variety_data.empty:
                                fetch_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                data_sources.append(f"è”ç½‘ä»“å•æ•°æ®ï¼ˆ{exchange}äº¤æ˜“æ‰€ï¼Œæ•°æ®æ—¥æœŸï¼š{target_date}ï¼Œè·å–æ—¶é—´ï¼š{fetch_time}ï¼Œ{len(variety_data)}æ¡è®°å½•ï¼‰")
                                print(f"âœ… è”ç½‘ä»“å•æ•°æ®: {target_date} æ—¥æ•°æ®ï¼Œ{len(variety_data)} æ¡è®°å½•")
                                online_receipt_df = variety_data
                                online_used = True
                                receipt_success = True
                                break
                    except Exception as e:
                        if days_back == 0:
                            print(f"âš ï¸ è·å–{target_date}ä»“å•æ•°æ®å¤±è´¥: {e}")
                        continue
                
                if not receipt_success:
                    print(f"âš ï¸ æœªèƒ½è·å–åˆ°æœ€è¿‘30å¤©çš„ä»“å•æ•°æ®")
                    
            except Exception as e:
                print(f"âŒ è”ç½‘ä»“å•æ•°æ®è·å–å¼‚å¸¸: {e}")
        
        # 3. è¿”å›æœ€ä¼˜æ•°æ®
        if online_receipt_df is not None and not online_receipt_df.empty:
            if local_receipt_df is not None and not local_receipt_df.empty:
                return online_receipt_df, data_sources, online_used
            else:
                return online_receipt_df, data_sources, online_used
        elif local_receipt_df is not None:
            return local_receipt_df, data_sources, online_used
        else:
            return None, data_sources, online_used
    
    def load_price_data_multi(self, variety_name):
        """åŠ è½½å¤šç»´ä»·æ ¼æ•°æ®"""
        variety_info = self.variety_mapping.get(variety_name, {})
        variety_code = variety_info.get('code', variety_name)
        
        data_sources = []
        
        price_file = self.technical_dir / variety_code / "ohlc_data.csv"
        if price_file.exists():
            try:
                price_df = pd.read_csv(price_file)
                price_df['æ—¶é—´'] = pd.to_datetime(price_df['æ—¶é—´'])
                price_df = price_df.sort_values('æ—¶é—´')
                print(f"âœ… æœ¬åœ°ä»·æ ¼æ•°æ®: {len(price_df)} æ¡è®°å½•")
                data_sources.append(f"æœ¬åœ°å†å²ä»·æ ¼æ•°æ®ï¼ˆ{len(price_df)}æ¡è®°å½•ï¼‰")
                return price_df, data_sources
            except Exception as e:
                print(f"âš ï¸ æœ¬åœ°ä»·æ ¼æ•°æ®åŠ è½½å¤±è´¥: {e}")
        
        print(f"âŒ æœªæ‰¾åˆ°ä»·æ ¼æ•°æ®")
        return None, data_sources
    
    def load_basis_data(self, variety_name):
        """åŠ è½½åŸºå·®æ•°æ®"""
        variety_info = self.variety_mapping.get(variety_name, {})
        variety_code = variety_info.get('code', variety_name)
        
        data_sources = []
        
        basis_file = self.basis_dir / variety_code / "basis_data.csv"
        if basis_file.exists():
            try:
                basis_df = pd.read_csv(basis_file)
                basis_df['date'] = pd.to_datetime(basis_df['date'])
                basis_df = basis_df.sort_values('date')
                print(f"âœ… æœ¬åœ°åŸºå·®æ•°æ®: {len(basis_df)} æ¡è®°å½•")
                data_sources.append(f"æœ¬åœ°åŸºå·®æ•°æ®ï¼ˆ{len(basis_df)}æ¡è®°å½•ï¼‰")
                return basis_df, data_sources
            except Exception as e:
                print(f"âš ï¸ åŸºå·®æ•°æ®åŠ è½½å¤±è´¥: {e}")
        
        print(f"â„¹ï¸ æœªæ‰¾åˆ°åŸºå·®æ•°æ®")
        return None, data_sources
    
    def load_term_structure_data(self, variety_name):
        """åŠ è½½æœŸé™ç»“æ„æ•°æ®"""
        variety_info = self.variety_mapping.get(variety_name, {})
        variety_code = variety_info.get('code', variety_name)
        
        data_sources = []
        
        term_file = self.term_structure_dir / variety_code / "term_structure.csv"
        if term_file.exists():
            try:
                term_df = pd.read_csv(term_file)
                term_df['date'] = pd.to_datetime(term_df['date'])
                term_df = term_df.sort_values('date')
                print(f"âœ… æœ¬åœ°æœŸé™ç»“æ„æ•°æ®: {len(term_df)} æ¡è®°å½•")
                data_sources.append(f"æœ¬åœ°æœŸé™ç»“æ„æ•°æ®ï¼ˆ{len(term_df)}æ¡è®°å½•ï¼‰")
                return term_df, data_sources
            except Exception as e:
                print(f"âš ï¸ æœŸé™ç»“æ„æ•°æ®åŠ è½½å¤±è´¥: {e}")
        
        print(f"â„¹ï¸ æœªæ‰¾åˆ°æœŸé™ç»“æ„æ•°æ®")
        return None, data_sources
    
    def load_positioning_data(self, variety_name):
        """åŠ è½½æŒä»“æ•°æ®"""
        variety_info = self.variety_mapping.get(variety_name, {})
        variety_code = variety_info.get('code', variety_name)
        
        data_sources = []
        
        # å°è¯•åŠ è½½å¤šå¤´æŒä»“æ•°æ®
        long_pos_file = self.positioning_dir / variety_code / "long_position_ranking.csv"
        if long_pos_file.exists():
            try:
                pos_df = pd.read_csv(long_pos_file)
                
                # å¤„ç†æ··åˆæ—¥æœŸæ ¼å¼
                def parse_mixed_dates(date_str):
                    """å¤„ç†æ··åˆçš„æ—¥æœŸæ ¼å¼"""
                    date_str = str(date_str).strip()
                    # å¦‚æœæ˜¯8ä½æ•°å­—æ ¼å¼ 20250822
                    if len(date_str) == 8 and date_str.isdigit():
                        return pd.to_datetime(date_str, format='%Y%m%d')
                    # æ ‡å‡†æ ¼å¼ 2025-08-18
                    else:
                        return pd.to_datetime(date_str)
                
                pos_df['date'] = pos_df['date'].apply(parse_mixed_dates)
                pos_df = pos_df.sort_values('date')
                print(f"âœ… æœ¬åœ°æŒä»“æ•°æ®: {len(pos_df)} æ¡è®°å½•")
                data_sources.append(f"æœ¬åœ°æŒä»“æ•°æ®ï¼ˆ{len(pos_df)}æ¡è®°å½•ï¼‰")
                return pos_df, data_sources
            except Exception as e:
                print(f"âš ï¸ æŒä»“æ•°æ®åŠ è½½å¤±è´¥: {e}")
        
        print(f"â„¹ï¸ æœªæ‰¾åˆ°æŒä»“æ•°æ®")
        return None, data_sources
    
    def fetch_online_supplement_data(self, variety_name):
        """è·å–è”ç½‘è¡¥å……æ•°æ®"""
        variety_info = self.variety_mapping.get(variety_name, {})
        variety_code = variety_info.get('code', variety_name)
        ak_name = variety_info.get('ak_name', variety_name)
        
        data_sources = []
        online_used = False
        supplement_data = {}
        
        print(f"ğŸ“¡ è·å–{variety_name}è”ç½‘è¡¥å……æ•°æ®...")
        
        try:
            # 1. è·å–æœ€æ–°ä»·æ ¼å’ŒæŒä»“é‡æ•°æ®
            try:
                realtime_data = ak.futures_main_sina(symbol=f"{variety_code}0")
                if realtime_data is not None and not realtime_data.empty:
                    latest_data = realtime_data.iloc[-1]
                    supplement_data['realtime_price'] = {
                        'current_price': latest_data.get('æ”¶ç›˜', 0),
                        'volume': latest_data.get('æˆäº¤é‡', 0),
                        'open_interest': latest_data.get('æŒä»“é‡', 0),
                        'change': latest_data.get('æ¶¨è·Œ', 0)
                    }
                    fetch_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    data_sources.append(f"è”ç½‘å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆæ–°æµªè´¢ç»ï¼Œè·å–æ—¶é—´ï¼š{fetch_time}ï¼‰")
                    online_used = True
                    print(f"âœ… è·å–å®æ—¶è¡Œæƒ…æ•°æ®æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ è·å–å®æ—¶è¡Œæƒ…æ•°æ®å¤±è´¥: {e}")
            
        except Exception as e:
            print(f"âŒ è”ç½‘è¡¥å……æ•°æ®è·å–å¼‚å¸¸: {e}")
        
        return supplement_data, data_sources, online_used
    
    def calculate_multi_dimensional_metrics(self, data):
        """è®¡ç®—å¤šç»´åº¦åˆ†ææŒ‡æ ‡"""
        metrics = {}
        
        inventory_df = data.get('inventory')
        receipt_df = data.get('receipt')
        price_df = data.get('price')
        basis_df = data.get('basis')
        term_df = data.get('term_structure')
        positioning_df = data.get('positioning')
        online_supplement = data.get('online_supplement', {})
        
        # 1. æ ¸å¿ƒåº“å­˜åˆ†ææŒ‡æ ‡
        if inventory_df is not None and not inventory_df.empty:
            inv_values = inventory_df['value']
            
            latest_inv = inv_values.iloc[-1]
            mean_inv = inv_values.mean()
            std_inv = inv_values.std()
            percentile = stats.percentileofscore(inv_values, latest_inv)
            
            # åº“å­˜å‘¨æœŸåˆ†æ
            if len(inv_values) >= 30:
                recent_30d_change = inv_values.iloc[-1] - inv_values.iloc[-30]
                daily_avg_change = recent_30d_change / 30
                
                price_trend = None
                if price_df is not None and not price_df.empty and len(price_df) >= 30:
                    price_30d_change = price_df['æ”¶ç›˜'].iloc[-1] - price_df['æ”¶ç›˜'].iloc[-30]
                    price_trend = "ä¸Šæ¶¨" if price_30d_change > 0 else "ä¸‹è·Œ"
                
                if recent_30d_change > std_inv * 0.3:
                    if price_trend == "ä¸Šæ¶¨":
                        cycle_stage = "ä¸»åŠ¨è¡¥åº“é˜¶æ®µ"
                        cycle_confidence = 0.8
                        cycle_meaning = "éœ€æ±‚é¢„æœŸå‘å¥½ï¼Œå¸‚åœºä¸»åŠ¨è¡¥åº“"
                    else:
                        cycle_stage = "è¢«åŠ¨è¡¥åº“é˜¶æ®µ"
                        cycle_confidence = 0.7
                        cycle_meaning = "éœ€æ±‚ç–²å¼±å¯¼è‡´è¢«åŠ¨ç´¯åº“"
                elif recent_30d_change < -std_inv * 0.3:
                    if price_trend == "ä¸Šæ¶¨":
                        cycle_stage = "è¢«åŠ¨å»åº“é˜¶æ®µ"
                        cycle_confidence = 0.7
                        cycle_meaning = "ä¾›ç»™æ”¶ç¼©å¯¼è‡´è¢«åŠ¨å»åº“"
                    else:
                        cycle_stage = "ä¸»åŠ¨å»åº“é˜¶æ®µ"
                        cycle_confidence = 0.8
                        cycle_meaning = "é¢„æœŸæ‚²è§‚ï¼Œå¸‚åœºä¸»åŠ¨å»åº“"
                else:
                    cycle_stage = "å¹³è¡¡é˜¶æ®µ"
                    cycle_confidence = 0.6
                    cycle_meaning = "ä¾›éœ€ç›¸å¯¹å¹³è¡¡"
            else:
                recent_30d_change = 0
                daily_avg_change = 0
                cycle_stage = "æ•°æ®ä¸è¶³"
                cycle_confidence = 0.3
                cycle_meaning = "å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­"
            
            # æŠ•æœºæ€§åº“å­˜åˆ†æ
            if len(inv_values) >= 20:
                volatility = inv_values.rolling(10).std().iloc[-1] / mean_inv if mean_inv > 0 else 0
                high_volatility_periods = (inv_values.rolling(5).std() > std_inv * 1.2).sum()
                
                speculative_ratio = min(volatility * 100, 25)
                
                if speculative_ratio > 15:
                    speculative_level = "é«˜æŠ•æœºæ€§"
                    speculative_meaning = "å¸‚åœºå­˜åœ¨å¤§é‡æŠ•æœºæ€§éœ€æ±‚ï¼Œåº“å­˜æ³¢åŠ¨å‰§çƒˆ"
                elif speculative_ratio > 8:
                    speculative_level = "ä¸­æŠ•æœºæ€§"
                    speculative_meaning = "å­˜åœ¨ä¸€å®šæŠ•æœºè¡Œä¸ºï¼Œéœ€å…³æ³¨å¸‚åœºæƒ…ç»ªå˜åŒ–"
                else:
                    speculative_level = "ä½æŠ•æœºæ€§"
                    speculative_meaning = "åº“å­˜å˜åŒ–ä¸»è¦åæ˜ çœŸå®ä¾›éœ€"
            else:
                speculative_ratio = 0
                speculative_level = "æ— æ³•åˆ¤æ–­"
                speculative_meaning = "æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†ææŠ•æœºæ€§ç‰¹å¾"
            
            metrics['inventory'] = {
                'latest': latest_inv,
                'mean': mean_inv,
                'std': std_inv,
                'percentile': percentile,
                'recent_30d_change': recent_30d_change,
                'daily_avg_change': daily_avg_change,
                'cycle_stage': cycle_stage,
                'cycle_confidence': cycle_confidence,
                'cycle_meaning': cycle_meaning,
                'speculative_ratio': speculative_ratio,
                'speculative_level': speculative_level,
                'speculative_meaning': speculative_meaning
            }
        
        # 2. åº“å­˜ä¸ä»·æ ¼åèº«æ€§åˆ†æ
        if inventory_df is not None and price_df is not None and not inventory_df.empty and not price_df.empty:
            try:
                inv_dates = inventory_df['date'].dt.date
                price_dates = price_df['æ—¶é—´'].dt.date
                common_dates = set(inv_dates) & set(price_dates)
                
                if len(common_dates) >= 10:
                    aligned_data = []
                    for date in sorted(common_dates):
                        inv_val = inventory_df[inventory_df['date'].dt.date == date]['value'].iloc[0]
                        price_val = price_df[price_df['æ—¶é—´'].dt.date == date]['æ”¶ç›˜'].iloc[0]
                        aligned_data.append({'date': date, 'inventory': inv_val, 'price': price_val})
                    
                    aligned_df = pd.DataFrame(aligned_data).sort_values('date')
                    price_inv_corr = aligned_df['price'].corr(aligned_df['inventory'])
                    
                    if abs(price_inv_corr) < 0.3:
                        reflexivity_type = "å¼±åèº«æ€§"
                        reflexivity_meaning = "ä»·æ ¼ä¸åº“å­˜å…³ç³»ä¸æ˜æ˜¾ï¼Œå¯èƒ½å­˜åœ¨å…¶ä»–ä¸»å¯¼å› ç´ "
                    elif price_inv_corr < -0.5:
                        reflexivity_type = "ç»å…¸è´Ÿç›¸å…³"
                        reflexivity_meaning = "åº“å­˜é«˜æ—¶ä»·æ ¼ä½ï¼Œç¬¦åˆä¼ ç»Ÿä¾›éœ€é€»è¾‘"
                    elif price_inv_corr > 0.5:
                        reflexivity_type = "æ­£å‘åèº«æ€§"
                        reflexivity_meaning = "ä»·æ ¼ä¸åº“å­˜åŒå‘å˜åŒ–ï¼Œå¯èƒ½å­˜åœ¨æŠ•æœºé©±åŠ¨"
                    else:
                        reflexivity_type = "ä¸­ç­‰ç›¸å…³æ€§"
                        reflexivity_meaning = "ä»·æ ¼ä¸åº“å­˜å­˜åœ¨ä¸€å®šç›¸å…³æ€§ï¼Œéœ€ç»“åˆå…¶ä»–å› ç´ åˆ†æ"
                        
                    metrics['reflexivity'] = {
                        'correlation': price_inv_corr,
                        'type': reflexivity_type,
                        'meaning': reflexivity_meaning,
                        'data_points': len(aligned_df)
                    }
                else:
                    metrics['reflexivity'] = {
                        'correlation': None,
                        'type': "æ•°æ®ä¸è¶³",
                        'meaning': "ä»·æ ¼ä¸åº“å­˜æ•°æ®æ— æ³•æœ‰æ•ˆå¯¹é½",
                        'data_points': len(common_dates)
                    }
            except Exception as e:
                metrics['reflexivity'] = {
                    'correlation': None,
                    'type': "åˆ†æå¤±è´¥",
                    'meaning': f"åèº«æ€§åˆ†æå¼‚å¸¸ï¼š{str(e)[:50]}",
                    'data_points': 0
                }
        
        # 3. å¤šç»´åº¦äº¤å‰åˆ†æ
        cross_analysis = {}
        
        if inventory_df is not None and basis_df is not None and not inventory_df.empty and not basis_df.empty:
            try:
                # åˆ†æåŸºå·®ç»“æ„
                latest_near_basis = basis_df['near_basis'].iloc[-1] if 'near_basis' in basis_df.columns else 0
                latest_dom_basis = basis_df['dom_basis'].iloc[-1] if 'dom_basis' in basis_df.columns else 0
                latest_near_rate = basis_df['near_basis_rate'].iloc[-1] if 'near_basis_rate' in basis_df.columns else 0
                latest_dom_rate = basis_df['dom_basis_rate'].iloc[-1] if 'dom_basis_rate' in basis_df.columns else 0
                
                # åŸºå·®ç»“æ„åˆ†æ
                structure_type = "æ­£å‘å¸‚åœº" if latest_near_basis < latest_dom_basis else "åå‘å¸‚åœº"
                basis_meaning = f"è¿‘æœˆåŸºå·®{latest_near_basis:.0f}å…ƒï¼Œè¿œæœˆåŸºå·®{latest_dom_basis:.0f}å…ƒï¼Œå‘ˆ{structure_type}ç»“æ„"
                
                cross_analysis['inventory_basis'] = {
                    'near_basis': latest_near_basis,
                    'dom_basis': latest_dom_basis,
                    'near_basis_rate': latest_near_rate,
                    'dom_basis_rate': latest_dom_rate,
                    'structure_type': structure_type,
                    'meaning': basis_meaning
                }
                print(f"âœ… åŸºå·®åˆ†æ: {basis_meaning}")
            except Exception as e:
                print(f"âš ï¸ åŸºå·®åˆ†æå¤±è´¥: {e}")
        
        # æŒä»“åˆ†æå¢å¼º
        if inventory_df is not None and positioning_df is not None and not inventory_df.empty and not positioning_df.empty:
            try:
                # è®¡ç®—æŒä»“åˆ†å¸ƒå’Œé›†ä¸­åº¦
                latest_date = positioning_df['date'].max()
                latest_positions = positioning_df[positioning_df['date'] == latest_date]
                
                if 'æŒä»“é‡' in latest_positions.columns:
                    total_position = latest_positions['æŒä»“é‡'].sum()
                    top3_position = latest_positions.head(3)['æŒä»“é‡'].sum()
                    top5_position = latest_positions.head(5)['æŒä»“é‡'].sum()
                    concentration_top3 = (top3_position / total_position * 100) if total_position > 0 else 0
                    concentration_top5 = (top5_position / total_position * 100) if total_position > 0 else 0
                    
                    cross_analysis['inventory_positioning'] = {
                        'total_position': total_position,
                        'top3_concentration': concentration_top3,
                        'top5_concentration': concentration_top5,
                        'meaning': f"æ€»æŒä»“{total_position:,.0f}æ‰‹ï¼Œå‰3å¸­ä½é›†ä¸­åº¦{concentration_top3:.1f}%ï¼Œå‰5å¸­ä½é›†ä¸­åº¦{concentration_top5:.1f}%"
                    }
                    print(f"âœ… æŒä»“åˆ†æ: æ€»æŒä»“{total_position:,.0f}æ‰‹ï¼Œå‰3é›†ä¸­åº¦{concentration_top3:.1f}%")
            except Exception as e:
                print(f"âš ï¸ æŒä»“åˆ†æå¤±è´¥: {e}")
        
        # æœŸé™ç»“æ„åˆ†æå¢å¼º
        if term_df is not None and not term_df.empty:
            try:
                # åˆ†ææœŸé™ç»“æ„å½¢æ€
                latest_date_term = term_df['date'].max()
                latest_terms = term_df[term_df['date'] == latest_date_term].copy()
                
                if len(latest_terms) >= 2 and 'close' in latest_terms.columns:
                    # æŒ‰åˆçº¦æœˆä»½æ’åº
                    latest_terms = latest_terms.sort_values('symbol')
                    prices = latest_terms['close'].values
                    
                    # è®¡ç®—æœŸé™ç»“æ„æ–œç‡
                    if len(prices) >= 3:
                        near_price = prices[0]
                        mid_price = prices[len(prices)//2]
                        far_price = prices[-1]
                        
                        term_slope = (far_price - near_price) / near_price * 100
                        term_shape = "æ­£å‘ç»“æ„(è¿‘ä½è¿œé«˜)" if term_slope > 1 else "å¹³å¦ç»“æ„" if abs(term_slope) <= 1 else "åå‘ç»“æ„(è¿‘é«˜è¿œä½)"
                        
                        cross_analysis['term_structure'] = {
                            'near_price': near_price,
                            'far_price': far_price,
                            'term_slope': term_slope,
                            'term_shape': term_shape,
                            'meaning': f"{term_shape}ï¼Œæ–œç‡{term_slope:.2f}%"
                        }
                        print(f"âœ… æœŸé™ç»“æ„: {term_shape}ï¼Œæ–œç‡{term_slope:.2f}%")
            except Exception as e:
                print(f"âš ï¸ æœŸé™ç»“æ„åˆ†æå¤±è´¥: {e}")
        
        metrics['cross_analysis'] = cross_analysis
        
        # 4. å½“å‰å¸‚åœºçŠ¶æ€ç»¼åˆåˆ¤æ–­
        current_price = 0
        price_change_30d = 0
        
        # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ä»·æ ¼æ•°æ®ï¼ˆæ›´å¯é ï¼‰
        if price_df is not None and not price_df.empty:
            current_price = float(price_df['æ”¶ç›˜'].iloc[-1])
            if len(price_df) >= 30:
                price_change_30d = float(price_df['æ”¶ç›˜'].iloc[-1] - price_df['æ”¶ç›˜'].iloc[-30])
            print(f"âœ… å½“å‰ä»·æ ¼: {current_price} å…ƒ/å¨, 30æ—¥å˜åŒ–: {price_change_30d:+.0f} å…ƒ/å¨")
        elif online_supplement.get('realtime_price'):
            current_price = online_supplement['realtime_price'].get('current_price', 0)
            price_change_30d = online_supplement['realtime_price'].get('change', 0)
            print(f"âœ… è”ç½‘ä»·æ ¼: {current_price} å…ƒ/å¨")
        
        metrics['current_market'] = {
            'price': current_price,
            'price_change_30d': price_change_30d
        }
        
        return metrics
    
    def generate_professional_charts(self, variety_name, data, metrics):
        """ç”Ÿæˆä¸“ä¸šå›¾è¡¨"""
        print(f"ğŸ“Š æ­£åœ¨ç”Ÿæˆ{variety_name}ä¸“ä¸šåˆ†æå›¾è¡¨...")
        
        variety_code = data['variety_info'].get('code', variety_name)
        chart_objects = {}  # æ”¹ä¸ºå­—å…¸å­˜å‚¨å›¾è¡¨å¯¹è±¡
        
        try:
            
            inventory_df = data.get('inventory')
            price_df = data.get('price')
            basis_df = data.get('basis')
            
            # 1. åº“å­˜è¶‹åŠ¿å›¾ï¼ˆPlotlyç‰ˆæœ¬ï¼‰
            if inventory_df is not None and not inventory_df.empty:
                fig = go.Figure()
                
                # åº“å­˜è¶‹åŠ¿çº¿
                fig.add_trace(go.Scatter(
                    x=inventory_df['date'],
                    y=inventory_df['value'],
                    mode='lines+markers',
                    name='åº“å­˜æ°´å¹³',
                    line=dict(color='#2E86AB', width=3),
                    marker=dict(size=6),
                    hovertemplate='æ—¥æœŸ: %{x}<br>åº“å­˜: %{y:.1f}ä¸‡å¨<extra></extra>'
                ))
                
                # æ·»åŠ 30æ—¥ç§»åŠ¨å¹³å‡çº¿
                if len(inventory_df) >= 30:
                    ma30 = inventory_df['value'].rolling(30).mean()
                    fig.add_trace(go.Scatter(
                        x=inventory_df['date'],
                        y=ma30,
                        mode='lines',
                        name='30æ—¥ç§»åŠ¨å¹³å‡',
                        line=dict(color='#FF6B6B', width=2, dash='dash'),
                        hovertemplate='æ—¥æœŸ: %{x}<br>30æ—¥å‡å€¼: %{y:.1f}ä¸‡å¨<extra></extra>'
                    ))
                
                # æ·»åŠ å†å²å‡å€¼çº¿
                inv_metrics = metrics.get('inventory', {})
                percentile = inv_metrics.get('percentile', 0)
                mean_value = inv_metrics.get('mean', 0)
                current_value = inv_metrics.get('latest', 0)
                
                if mean_value > 0:
                    fig.add_hline(y=mean_value, line_dash="dot", line_color="gray", 
                                 annotation_text=f"å†å²å‡å€¼: {mean_value:.1f}ä¸‡å¨")
                
                fig.update_layout(
                    title=f'{variety_name}åº“å­˜è¶‹åŠ¿åˆ†æ<br><sub>å½“å‰åº“å­˜ï¼š{current_value:.1f}ä¸‡å¨ï¼ˆå†å²{percentile:.1f}%åˆ†ä½æ•°ï¼‰</sub>',
                    xaxis_title='æ—¶é—´',
                    yaxis_title=f'åº“å­˜({data["variety_info"].get("unit", "ä¸‡å¨")})',
                    hovermode='x unified',
                    template='plotly_white',
                    height=500,
                    font=dict(size=12),
                    showlegend=True
                )
                
                chart_objects['åº“å­˜è¶‹åŠ¿åˆ†æ'] = fig
                print(f"âœ… ç”Ÿæˆåº“å­˜è¶‹åŠ¿Plotlyå›¾è¡¨")
            
            # åº“å­˜ä»·æ ¼èµ°åŠ¿å¯¹æ¯”å›¾ï¼ˆæ–°å¢ï¼Œæ•°æ®å¯¹é½ç‰ˆæœ¬ï¼‰
            if inventory_df is not None and price_df is not None and not inventory_df.empty and not price_df.empty:
                try:
                    # ç¡®ä¿æ•°æ®å¯¹é½ - æ‰¾åˆ°å…±åŒçš„æ—¶é—´èŒƒå›´
                    price_col = 'æ”¶ç›˜' if 'æ”¶ç›˜' in price_df.columns else 'close'
                    date_col = 'æ—¶é—´' if 'æ—¶é—´' in price_df.columns else 'date'
                    
                    # å°†ä¸¤ä¸ªæ•°æ®çš„æ—¥æœŸéƒ½è½¬ä¸ºæ ‡å‡†æ ¼å¼
                    inventory_df_copy = inventory_df.copy()
                    price_df_copy = price_df.copy()
                    
                    # ç¡®ä¿æ—¥æœŸä¸ºdatetimeæ ¼å¼
                    inventory_df_copy['date'] = pd.to_datetime(inventory_df_copy['date'])
                    price_df_copy[date_col] = pd.to_datetime(price_df_copy[date_col])
                    
                    # æ‰¾åˆ°å…±åŒçš„æ—¶é—´èŒƒå›´
                    inv_start, inv_end = inventory_df_copy['date'].min(), inventory_df_copy['date'].max()
                    price_start, price_end = price_df_copy[date_col].min(), price_df_copy[date_col].max()
                    
                    # å–äº¤é›†æ—¶é—´èŒƒå›´
                    common_start = max(inv_start, price_start)
                    common_end = min(inv_end, price_end)
                    
                    # è¿‡æ»¤åˆ°å…±åŒæ—¶é—´èŒƒå›´
                    inventory_aligned = inventory_df_copy[
                        (inventory_df_copy['date'] >= common_start) & 
                        (inventory_df_copy['date'] <= common_end)
                    ].copy()
                    
                    price_aligned = price_df_copy[
                        (price_df_copy[date_col] >= common_start) & 
                        (price_df_copy[date_col] <= common_end)
                    ].copy()
                    
                    if len(inventory_aligned) > 0 and len(price_aligned) > 0:
                        # åˆ›å»ºåŒYè½´å¯¹æ¯”å›¾
                        fig_compare = make_subplots(specs=[[{"secondary_y": True}]])
                        
                        # åº“å­˜èµ°åŠ¿ï¼ˆå·¦è½´ï¼‰
                        fig_compare.add_trace(
                            go.Scatter(x=inventory_aligned['date'], y=inventory_aligned['value'],
                                     mode='lines+markers', name='åº“å­˜èµ°åŠ¿',
                                     line=dict(color='#1f77b4', width=3),
                                     marker=dict(size=6),
                                     hovertemplate='æ—¥æœŸ: %{x}<br>åº“å­˜: %{y:.1f}ä¸‡å¨<extra></extra>'),
                            secondary_y=False,
                        )
                        
                        # ä»·æ ¼èµ°åŠ¿ï¼ˆå³è½´ï¼‰
                        fig_compare.add_trace(
                            go.Scatter(x=price_aligned[date_col], y=price_aligned[price_col],
                                     mode='lines+markers', name='ä»·æ ¼èµ°åŠ¿',
                                     line=dict(color='#ff7f0e', width=3),
                                     marker=dict(size=6, symbol='square'),
                                     hovertemplate='æ—¥æœŸ: %{x}<br>ä»·æ ¼: %{y:.0f}å…ƒ/å¨<extra></extra>'),
                            secondary_y=True,
                        )
                        
                        # è®¾ç½®Yè½´æ ‡é¢˜
                        fig_compare.update_yaxes(title_text=f"åº“å­˜({data['variety_info'].get('unit', 'ä¸‡å¨')})", 
                                               secondary_y=False, title_font_color='#1f77b4')
                        fig_compare.update_yaxes(title_text="ä»·æ ¼ï¼ˆå…ƒ/å¨ï¼‰", 
                                               secondary_y=True, title_font_color='#ff7f0e')
                        
                        # è®¡ç®—ç›¸å…³æ€§ï¼ˆåŸºäºå¯¹é½çš„æ•°æ®ï¼‰
                        try:
                            # é‡é‡‡æ ·åˆ°æ—¥é¢‘ç‡å¯¹é½
                            inv_daily = inventory_aligned.set_index('date')['value'].resample('D').last().dropna()
                            price_daily = price_aligned.set_index(date_col)[price_col].resample('D').last().dropna()
                            common_daily_dates = inv_daily.index.intersection(price_daily.index)
                            
                            if len(common_daily_dates) > 10:
                                correlation = inv_daily[common_daily_dates].corr(price_daily[common_daily_dates])
                            else:
                                correlation = 0.0
                        except Exception:
                            correlation = 0.0
                        
                        fig_compare.update_layout(
                            title=f'{variety_name}åº“å­˜ä¸ä»·æ ¼èµ°åŠ¿å¯¹æ¯”<br><sub>æ—¶é—´èŒƒå›´: {common_start.strftime("%Y-%m-%d")} ~ {common_end.strftime("%Y-%m-%d")} | ç›¸å…³æ€§: {correlation:.3f}</sub>',
                            xaxis_title='æ—¶é—´',
                            hovermode='x unified',
                            template='plotly_white',
                            height=600,
                            font=dict(size=12)
                        )
                        
                        chart_objects['åº“å­˜ä»·æ ¼èµ°åŠ¿å¯¹æ¯”'] = fig_compare
                        print(f"âœ… ç”Ÿæˆåº“å­˜ä»·æ ¼èµ°åŠ¿å¯¹æ¯”Plotlyå›¾è¡¨ï¼ˆæ—¶é—´èŒƒå›´ï¼š{common_start.strftime('%Y-%m-%d')} ~ {common_end.strftime('%Y-%m-%d')}ï¼‰")
                    else:
                        print(f"âš ï¸ åº“å­˜å’Œä»·æ ¼æ•°æ®æ—¶é—´èŒƒå›´ä¸é‡å ï¼Œæ— æ³•ç”Ÿæˆå¯¹æ¯”å›¾")
                        
                except Exception as e:
                    print(f"âŒ åº“å­˜ä»·æ ¼å¯¹æ¯”å›¾ç”Ÿæˆå¤±è´¥: {e}")
            
            # 2. ä»·æ ¼åº“å­˜åèº«æ€§åˆ†æå›¾ï¼ˆPlotlyç‰ˆæœ¬ï¼‰
            if inventory_df is not None and price_df is not None and not inventory_df.empty and not price_df.empty:
                # æ•°æ®å¯¹é½
                inventory_monthly = inventory_df.set_index('date')['value'].resample('M').last().dropna()
                
                # ç¡®ä¿ä»·æ ¼æ•°æ®çš„åˆ—åæ­£ç¡®
                if 'æ—¶é—´' in price_df.columns:
                    price_monthly = price_df.set_index('æ—¶é—´')['æ”¶ç›˜'].resample('M').last().dropna()
                else:
                    price_monthly = price_df.set_index('date')['æ”¶ç›˜'].resample('M').last().dropna()
                
                # æ‰¾åˆ°å…±åŒæ—¶é—´èŒƒå›´
                common_dates = inventory_monthly.index.intersection(price_monthly.index)
                
                if len(common_dates) > 6:  # è‡³å°‘éœ€è¦6ä¸ªæœˆçš„æ•°æ®
                    inv_aligned = inventory_monthly[common_dates]
                    price_aligned = price_monthly[common_dates]
                    
                    # åˆ›å»ºåŒYè½´å›¾è¡¨
                    fig = make_subplots(specs=[[{"secondary_y": True}]])
                    
                    # æ·»åŠ åº“å­˜
                    fig.add_trace(
                        go.Scatter(x=inv_aligned.index, y=inv_aligned.values,
                                 name="åº“å­˜æ°´å¹³", line=dict(color='#1f77b4', width=3),
                                 marker=dict(size=8),
                                 hovertemplate='æ—¥æœŸ: %{x}<br>åº“å­˜: %{y:.1f}ä¸‡å¨<extra></extra>'),
                        secondary_y=False,
                    )
                    
                    # æ·»åŠ ä»·æ ¼
                    fig.add_trace(
                        go.Scatter(x=price_aligned.index, y=price_aligned.values,
                                 name="ä»·æ ¼", line=dict(color='#ff7f0e', width=3),
                                 marker=dict(size=8, symbol='square'),
                                 hovertemplate='æ—¥æœŸ: %{x}<br>ä»·æ ¼: %{y:.0f}å…ƒ/å¨<extra></extra>'),
                        secondary_y=True,
                    )
                    
                    # è®¡ç®—ç›¸å…³æ€§
                    correlation = inv_aligned.corr(price_aligned)
                    reflex_type = "è´Ÿç›¸å…³(åèº«æ€§æ˜¾è‘—)" if correlation < -0.3 else "æ­£ç›¸å…³(åŒæ­¥æ€§æ˜¾è‘—)" if correlation > 0.3 else "å¼±ç›¸å…³(åèº«æ€§ä¸æ˜æ˜¾)"
                    
                    # è®¾ç½®Yè½´æ ‡é¢˜
                    fig.update_yaxes(title_text=f"åº“å­˜({data['variety_info'].get('unit', 'ä¸‡å¨')})", secondary_y=False, title_font_color='#1f77b4')
                    fig.update_yaxes(title_text="ä»·æ ¼ï¼ˆå…ƒ/å¨ï¼‰", secondary_y=True, title_font_color='#ff7f0e')
                    
                    fig.update_layout(
                        title=f'{variety_name}ä»·æ ¼åº“å­˜åèº«æ€§åˆ†æ<br><sub>ç›¸å…³ç³»æ•°ï¼š{correlation:.3f} ï¼ˆ{reflex_type}ï¼‰</sub>',
                        xaxis_title='æ—¶é—´',
                        hovermode='x unified',
                        template='plotly_white',
                        height=500,
                        font=dict(size=12)
                    )
                    
                    chart_objects['ä»·æ ¼åº“å­˜åèº«æ€§åˆ†æ'] = fig
                    print(f"âœ… ç”Ÿæˆä»·æ ¼åº“å­˜åèº«æ€§Plotlyå›¾è¡¨")
            
            # 3. åº“å­˜å‘¨æœŸåˆ†æå›¾ï¼ˆPlotlyç‰ˆæœ¬ï¼‰
            if inventory_df is not None and not inventory_df.empty and len(inventory_df) >= 60:
                inventory_df_copy = inventory_df.copy().sort_values('date')
                inventory_df_copy['change_rate'] = inventory_df_copy['value'].pct_change(periods=30) * 100
                inventory_df_copy['ma_20d'] = inventory_df_copy['value'].rolling(20).mean()
                inventory_df_copy = inventory_df_copy.dropna()
                
                # åˆ›å»ºåŒYè½´å›¾è¡¨
                fig = make_subplots(specs=[[{"secondary_y": True}]])
                
                # æ·»åŠ åº“å­˜æ°´å¹³
                fig.add_trace(
                    go.Scatter(x=inventory_df_copy['date'], y=inventory_df_copy['value'],
                             mode='lines+markers', name='åº“å­˜æ°´å¹³',
                             line=dict(color='#2E86AB', width=3),
                             marker=dict(size=6),
                             hovertemplate='æ—¥æœŸ: %{x}<br>åº“å­˜: %{y:.1f}ä¸‡å¨<extra></extra>'),
                    secondary_y=False,
                )
                
                # æ·»åŠ 20æ—¥ç§»åŠ¨å¹³å‡
                fig.add_trace(
                    go.Scatter(x=inventory_df_copy['date'], y=inventory_df_copy['ma_20d'],
                             mode='lines', name='20æ—¥ç§»åŠ¨å¹³å‡',
                             line=dict(color='#17becf', width=2, dash='dash'),
                             hovertemplate='æ—¥æœŸ: %{x}<br>20æ—¥å‡å€¼: %{y:.1f}ä¸‡å¨<extra></extra>'),
                    secondary_y=False,
                )
                
                # æ·»åŠ åº“å­˜å˜åŒ–ç‡ï¼ˆæŸ±çŠ¶å›¾ï¼‰
                colors = ['green' if x >= 0 else 'red' for x in inventory_df_copy['change_rate']]
                fig.add_trace(
                    go.Bar(x=inventory_df_copy['date'], y=inventory_df_copy['change_rate'],
                          name='30æ—¥å˜åŒ–ç‡', marker_color=colors, opacity=0.6,
                          hovertemplate='æ—¥æœŸ: %{x}<br>å˜åŒ–ç‡: %{y:.1f}%<extra></extra>'),
                    secondary_y=True,
                )
                
                # æ·»åŠ é›¶çº¿
                fig.add_hline(y=0, line_dash="dash", line_color="gray", secondary_y=True)
                
                # åº“å­˜å‘¨æœŸé˜¶æ®µæ ‡æ³¨
                inv_metrics = metrics.get('inventory', {})
                cycle_stage = inv_metrics.get('cycle_stage', 'æœªçŸ¥')
                cycle_confidence = inv_metrics.get('cycle_confidence', 0)
                
                # è®¾ç½®Yè½´æ ‡é¢˜
                fig.update_yaxes(title_text=f"åº“å­˜({data['variety_info'].get('unit', 'ä¸‡å¨')})", secondary_y=False, title_font_color='#2E86AB')
                fig.update_yaxes(title_text="å˜åŒ–ç‡ï¼ˆ%ï¼‰", secondary_y=True, title_font_color='#FF6B6B')
                
                fig.update_layout(
                    title=f'{variety_name}åº“å­˜å‘¨æœŸåˆ†æ<br><sub>å½“å‰é˜¶æ®µï¼š{cycle_stage} (ç½®ä¿¡åº¦{cycle_confidence:.0%})</sub>',
                    xaxis_title='æ—¶é—´',
                    hovermode='x unified',
                    template='plotly_white',
                    height=600,
                    font=dict(size=12)
                )
                
                chart_objects['åº“å­˜å‘¨æœŸåˆ†æ'] = fig
                print(f"âœ… ç”Ÿæˆåº“å­˜å‘¨æœŸåˆ†æPlotlyå›¾è¡¨")
            
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        
        return chart_objects
    
    def get_comprehensive_market_context(self, variety_name):
        """è·å–ç»¼åˆå¸‚åœºèƒŒæ™¯ä¿¡æ¯ï¼ˆå¼ºåŒ–ç‰ˆï¼‰"""
        try:
            variety_info = self.variety_mapping.get(variety_name, {})
            variety_code = variety_info.get('code', variety_name)
            category = variety_info.get('category', 'æœªçŸ¥')
            
            # æ‰©å±•æœç´¢æŸ¥è¯¢ï¼Œæ¶µç›–æ›´å¤šç»´åº¦å’Œå…·ä½“æ•°æ®
            search_queries = [
                f"{variety_name} {variety_code} æœŸè´§ åº“å­˜ ä»“å• æœ€æ–°æ•°æ® ç»Ÿè®¡å±€ 2024 2025",
                f"{variety_name} ä¾›éœ€å¹³è¡¡è¡¨ äº§é‡æ•°æ® æ¶ˆè´¹é‡ç»Ÿè®¡ è¿›å‡ºå£æœˆåº¦æ•°æ®",
                f"{variety_name} äº§èƒ½åˆ©ç”¨ç‡ å¼€å·¥ç‡ è£…ç½®æ£€ä¿® ä¼ä¸šåœäº§ ç”Ÿäº§çŠ¶å†µ",
                f"{variety_name} æˆæœ¬ç»“æ„åˆ†æ åŸæ–™ä»·æ ¼ ç”µåŠ›æˆæœ¬ è¿è¾“è´¹ç”¨ åˆ©æ¶¦",
                f"{variety_name} ä¸‹æ¸¸éœ€æ±‚è°ƒç ” æˆ¿åœ°äº§ åŸºå»ºæŠ•èµ„ æ±½è½¦å·¥ä¸š ç»ˆç«¯æ¶ˆè´¹",
                f"{variety_name} åº“å­˜åˆ†ç±» ç¤¾ä¼šåº“å­˜ å·¥å‚åº“å­˜ è´¸æ˜“å•†åº“å­˜ æ¸¯å£åº“å­˜",
                f"{variety_name} åŸºå·®åŠ¨é‡ æœŸé™ç»“æ„ åˆçº¦ä»·å·® äº¤å‰²å‹åŠ› èµ„é‡‘æˆæœ¬",
                f"{variety_name} æŒä»“åˆ†æ ä¸»åŠ›å¸­ä½ å‡€æŒä»“ èµ„é‡‘æµå‘ æŠ•æœºå¥—ä¿",
                f"{variety_name} æ”¿ç­–ç¯ä¿ é™äº§ä»¤ ç¯ä¿ç£æŸ¥ è¡Œä¸šæ ‡å‡† äº§ä¸šæ”¿ç­–",
                f"{variety_name} å­£èŠ‚æ€§è§„å¾‹ æ¶ˆè´¹æ—ºå­£ åº“å­˜å‘¨æœŸ å†å²ä»·æ ¼ å‘¨æœŸæ€§",
                f"{variety_name} æ›¿ä»£å“ç«äº‰ ä¸Šæ¸¸å„æ–­ ä¸‹æ¸¸è®®ä»· äº§ä¸šé“¾åšå¼ˆ",
                f"{variety_name} å®è§‚ä¼ å¯¼ è´§å¸æ”¿ç­– æ±‡ç‡å½±å“ é€šèƒ€é¢„æœŸ ç»æµå‘¨æœŸ"
            ]
            
            all_context_info = []
            search_success_count = 0
            
            for i, query in enumerate(search_queries):
                headers = {
                    "X-API-KEY": self.serper_api_key,
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "q": query,
                    "gl": "cn",
                    "hl": "zh-cn",
                    "num": 4  # æ¯ä¸ªæŸ¥è¯¢è·å–æ›´å¤šç»“æœ
                }
                
                try:
                    response = requests.post(self.serper_base_url,
                                           headers=headers,
                                           json=payload,
                                           timeout=15)
                    
                    if response.status_code == 200:
                        data = response.json()
                        organic_results = data.get('organic', [])
                        search_success_count += 1
                        
                        for result in organic_results:
                            title = result.get('title', '').strip()
                            snippet = result.get('snippet', '').strip()
                            link = result.get('link', '').strip()
                            if title and snippet:
                                # å¢å¼ºä¿¡æ¯åˆ†ç±»ï¼ˆ12ä¸ªç»´åº¦ï¼‰
                                query_categories = [
                                    "åº“å­˜ä»“å•ç»Ÿè®¡", "ä¾›éœ€å¹³è¡¡è¡¨", "äº§èƒ½å¼€å·¥ç‡", 
                                    "æˆæœ¬ç»“æ„åˆ†æ", "ä¸‹æ¸¸éœ€æ±‚è°ƒç ”", "åº“å­˜åˆ†ç±»ç»Ÿè®¡",
                                    "åŸºå·®æœŸé™ç»“æ„", "æŒä»“èµ„é‡‘åˆ†æ", "æ”¿ç­–ç¯ä¿å½±å“",
                                    "å­£èŠ‚æ€§è§„å¾‹", "äº§ä¸šé“¾åšå¼ˆ", "å®è§‚ç»æµä¼ å¯¼"
                                ]
                                
                                all_context_info.append({
                                    'title': title[:150],  # æ›´é•¿æ ‡é¢˜
                                    'snippet': snippet[:300],  # æ›´é•¿æ‘˜è¦
                                    'link': link,
                                    'query_type': f"{query_categories[i]}",
                                    'search_query': query,
                                    'relevance_score': len([kw for kw in [variety_name, variety_code] if kw.lower() in (title + snippet).lower()])
                                })
                    else:
                        print(f"âš ï¸ æœç´¢APIè¿”å›é”™è¯¯çŠ¶æ€ç : {response.status_code}")
                        
                except Exception as e:
                    print(f"âš ï¸ æœç´¢æŸ¥è¯¢å¤±è´¥ '{query[:50]}...': {e}")
                    continue
                
                # é€‚å½“å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(1.0)
            
            # æŒ‰ç›¸å…³æ€§æ’åºå¹¶æ ¼å¼åŒ–ç»“æœ
            if all_context_info:
                # æŒ‰ç›¸å…³æ€§åˆ†æ•°æ’åº
                all_context_info.sort(key=lambda x: x['relevance_score'], reverse=True)
                
                fetch_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                formatted_context = f"""ã€å¼ºåŒ–è”ç½‘æœç´¢ç»“æœã€‘
æœç´¢æ—¶é—´ï¼š{fetch_time}
æˆåŠŸæŸ¥è¯¢ï¼š{search_success_count}/{len(search_queries)} ä¸ªç»´åº¦ï¼ˆ12ç»´åº¦å…¨è¦†ç›–æœç´¢ï¼‰
è·å–ä¿¡æ¯ï¼š{len(all_context_info)} æ¡ç›¸å…³ä¿¡æ¯
æ•°æ®æ—¶æ•ˆæ€§ï¼šå®æ—¶è”ç½‘è·å–ï¼Œè¯·æ³¨æ„ä¿¡æ¯å‘å¸ƒæ—¶é—´
è¦†ç›–èŒƒå›´ï¼šåº“å­˜ç»Ÿè®¡ã€ä¾›éœ€å¹³è¡¡ã€äº§èƒ½å¼€å·¥ã€æˆæœ¬ç»“æ„ã€éœ€æ±‚è°ƒç ”ã€æŒä»“åˆ†æã€æ”¿ç­–å½±å“ã€å­£èŠ‚è§„å¾‹ã€äº§ä¸šåšå¼ˆã€å®è§‚ä¼ å¯¼

=== 12ç»´åº¦å¸‚åœºä¿¡æ¯æ±‡æ€» ===
"""
                
                # é™åˆ¶æ˜¾ç¤ºæœ€ç›¸å…³çš„12æ¡ä¿¡æ¯
                for i, info in enumerate(all_context_info[:12], 1):
                    formatted_context += f"""
{i}. ã€{info['query_type']}ã€‘{info['title']}
   å†…å®¹æ‘˜è¦ï¼š{info['snippet']}
   ä¿¡æ¯æ¥æºï¼š{info['link'][:120]}
   ç›¸å…³åº¦ï¼š{'â˜…' * info['relevance_score']}{'â˜†' * (3 - info['relevance_score'])}
   æœç´¢æŸ¥è¯¢ï¼š{info['search_query'][:60]}...
"""
                
                formatted_context += f"""

=== æ•°æ®è¯´æ˜ ===
- ä»¥ä¸Šä¿¡æ¯é€šè¿‡Serper APIå®æ—¶æœç´¢è·å–
- ä¿¡æ¯æ¥æºå‡å·²æ ‡æ³¨ï¼Œè¯·æ ¸å®æ—¶æ•ˆæ€§
- ç›¸å…³åº¦è¯„åˆ†åŸºäºå…³é”®è¯åŒ¹é…ç¨‹åº¦
- å»ºè®®ç»“åˆå¤šä¸ªä¿¡æ¯æºè¿›è¡Œç»¼åˆåˆ¤æ–­
"""
                
                # æ„å»ºè„šæ³¨å¼•ç”¨ä¿¡æ¯
                footnote_refs = []
                for i, info in enumerate(all_context_info[:12], 1):
                    footnote_refs.append({
                        'id': i,
                        'title': info['title'],
                        'link': info['link'],
                        'snippet': info['snippet'][:150],
                        'query_type': info['query_type'],
                        'fetch_time': fetch_time
                    })
                
                print(f"âœ… æˆåŠŸè·å–è”ç½‘å¸‚åœºä¿¡æ¯: {len(all_context_info)} æ¡")
                return {
                    'formatted_context': formatted_context,
                    'footnote_refs': footnote_refs,
                    'search_success': True
                }
            else:
                return {
                    'formatted_context': f"""ã€è”ç½‘æœç´¢å¤±è´¥ã€‘
æœç´¢æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æœç´¢çŠ¶æ€ï¼šæ‰€æœ‰æŸ¥è¯¢å‡å¤±è´¥ï¼Œæ— æ³•è·å–å®æ—¶å¸‚åœºä¿¡æ¯
å»ºè®®ï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•
""",
                    'footnote_refs': [],
                    'search_success': False
                }
                
        except Exception as e:
            print(f"âŒ è·å–ç»¼åˆå¸‚åœºä¿¡æ¯å¼‚å¸¸: {e}")
            return {
                'formatted_context': f"""ã€è”ç½‘æœç´¢å¼‚å¸¸ã€‘
æœç´¢æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
é”™è¯¯ä¿¡æ¯ï¼š{str(e)[:100]}
å½±å“ï¼šæ— æ³•è·å–å®æ—¶å¸‚åœºèƒŒæ™¯ä¿¡æ¯ï¼Œåˆ†æå°†åŸºäºæœ¬åœ°æ•°æ®
""",
                'footnote_refs': [],
                'search_success': False
            }
    
    def build_ultimate_analysis_prompt(self, variety_name, metrics, market_context, data):
        """æ„å»ºç»ˆæåˆ†ææç¤ºè¯"""
        
        variety_info = self.variety_mapping.get(variety_name, {})
        variety_code = variety_info.get('code', variety_name)
        category = variety_info.get('category', 'æœªçŸ¥')
        exchange = variety_info.get('exchange', 'æœªçŸ¥')
        chinese_name = variety_info.get('chinese_name', variety_name)
        
        # æå–å…³é”®æŒ‡æ ‡
        inv_metrics = metrics.get('inventory', {})
        reflex_metrics = metrics.get('reflexivity', {})
        current_market = metrics.get('current_market', {})
        cross_analysis = metrics.get('cross_analysis', {})
        
        # æ ¸å¿ƒæ•°æ®
        current_inventory = inv_metrics.get('latest', 0)
        inventory_percentile = inv_metrics.get('percentile', 0)
        recent_change = inv_metrics.get('recent_30d_change', 0)
        cycle_stage = inv_metrics.get('cycle_stage', 'æœªçŸ¥')
        cycle_meaning = inv_metrics.get('cycle_meaning', '')
        speculative_level = inv_metrics.get('speculative_level', 'æœªçŸ¥')
        speculative_meaning = inv_metrics.get('speculative_meaning', '')
        
        current_price = current_market.get('price', 0)
        price_change_30d = current_market.get('price_change_30d', 0)
        
        reflexivity_type = reflex_metrics.get('type', 'æœªçŸ¥')
        reflexivity_meaning = reflex_metrics.get('meaning', '')
        correlation = reflex_metrics.get('correlation', 0)
        
        # åŸºå·®æ•°æ®
        basis_data = cross_analysis.get('inventory_basis', {})
        basis_structure = basis_data.get('structure_type', 'æœªçŸ¥')
        basis_meaning = basis_data.get('meaning', '')
        
        # æŒä»“æ•°æ®
        position_data = cross_analysis.get('inventory_positioning', {})
        position_meaning = position_data.get('meaning', 'æŒä»“æ•°æ®ä¸å¯ç”¨')
        
        # æœŸé™ç»“æ„æ•°æ®
        term_data = cross_analysis.get('term_structure', {})
        term_structure = term_data.get('term_shape', 'æœŸé™ç»“æ„æ•°æ®ä¸å¯ç”¨')
        term_meaning = term_data.get('meaning', '')
        
        # æ•°æ®ç»´åº¦ç»Ÿè®¡
        data_dimensions = []
        if data.get('inventory') is not None:
            data_dimensions.append("åº“å­˜æ•°æ®")
        if data.get('receipt') is not None:
            data_dimensions.append("ä»“å•æ•°æ®")
        if data.get('price') is not None:
            data_dimensions.append("ä»·æ ¼æ•°æ®")
        if data.get('basis') is not None:
            data_dimensions.append("åŸºå·®æ•°æ®")
        if data.get('term_structure') is not None:
            data_dimensions.append("æœŸé™ç»“æ„æ•°æ®")
        if data.get('positioning') is not None:
            data_dimensions.append("æŒä»“æ•°æ®")
        
        # æ„å»ºç»ˆæåˆ†ææç¤ºè¯
        prompt = f"""
ä½ æ˜¯ä¸–ç•Œé¡¶çº§çš„æœŸè´§åŸºæœ¬é¢åˆ†æä¸“å®¶ï¼Œå…·æœ‰25å¹´ä¸“ä¸šç»éªŒã€‚ç°åœ¨éœ€è¦ä¸º{variety_name}({variety_code})æœŸè´§æ’°å†™ä¸€ä»½æŠ•èµ„æœºæ„çº§åˆ«çš„å¤šç»´åº¦åº“å­˜ä»“å•ä¸“ä¸šåˆ†ææŠ¥å‘Šã€‚

CRITICALè¦æ±‚ï¼š
1. ç»å¯¹ç¦æ­¢ä½¿ç”¨ä»»ä½•è‹±æ–‡å•è¯ã€çŸ­è¯­æˆ–è¡¨è¾¾ï¼Œå¿…é¡»ä½¿ç”¨çº¯ä¸­æ–‡
2. ç¦æ­¢å‡ºç°å¦‚"due to"ã€"contango"ã€"backwardation"ç­‰è‹±æ–‡æœ¯è¯­
3. æ‰€æœ‰ä¸“ä¸šæœ¯è¯­å¿…é¡»ç”¨ä¸­æ–‡è¡¨è¾¾ï¼Œå¦‚"è¿œæœŸå‡æ°´ç»“æ„"ã€"è¿‘æœŸè´´æ°´ç»“æ„"ç­‰
4. ä¸¥æ ¼é¿å…ä»»ä½•è‹±æ–‡ç¼©å†™æˆ–è‹±æ–‡è¡¨è¾¾

å“ç§åŸºæœ¬ä¿¡æ¯ï¼š
{variety_name}({variety_code})ï¼Œ{category}ç±»ï¼Œ{exchange}äº¤æ˜“æ‰€

å¤šç»´åº¦æ•°æ®åŸºç¡€ï¼š
å¯ç”¨æ•°æ®ç»´åº¦ï¼š{', '.join(data_dimensions)}
è”ç½‘æ•°æ®ä½¿ç”¨ï¼š{'æ˜¯' if data.get('online_data_used', False) else 'å¦'}

æ ¸å¿ƒåº“å­˜åˆ†æï¼š
å½“å‰åº“å­˜ï¼š{current_inventory:,.0f}ä¸‡å¨ï¼ˆå†å²{inventory_percentile:.1f}%åˆ†ä½æ•°ï¼‰
30æ—¥å˜åŒ–ï¼š{recent_change:+,.0f}ä¸‡å¨
åº“å­˜å‘¨æœŸï¼š{cycle_stage}
å‘¨æœŸå«ä¹‰ï¼š{cycle_meaning}
æŠ•æœºæ€§æ°´å¹³ï¼š{speculative_level}
æŠ•æœºæ€§ç‰¹å¾ï¼š{speculative_meaning}

ä»·æ ¼åèº«æ€§åˆ†æï¼š
å½“å‰ä»·æ ¼ï¼š{current_price:,.0f}å…ƒ/å¨
30æ—¥ä»·æ ¼å˜åŒ–ï¼š{price_change_30d:+,.0f}å…ƒ/å¨
åèº«æ€§ç±»å‹ï¼š{reflexivity_type}
åèº«æ€§å«ä¹‰ï¼š{reflexivity_meaning}
ä»·æ ¼åº“å­˜ç›¸å…³æ€§ï¼š{correlation:.3f}

å¤šç»´åº¦æ•°æ®éªŒè¯ï¼š
åŸºå·®ç»“æ„ï¼š{basis_structure} - {basis_meaning}
æŒä»“åˆ†æï¼š{position_meaning}
æœŸé™ç»“æ„ï¼š{term_structure} - {term_meaning}

å¸‚åœºèƒŒæ™¯ä¿¡æ¯ï¼š
{market_context.get('formatted_context', 'æ— è”ç½‘æ•°æ®') if isinstance(market_context, dict) else market_context}

è„šæ³¨å¼•ç”¨ä¿¡æ¯ï¼ˆAIåˆ†ææ—¶ä½¿ç”¨ï¼‰ï¼š
{chr(10).join([f'[{ref["id"]}] {ref["query_type"]}: {ref["title"]} - {ref["snippet"][:100]}...' for ref in (market_context.get('footnote_refs', []) if isinstance(market_context, dict) else [])])}

åˆ†æä»»åŠ¡è¦æ±‚ï¼š

è¯·æ’°å†™ä¸“ä¸šçš„{chinese_name}æœŸè´§å¤šç»´åº¦åº“å­˜ä»“å•åˆ†ææŠ¥å‘Šï¼Œé‡‡ç”¨ä»¥ä¸‹ç»“æ„ï¼š

ä¸€ã€æ ¸å¿ƒæŠ•èµ„è§‚ç‚¹
åŸºäºå¤šç»´åº¦æ•°æ®çš„ç»¼åˆåˆ¤æ–­
æ˜ç¡®çš„å¤šç©ºæ–¹å‘å»ºè®®
é‡åŒ–çš„ä¿¡å¿ƒæ°´å¹³è¯„ä¼°
å…³é”®é£é™©å› ç´ è¯†åˆ«

äºŒã€åº“å­˜æ·±åº¦è§£è¯»
1. åº“å­˜ç»å¯¹æ°´å¹³åˆ†æï¼šå†å²åˆ†ä½æ•°æ„ä¹‰ï¼Œä¾›éœ€çŠ¶æ€åˆ¤æ–­
2. åº“å­˜å˜åŒ–è¶‹åŠ¿è§£è¯»ï¼šç»“åˆåº“å­˜å‘¨æœŸç†è®ºçš„ä¸“ä¸šåˆ†æ
3. æŠ•æœºæ€§åº“å­˜è¯†åˆ«ï¼šåŒºåˆ†çœŸå®æ¶ˆè´¹éœ€æ±‚ä¸æŠ•æœºæ€§å›¤è´§
4. åº“å­˜åèº«æ€§å…³ç³»ï¼šæ·±åº¦ç†è§£åº“å­˜ä¸ä»·æ ¼çš„åŠ¨æ€å…³ç³»

ä¸‰ã€å¤šç»´åº¦äº¤å‰éªŒè¯åˆ†æ
1. åº“å­˜ä¸ä»·æ ¼èµ°åŠ¿çš„äº’åŠ¨å…³ç³»éªŒè¯
2. åŸºå·®ç»“æ„å¯¹åº“å­˜æ„ä¹‰çš„è¡¥å……éªŒè¯ï¼ˆå¦‚æœ‰æ•°æ®ï¼‰
3. æŒä»“ç»“æ„ä¸åº“å­˜å˜åŒ–çš„ååŒåˆ†æï¼ˆå¦‚æœ‰æ•°æ®ï¼‰
4. æœŸé™ç»“æ„å¯¹åº“å­˜é¢„æœŸçš„åæ˜ ï¼ˆå¦‚æœ‰æ•°æ®ï¼‰

å››ã€ä¾›éœ€æ ¼å±€æ·±åº¦å‰–æ
1. ä¾›ç»™ç«¯åˆ†æï¼šäº§èƒ½ã€å¼€å·¥ç‡ã€æˆæœ¬ã€æ”¿ç­–å½±å“
2. éœ€æ±‚ç«¯åˆ†æï¼šçœŸå®æ¶ˆè´¹ä¸æŠ•æœºéœ€æ±‚çš„åŒºåˆ†
3. åº“å­˜åœ¨ä¾›éœ€ä¼ å¯¼ä¸­çš„ä½œç”¨ï¼šè“„æ°´æ± åŠŸèƒ½åŠå…¶æ æ†æ•ˆåº”
4. ä¾›éœ€å¹³è¡¡çš„åŠ¨æ€æ¼”åŒ–è¶‹åŠ¿

äº”ã€å¸‚åœºå¾®è§‚ç»“æ„åˆ†æ
1. è´§æƒåˆ†å¸ƒçŠ¶å†µï¼šåº“å­˜é›†ä¸­åº¦åŠå…¶å¸‚åœºå½±å“
2. äº§ä¸šé“¾åº“å­˜ç»“æ„ï¼šå·¥å‚åº“å­˜ä¸ç¤¾ä¼šåº“å­˜çš„å·®å¼‚åŒ–å«ä¹‰
3. éšæ€§åº“å­˜æ˜¾æ€§åŒ–é£é™©è¯„ä¼°
4. åº“å­˜æµåŠ¨æ€§å’Œå˜ç°èƒ½åŠ›åˆ†æ

å…­ã€æŠ•èµ„ç­–ç•¥åˆ¶å®š
1. åŸºäºåº“å­˜åˆ†æçš„æ€»ä½“ç­–ç•¥æ–¹å‘
2. å…·ä½“æ“ä½œå»ºè®®ï¼šè¿›åœºæ—¶æœºã€ä»“ä½é…ç½®ã€æŒä»“å‘¨æœŸ
3. å…³é”®ä»·ä½è¯†åˆ«ï¼šæ”¯æ’‘é˜»åŠ›ä½çš„åº“å­˜é€»è¾‘æ”¯æ’‘
4. åŠ¨æ€è°ƒæ•´æ¡ä»¶ï¼šåº“å­˜æ‹ç‚¹åŠç­–ç•¥åˆ‡æ¢ä¿¡å·

ä¸ƒã€é£é™©ç®¡ç†è¦ç‚¹
1. åº“å­˜åˆ†æçš„å±€é™æ€§å’Œç›²ç‚¹
2. åèº«æ€§å…³ç³»å˜åŒ–çš„é£é™©é¢„è­¦
3. æ”¿ç­–å’Œçªå‘äº‹ä»¶å¯¹åº“å­˜é€»è¾‘çš„å†²å‡»
4. æŒç»­ç›‘æ§çš„å…³é”®æŒ‡æ ‡è®¾å®š

æ’°å†™è¦æ±‚ï¼š
1. ä½“ç°å¯¹åº“å­˜æœ¬è´¨çš„æ·±åº¦ç†è§£ï¼Œé¿å…æŒ‡æ ‡åŒ–å¤„ç†
2. é‡ç‚¹é˜è¿°åº“å­˜ä¸ä»·æ ¼çš„åèº«æ€§å…³ç³»
3. ç»“åˆå¤šç»´åº¦æ•°æ®è¿›è¡Œäº¤å‰éªŒè¯
4. æä¾›å…·ä½“å¯æ“ä½œçš„æŠ•èµ„å»ºè®®
5. ä¿æŒä¸“ä¸šå®¢è§‚çš„åˆ†ææ€åº¦
6. ç»å¯¹ç¦æ­¢ä½¿ç”¨ä»»ä½•è‹±æ–‡è¡¨è¾¾ï¼Œå¿…é¡»çº¯ä¸­æ–‡
7. å­—æ•°æ§åˆ¶åœ¨2800-3200å­—
8. ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„ä¸­æ–‡æœ¯è¯­
9. **é‡è¦**ï¼šå¿…é¡»åœ¨æŠ¥å‘Šä¸­è‡ªç„¶å¼•ç”¨è”ç½‘æœç´¢è·å–çš„å¸‚åœºä¿¡æ¯ï¼Œä½¿ç”¨è„šæ³¨æ ‡æ³¨æ–¹å¼å¦‚[1] [2] [3]ç­‰ï¼Œé¿å…ä½¿ç”¨"æ®è”ç½‘æ•°æ®æ˜¾ç¤º"ç­‰ä¸å¤Ÿä¸“ä¸šçš„è¡¨è¿°
10. **é‡è¦**ï¼šæ‰€æœ‰è”ç½‘è·å–çš„ä¿¡æ¯éƒ½è¦ç”¨è„šæ³¨æ ‡è®°ï¼Œå¹¶åœ¨æ–‡æœ«"å‚è€ƒèµ„æ–™"éƒ¨åˆ†æŒ‰ç¼–å·åˆ—å‡ºå…·ä½“çš„ä¿¡æ¯æ¥æºé“¾æ¥å’Œè·å–æ—¶é—´

è¯·å¼€å§‹æ’°å†™çº¯ä¸­æ–‡ä¸“ä¸šåˆ†ææŠ¥å‘Šï¼Œç›´æ¥ä»æ ‡é¢˜å’Œå†…å®¹å¼€å§‹ï¼Œç¦æ­¢ä»»ä½•AIæè¿°æ€§å¼•å¯¼è¯­ï¼š
"""
        
        return prompt
    
    def call_deepseek_ultimate(self, prompt):
        """è°ƒç”¨DeepSeekè¿›è¡Œç»ˆæåˆ†æ"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.deepseek_api_key}"
        }
        
        system_content = """ä½ æ˜¯ä¸–ç•Œé¡¶çº§çš„æœŸè´§åŸºæœ¬é¢åˆ†æä¸“å®¶ï¼Œå…·æœ‰25å¹´ä¸“ä¸šç»éªŒå’Œæ·±åº¦æ¨ç†èƒ½åŠ›ã€‚

ä½ çš„æ ¸å¿ƒä¸“ä¸šç‰¹é•¿ï¼š
1. åº“å­˜æ•°æ®çš„æ·±åº¦ç†è§£å’Œåèº«æ€§å…³ç³»åˆ†æ
2. æŠ•æœºæ€§åº“å­˜ä¸çœŸå®æ¶ˆè´¹éœ€æ±‚çš„å‡†ç¡®åŒºåˆ†
3. åº“å­˜å‘¨æœŸç†è®ºçš„å®æˆ˜åº”ç”¨
4. å¤šç»´åº¦æ•°æ®çš„äº¤å‰éªŒè¯åˆ†æèƒ½åŠ›
5. å¸‚åœºå¾®è§‚ç»“æ„å’Œäº§ä¸šé“¾åˆ†æ
6. åŸºäºåº“å­˜åˆ†æçš„ç²¾å‡†æŠ•èµ„ç­–ç•¥åˆ¶å®š

CRITICALè¯­è¨€è¦æ±‚ï¼š
- ç»å¯¹ç¦æ­¢ä½¿ç”¨ä»»ä½•è‹±æ–‡å•è¯ã€çŸ­è¯­ã€æœ¯è¯­æˆ–ç¼©å†™
- å¿…é¡»ä½¿ç”¨çº¯æ­£çš„ä¸­æ–‡ä¸“ä¸šæœ¯è¯­
- æ‰€æœ‰åˆ†æå†…å®¹å¿…é¡»ç”¨ä¸­æ–‡è¡¨è¾¾
- ä¸“ä¸šæœ¯è¯­ä¸­æ–‡åŒ–ï¼Œå¦‚è¿œæœŸå‡æ°´ã€è¿‘æœŸè´´æ°´ã€æ­£å‘å¸‚åœºã€åå‘å¸‚åœºç­‰

CRITICALè”ç½‘æ•°æ®å¼•ç”¨è¦æ±‚ï¼š
- å¿…é¡»è‡ªç„¶èå…¥è”ç½‘æœç´¢è·å–çš„å¸‚åœºä¿¡æ¯ï¼Œç¦ç”¨"æ®è”ç½‘æ•°æ®æ˜¾ç¤º"ç­‰è¡¨è¿°
- æ‰€æœ‰è”ç½‘è·å–çš„ä¿¡æ¯ä½¿ç”¨è„šæ³¨æ ‡è®°æ–¹å¼ï¼š[1] [2] [3]ç­‰
- å¯¹å…³é”®å¸‚åœºä¿¡æ¯ï¼ˆäº§èƒ½åˆ©ç”¨ç‡ã€å¼€å·¥ç‡ã€éœ€æ±‚çŠ¶å†µã€åº“å­˜åˆ†ç±»ç­‰ï¼‰è¿›è¡Œè„šæ³¨æ ‡æ³¨
- åœ¨æŠ¥å‘Šæœ«å°¾å¢è®¾"å‚è€ƒèµ„æ–™"éƒ¨åˆ†ï¼ŒæŒ‰è„šæ³¨ç¼–å·åˆ—å‡ºä¿¡æ¯æ¥æºé“¾æ¥å’Œè·å–æ—¶é—´
- ç¡®ä¿æ‰€æœ‰è„šæ³¨ä¿¡æ¯å…·æœ‰æ—¶æ•ˆæ€§å’Œç›¸å…³æ€§

é‡è¦ç†å¿µè¦æ±‚ï¼š
- ç†è§£åº“å­˜ä¸ä»·æ ¼çš„å¤æ‚åèº«æ€§å…³ç³»ï¼Œæ‘†è„±ç®€å•çš„è´Ÿç›¸å…³æ€ç»´
- åŒºåˆ†æŠ•æœºæ€§åº“å­˜å’ŒçœŸå®æ¶ˆè´¹éœ€æ±‚çš„ä¸åŒå¸‚åœºå«ä¹‰
- ç»“åˆåº“å­˜å‘¨æœŸç†è®ºè¿›è¡ŒåŠ¨æ€åˆ†æ
- å¤šç»´åº¦æ•°æ®äº¤å‰éªŒè¯ï¼Œé¿å…å•ä¸€æŒ‡æ ‡è¯¯åˆ¤
- æ·±åº¦ç†è§£åº“å­˜ä½œä¸ºä¾›éœ€è“„æ°´æ± çš„æ æ†æ•ˆåº”
- å……åˆ†åˆ©ç”¨è”ç½‘å¸‚åœºä¿¡æ¯å¢å¼ºåˆ†æçš„å…¨é¢æ€§å’Œæ—¶æ•ˆæ€§

è¯·è¿ç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†å’Œæ·±åº¦æ¨ç†èƒ½åŠ›ï¼Œæ’°å†™ä¸€ä»½ä½“ç°åº“å­˜åˆ†æç²¾é«“çš„çº¯ä¸­æ–‡ä¸“ä¸šæŠ¥å‘Šã€‚"""
        
        data = {
            "model": "deepseek-reasoner",
            "messages": [
                {"role": "system", "content": system_content},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 12000,
            "temperature": 0.1
        }
        
        try:
            print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨DeepSeek Reasonerè¿›è¡Œç»ˆææ·±åº¦åˆ†æ...")
            response = requests.post(self.deepseek_base_url,
                                   headers=headers,
                                   json=data,
                                   timeout=180)
            response.raise_for_status()
            result = response.json()['choices'][0]['message']['content']
            print("âœ… AIç»ˆææ·±åº¦åˆ†æå®Œæˆ")
            return result
            
        except Exception as e:
            print(f"âŒ Reasoneråˆ†æå¤±è´¥ï¼Œå°è¯•Chatæ¨¡å¼: {e}")
            # é™çº§åˆ°chatæ¨¡å¼
            data["model"] = "deepseek-chat"
            data["max_tokens"] = 6000
            try:
                response = requests.post(self.deepseek_base_url,
                                       headers=headers,
                                       json=data,
                                       timeout=120)
                response.raise_for_status()
                result = response.json()['choices'][0]['message']['content']
                print("âœ… AI Chatæ¨¡å¼åˆ†æå®Œæˆ")
                return result
            except Exception as e2:
                return f"AIç»ˆæåˆ†æç”Ÿæˆå¤±è´¥: {e2}"
    
    def ultimate_comprehensive_analysis(self, variety_name):
        """æ‰§è¡Œç»ˆæç»¼åˆåˆ†æ"""
        print("="*80)
        print(f"ğŸš€ {variety_name} ä¸“ä¸šåº“å­˜ä»“å•AIåˆ†æï¼ˆç»ˆæå®Œå–„ç‰ˆï¼‰")
        print("="*80)
        
        # 1. åŠ è½½å¤šç»´åº¦æ•°æ®
        data = self.load_multi_dimensional_data(variety_name)
        
        # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
        has_inventory = data.get('inventory') is not None and not data['inventory'].empty
        has_any_data = any([
            data.get('inventory') is not None and not data['inventory'].empty,
            data.get('receipt') is not None and not data['receipt'].empty,
            data.get('price') is not None and not data['price'].empty
        ])
        
        if not has_any_data:
            return {
                "error": "æ— æœ‰æ•ˆæ•°æ®å¯ä¾›ç»ˆæåˆ†æ",
                "variety": variety_name,
                "data_sources": data.get('data_sources', [])
            }
        
        # 2. è®¡ç®—å¤šç»´åº¦åˆ†ææŒ‡æ ‡
        print("ğŸ“ˆ æ­£åœ¨è®¡ç®—å¤šç»´åº¦åˆ†ææŒ‡æ ‡...")
        metrics = self.calculate_multi_dimensional_metrics(data)
        
        # 3. ç”Ÿæˆä¸“ä¸šå›¾è¡¨ï¼ˆPlotlyå¯¹è±¡ï¼‰
        print("ğŸ“Š æ­£åœ¨ç”Ÿæˆä¸“ä¸šåˆ†æå›¾è¡¨...")
        charts = self.generate_professional_charts(variety_name, data, metrics)
        charts_html = charts  # Plotlyå›¾è¡¨å¯¹è±¡ç›´æ¥ç”¨äºStreamlitæ˜¾ç¤º
        
        # 4. è·å–ç»¼åˆå¸‚åœºèƒŒæ™¯
        print("ğŸŒ æ­£åœ¨è·å–å¤šç»´åº¦å¸‚åœºèƒŒæ™¯ä¿¡æ¯...")
        market_context = self.get_comprehensive_market_context(variety_name)
        
        # 5. æ„å»ºç»ˆæåˆ†ææç¤ºè¯
        print("ğŸ“ æ­£åœ¨æ„å»ºç»ˆæä¸“ä¸šåˆ†ææ¡†æ¶...")
        prompt = self.build_ultimate_analysis_prompt(variety_name, metrics, market_context, data)
        
        # 6. AIç»ˆææ·±åº¦åˆ†æ
        print("ğŸ¤– æ­£åœ¨è¿›è¡ŒAIç»ˆæä¸“ä¸šæ·±åº¦åˆ†æ...")
        ai_analysis = self.call_deepseek_ultimate(prompt)
        
        # 7. æ„å»ºåˆ†æç»“æœï¼ˆå…ƒæ•°æ®åç½®ï¼‰
        result = {
            "variety_name": variety_name,
            "professional_analysis": ai_analysis,  # ä¸»ä½“å†…å®¹å‰ç½®
            "charts": charts,
            "charts_html": charts_html,  # Plotlyå¯¹è±¡ç”¨äºStreamlitæ˜¾ç¤º
            "market_context": market_context,
            
            # ä»¥ä¸‹ä¸ºåç½®çš„å…ƒæ•°æ®ä¿¡æ¯
            "variety_info": data['variety_info'],
            "multi_dimensional_metrics": metrics,
            "analysis_metadata": {
                "version": "v8.0 Ultimate Perfection",
                "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "data_dimensions": [dim for dim in ['inventory', 'receipt', 'price', 'basis', 'term_structure', 'positioning'] if data.get(dim) is not None],
                "confidence_level": "é«˜",
                "online_data_used": data.get('online_data_used', False),
                "analysis_completeness": "å®Œæ•´" if has_inventory else "éƒ¨åˆ†",
                "charts_generated": len(charts)
            },
            "data_summary": {
                "inventory_points": len(data['inventory']) if data['inventory'] is not None else 0,
                "receipt_available": data.get('receipt') is not None and not data['receipt'].empty,
                "receipt_points": len(data['receipt']) if data['receipt'] is not None else 0,
                "price_points": len(data['price']) if data['price'] is not None else 0,
                "basis_points": len(data['basis']) if data['basis'] is not None else 0,
                "term_structure_points": len(data['term_structure']) if data['term_structure'] is not None else 0,
                "positioning_points": len(data['positioning']) if data['positioning'] is not None else 0,
                "analysis_date": datetime.now().strftime('%Y-%m-%d'),
                "data_sources": data.get('data_sources', [])
            }
        }
        
        return result
    
    def display_ultimate_result(self, result):
        """æ˜¾ç¤ºç»ˆæåˆ†æç»“æœï¼ˆå…ƒæ•°æ®åç½®ï¼‰"""
        if "error" in result:
            print(f"âŒ åˆ†æå¤±è´¥: {result['error']}")
            if result.get('data_sources'):
                print("æ•°æ®æ¥æºå°è¯•:")
                for source in result['data_sources']:
                    print(f"  - {source}")
            return
        
        print("\n" + "="*80)
        print(f"ğŸ“‹ {result['variety_name']} ä¸“ä¸šåº“å­˜ä»“å•AIåˆ†ææŠ¥å‘Š")
        print("="*80)
        
        # ä¸»ä½“å†…å®¹ï¼ˆAIåˆ†ææŠ¥å‘Šï¼‰ç›´æ¥æ˜¾ç¤º
        print(result['professional_analysis'])
        
        # å›¾è¡¨ä¿¡æ¯å¢å¼ºæ˜¾ç¤º
        if result.get('charts'):
            print("\n" + "="*80)
            print("ğŸ“Š ä¸“ä¸šå›¾è¡¨åˆ†æç»“æœ")
            print("="*80)
            
            charts_dict = result['charts']
            if isinstance(charts_dict, dict):
                for i, (chart_name, chart_obj) in enumerate(charts_dict.items(), 1):
                    print(f"\n{i}. ã€{chart_name}ã€‘")
                    print(f"   å›¾è¡¨ç±»å‹: Plotlyäº¤äº’å¼å›¾è¡¨")
                    print(f"   å›¾è¡¨çŠ¶æ€: å·²ç”Ÿæˆï¼Œå¯åœ¨Streamlitç³»ç»Ÿä¸­æŸ¥çœ‹")
                    print(f"   å›¾è¡¨è¯´æ˜: ä¸“ä¸šçº§æŠ€æœ¯åˆ†æå›¾è¡¨ï¼ŒåŒ…å«è¶‹åŠ¿çº¿ã€æŠ€æœ¯æŒ‡æ ‡å’Œäº¤äº’åŠŸèƒ½")
                    if 'åº“å­˜è¶‹åŠ¿' in chart_name:
                        print(f"   åˆ†æè¦ç‚¹: æ˜¾ç¤ºåº“å­˜ç»å¯¹æ°´å¹³ã€ç§»åŠ¨å¹³å‡çº¿ã€å†å²åˆ†ä½æ•°å‚è€ƒçº¿")
                    elif 'ä»·æ ¼èµ°åŠ¿å¯¹æ¯”' in chart_name:
                        print(f"   åˆ†æè¦ç‚¹: åº“å­˜ä¸ä»·æ ¼èµ°åŠ¿çš„ç›´è§‚å¯¹æ¯”ï¼Œä¾¿äºåˆ†æä¸¤è€…å…³ç³»")
                    elif 'åèº«æ€§' in chart_name:
                        print(f"   åˆ†æè¦ç‚¹: å±•ç°ä»·æ ¼ä¸åº“å­˜çš„åŠ¨æ€å…³ç³»ï¼ŒéªŒè¯åèº«æ€§ç†è®º")
                    elif 'å‘¨æœŸ' in chart_name:
                        print(f"   åˆ†æè¦ç‚¹: åº“å­˜å‘¨æœŸé˜¶æ®µè¯†åˆ«ï¼Œå˜åŒ–ç‡åˆ†æï¼Œè¶‹åŠ¿æ‹ç‚¹æ ‡æ³¨")
            else:
                print(f"   âš ï¸ å›¾è¡¨æ ¼å¼å¼‚å¸¸: {type(charts_dict)}")
        
        # å‚è€ƒèµ„æ–™ä¿¡æ¯ï¼ˆå¦‚æœ‰è”ç½‘æ•°æ®ï¼‰
        market_context = result.get('market_context', {})
        if isinstance(market_context, dict) and market_context.get('footnote_refs'):
            print("\n" + "="*80)
            print("ğŸ“š å‚è€ƒèµ„æ–™")
            print("="*80)
            for ref in market_context['footnote_refs']:
                print(f"[{ref['id']}] {ref['title']}")
                print(f"    ç±»å‹: {ref['query_type']}")
                print(f"    é“¾æ¥: {ref['link']}")
                print(f"    è·å–æ—¶é—´: {ref['fetch_time']}")
                print(f"    æ‘˜è¦: {ref['snippet']}")
                print()
        
        # å…ƒæ•°æ®ä¿¡æ¯ï¼ˆç§»è‡³æœ€åï¼‰
        print("\n" + "="*80)
        print("ğŸ“Š åˆ†ææŠ€æœ¯ä¿¡æ¯")
        print("="*80)
        
        metadata = result.get('analysis_metadata', {})
        print(f"åˆ†æç‰ˆæœ¬: {metadata.get('version', 'Unknown')}")
        print(f"æ•°æ®ç»´åº¦: {len(metadata.get('data_dimensions', []))}ä¸ªç»´åº¦")
        print(f"è”ç½‘æ•°æ®: {'æ˜¯' if metadata.get('online_data_used', False) else 'å¦'}")
        print(f"åˆ†æå®Œæ•´æ€§: {metadata.get('analysis_completeness', 'Unknown')}")
        print(f"ç”Ÿæˆå›¾è¡¨: {metadata.get('charts_generated', 0)}ä¸ª")
        
        summary = result['data_summary']
        print(f"\næ•°æ®ç»Ÿè®¡:")
        print(f"åº“å­˜æ•°æ®: {summary['inventory_points']} ä¸ªæ•°æ®ç‚¹")
        print(f"ä»“å•æ•°æ®: {'å¯ç”¨' if summary['receipt_available'] else 'ä¸å¯ç”¨'}")
        print(f"ä»·æ ¼æ•°æ®: {summary['price_points']} ä¸ªæ•°æ®ç‚¹")
        print(f"åˆ†ææ—¥æœŸ: {summary['analysis_date']}")
        
        print("\n" + "="*80)
        print("ğŸ“„ ç»ˆæå®Œå–„ç‰ˆåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        print("="*80)
    
    def export_ultimate_report(self, result, output_dir=None):
        """å¯¼å‡ºç»ˆæä¸“ä¸šåˆ†ææŠ¥å‘Šï¼ˆå…ƒæ•°æ®åç½®ï¼‰"""
        if "error" in result:
            print("âŒ æ— æ³•å¯¼å‡ºï¼Œåˆ†æç»“æœåŒ…å«é”™è¯¯")
            return None
        
        if output_dir is None:
            output_dir = Path("ultimate_reports")
        else:
            output_dir = Path(output_dir)
        
        output_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{result['variety_name']}_ç»ˆæåº“å­˜ä»“å•AIåˆ†ææŠ¥å‘Š_{timestamp}.txt"
        filepath = output_dir / filename
        
        # å†™å…¥ç»ˆæä¸“ä¸šæŠ¥å‘Šï¼ˆå…ƒæ•°æ®åç½®ï¼‰
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"{result['variety_name']} ä¸“ä¸šåº“å­˜ä»“å•AIåˆ†ææŠ¥å‘Š\n")
            f.write("="*80 + "\n\n")
            
            # ä¸»ä½“å†…å®¹ï¼ˆAIä¸“ä¸šåˆ†æï¼‰å‰ç½®
            f.write(result['professional_analysis'])
            f.write("\n\n")
            
            # å›¾è¡¨ä¿¡æ¯
            if result.get('charts'):
                f.write("ç”Ÿæˆçš„ä¸“ä¸šå›¾è¡¨\n")
                f.write("-" * 40 + "\n")
                for i, chart in enumerate(result['charts'], 1):
                    chart_name = Path(chart).name
                    f.write(f"{i}. {chart_name} - {chart}\n")
                f.write("\n")
            
            # å‚è€ƒèµ„æ–™
            market_context = result.get('market_context', {})
            if isinstance(market_context, dict) and market_context.get('footnote_refs'):
                f.write("å‚è€ƒèµ„æ–™\n")
                f.write("-" * 40 + "\n")
                for ref in market_context['footnote_refs']:
                    f.write(f"[{ref['id']}] {ref['title']}\n")
                    f.write(f"    ç±»å‹ï¼š{ref['query_type']}\n")
                    f.write(f"    é“¾æ¥ï¼š{ref['link']}\n")
                    f.write(f"    è·å–æ—¶é—´ï¼š{ref['fetch_time']}\n")
                    f.write(f"    æ‘˜è¦ï¼š{ref['snippet']}\n\n")
            
            # å¸‚åœºèƒŒæ™¯ä¿¡æ¯
            if result.get('market_context'):
                f.write("å¤šç»´åº¦å¸‚åœºèƒŒæ™¯ä¿¡æ¯\n")
                f.write("-" * 40 + "\n")
                if isinstance(market_context, dict):
                    f.write(market_context.get('formatted_context', ''))
                else:
                    f.write(result['market_context'])
                f.write("\n\n")
            
            # æŠ€æœ¯ä¿¡æ¯ï¼ˆå…ƒæ•°æ®åç½®ï¼‰
            f.write("="*80 + "\n")
            f.write("åˆ†ææŠ€æœ¯ä¿¡æ¯\n")
            f.write("="*80 + "\n")
            
            metadata = result.get('analysis_metadata', {})
            f.write(f"åˆ†æç‰ˆæœ¬ï¼š{metadata.get('version', 'Unknown')}\n")
            f.write(f"åˆ†ææ—¶é—´ï¼š{metadata.get('timestamp', 'Unknown')}\n")
            f.write(f"æ•°æ®ç»´åº¦ï¼š{len(metadata.get('data_dimensions', []))}ä¸ªç»´åº¦ - {', '.join(metadata.get('data_dimensions', []))}\n")
            f.write(f"è”ç½‘æ•°æ®ä½¿ç”¨ï¼š{'æ˜¯' if metadata.get('online_data_used', False) else 'å¦'}\n")
            f.write(f"åˆ†æå®Œæ•´æ€§ï¼š{metadata.get('analysis_completeness', 'Unknown')}\n")
            f.write(f"ç”Ÿæˆå›¾è¡¨ï¼š{metadata.get('charts_generated', 0)}ä¸ª\n\n")
            
            # æ•°æ®ç»Ÿè®¡ï¼ˆæœ€åï¼‰
            summary = result['data_summary']
            f.write("æ•°æ®ç»Ÿè®¡ä¿¡æ¯\n")
            f.write("-" * 40 + "\n")
            f.write(f"åº“å­˜æ•°æ®ï¼š{summary['inventory_points']} ä¸ªæ•°æ®ç‚¹\n")
            f.write(f"ä»“å•æ•°æ®ï¼š{'å¯ç”¨' if summary['receipt_available'] else 'ä¸å¯ç”¨'}ï¼Œ{summary['receipt_points']} ä¸ªæ•°æ®ç‚¹\n")
            f.write(f"ä»·æ ¼æ•°æ®ï¼š{summary['price_points']} ä¸ªæ•°æ®ç‚¹\n")
            if summary['basis_points'] > 0:
                f.write(f"åŸºå·®æ•°æ®ï¼š{summary['basis_points']} ä¸ªæ•°æ®ç‚¹\n")
            if summary['term_structure_points'] > 0:
                f.write(f"æœŸé™ç»“æ„æ•°æ®ï¼š{summary['term_structure_points']} ä¸ªæ•°æ®ç‚¹\n")
            if summary['positioning_points'] > 0:
                f.write(f"æŒä»“æ•°æ®ï¼š{summary['positioning_points']} ä¸ªæ•°æ®ç‚¹\n")
            f.write(f"åˆ†ææ—¥æœŸï¼š{summary['analysis_date']}\n\n")
            
            if summary.get('data_sources'):
                f.write("æ•°æ®æ¥æºè¯¦æƒ…\n")
                f.write("-" * 40 + "\n")
                for i, source in enumerate(summary['data_sources'], 1):
                    f.write(f"{i}. {source}\n")
                f.write("\n")
            
            f.write("-" * 80 + "\n")
            f.write("å…è´£å£°æ˜ï¼šæœ¬æŠ¥å‘ŠåŸºäºå¤šç»´åº¦æ•°æ®åˆ†æï¼Œç»“åˆä¸“ä¸šåº“å­˜ç†è®ºæ¡†æ¶ï¼Œä½†ä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚\n")
            f.write("å¸‚åœºæœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚è¯·ç†è§£åº“å­˜ä¸ä»·æ ¼çš„åèº«æ€§å…³ç³»ï¼Œé¿å…æœºæ¢°åŒ–åº”ç”¨ã€‚\n")
        
        print(f"âœ… ç»ˆæä¸“ä¸šåˆ†ææŠ¥å‘Šå·²å¯¼å‡º: {filepath}")
        return filepath
    
    # ä¸ºStreamlitç³»ç»Ÿæä¾›å…¼å®¹æ¥å£
    def analyze_variety_comprehensive(self, variety: str, analysis_date: str = None) -> dict:
        """
        ä¸ºStreamlitç³»ç»Ÿæä¾›çš„å…¼å®¹æ¥å£
        
        Args:
            variety: å“ç§åç§°
            analysis_date: åˆ†ææ—¥æœŸï¼ˆå¯é€‰ï¼‰
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            result = self.ultimate_comprehensive_analysis(variety)
            
            # è½¬æ¢ä¸ºStreamlitç³»ç»Ÿå…¼å®¹çš„æ ¼å¼
            if "error" in result:
                return {
                    "analysis_content": f"åˆ†æå¤±è´¥ï¼š{result['error']}",
                    "confidence_score": 0.0,
                    "result_data": result
                }
            
            return {
                "analysis_content": result['professional_analysis'],
                "confidence_score": 0.85,  # å›ºå®šé«˜ç½®ä¿¡åº¦
                "result_data": {
                    **result,
                    "charts_html": result.get('charts_html', {}),  # ç¡®ä¿Plotlyå›¾è¡¨å¯¹è±¡æ­£ç¡®ä¼ é€’
                },
                "charts": result.get('charts', {}),
                "charts_html": result.get('charts_html', {}),
                "variety_name": result['variety_name']
            }
            
        except Exception as e:
            return {
                "analysis_content": f"ç³»ç»Ÿåˆ†æå¼‚å¸¸ï¼š{str(e)}",
                "confidence_score": 0.0,
                "result_data": {"error": str(e)}
            }


def main():
    """ä¸»å‡½æ•°"""
    try:
        analyzer = UltimatePerfectedInventoryAnalyzer()
        
        print("\n" + "="*80)
        print("ğŸš€ ä¸“ä¸šåº“å­˜ä»“å•AIåˆ†æç³»ç»Ÿ - ç»ˆæå®Œå–„ç‰ˆ")
        print("="*80)
        print("ğŸ’¡ å…ƒæ•°æ®ä¿¡æ¯å®Œå…¨åç½®ï¼Œå¼€å¤´ç›´æ¥åˆ†æå†…å®¹")
        print("ğŸš« ä¸¥ç¦ä»»ä½•è‹±æ–‡ï¼Œçº¯ä¸­æ–‡ä¸“ä¸šè¡¨è¾¾")
        print("ğŸ“Š ä¸“ä¸šå›¾è¡¨ç”ŸæˆåŠŸèƒ½")
        print("ğŸ”— å®Œå…¨å…¼å®¹Streamlitç³»ç»Ÿè°ƒç”¨")
        print("âš¡ äº”ç»´æ•°æ®æ•´åˆ + åº“å­˜åèº«æ€§å…³ç³»æ·±åº¦è§£è¯»")
        print("ğŸ¤– DeepSeek Reasoneræ¨ç†æ¨¡å¼")
        print("="*80)
        
        available_varieties = list(analyzer.variety_mapping.keys())
        
        while True:
            print(f"\nğŸ“‹ å¯åˆ†æå“ç§ ({len(available_varieties)}ä¸ª):")
            for i, variety in enumerate(available_varieties, 1):
                info = analyzer.variety_mapping[variety]
                print(f"{i:2d}. {variety} ({info['code']}) - {info['category']} - {info['exchange']}")
            
            print("\nåŠŸèƒ½é€‰æ‹©:")
            print("1. é€‰æ‹©å“ç§è¿›è¡Œç»ˆæä¸“ä¸šåˆ†æ")
            print("2. å¯¼å‡ºæœ€è¿‘åˆ†ææŠ¥å‘Š")
            print("3. æµ‹è¯•Streamlitç³»ç»Ÿå…¼å®¹æ€§")
            print("4. é€€å‡ºç³»ç»Ÿ")
            print("-" * 40)
            
            choice = input("è¯·é€‰æ‹©åŠŸèƒ½ (1-4): ").strip()
            
            if choice == "1":
                variety_input = input(f"\nè¯·è¾“å…¥å“ç§åç§°æˆ–åºå·: ").strip()
                
                # è§£æè¾“å…¥
                if variety_input.isdigit():
                    idx = int(variety_input) - 1
                    if 0 <= idx < len(available_varieties):
                        variety_name = available_varieties[idx]
                    else:
                        print("âŒ æ— æ•ˆçš„åºå·")
                        continue
                else:
                    variety_name = variety_input
                
                if variety_name not in available_varieties:
                    print(f"âŒ ä¸æ”¯æŒçš„å“ç§: {variety_name}")
                    continue
                
                # æ‰§è¡Œç»ˆæä¸“ä¸šåˆ†æ
                result = analyzer.ultimate_comprehensive_analysis(variety_name)
                analyzer.last_result = result  # ä¿å­˜ç»“æœ
                
                # æ˜¾ç¤ºç»“æœ
                analyzer.display_ultimate_result(result)
                
            elif choice == "2":
                if hasattr(analyzer, 'last_result'):
                    output_dir = input("è¾“å…¥å¯¼å‡ºç›®å½• (å›è½¦ä½¿ç”¨é»˜è®¤): ").strip()
                    if not output_dir:
                        output_dir = None
                    analyzer.export_ultimate_report(analyzer.last_result, output_dir)
                else:
                    print("âŒ æ²¡æœ‰å¯å¯¼å‡ºçš„åˆ†æç»“æœï¼Œè¯·å…ˆè¿›è¡Œåˆ†æ")
                    
            elif choice == "3":
                # æµ‹è¯•Streamlitç³»ç»Ÿå…¼å®¹æ€§
                test_variety = "èšæ°¯ä¹™çƒ¯"
                print(f"\nğŸ§ª æµ‹è¯•Streamlitå…¼å®¹æ¥å£...")
                compat_result = analyzer.analyze_variety_comprehensive(test_variety)
                print(f"âœ… å…¼å®¹æ€§æµ‹è¯•å®Œæˆ")
                print(f"   ç½®ä¿¡åº¦: {compat_result['confidence_score']}")
                print(f"   å†…å®¹é•¿åº¦: {len(compat_result['analysis_content'])}å­—ç¬¦")
                print(f"   å›¾è¡¨æ•°é‡: {len(compat_result.get('charts', []))}ä¸ª")
                    
            elif choice == "4":
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ä¸“ä¸šåº“å­˜ä»“å•AIåˆ†æç³»ç»Ÿï¼ˆç»ˆæå®Œå–„ç‰ˆï¼‰ï¼")
                break
                
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}")


def test_ultimate_analysis():
    """æµ‹è¯•ç»ˆæåˆ†æç³»ç»Ÿ"""
    print("=" * 70)
    print("ğŸ¯ æµ‹è¯•ä¸“ä¸šåº“å­˜ä»“å•åˆ†æç³»ç»Ÿï¼ˆç»ˆæå®Œå–„ç‰ˆï¼‰")
    print("=" * 70)
    
    try:
        analyzer = UltimatePerfectedInventoryAnalyzer()
        
        # æµ‹è¯•èšæ°¯ä¹™çƒ¯æœŸè´§åˆ†æ
        print("\nğŸ” æµ‹è¯•å“ç§: èšæ°¯ä¹™çƒ¯(V)")
        result = analyzer.ultimate_comprehensive_analysis("èšæ°¯ä¹™çƒ¯")
        
        if "error" not in result:
            print("\nâœ… ç»ˆæå®Œå–„ç‰ˆæ”¹è¿›æ•ˆæœéªŒè¯:")
            metadata = result.get('analysis_metadata', {})
            print(f"   ğŸ“Š æ•°æ®ç»´åº¦: {len(metadata.get('data_dimensions', []))}ä¸ª")
            print(f"   ğŸŒ è”ç½‘æ•°æ®: {'æ˜¯' if metadata.get('online_data_used', False) else 'å¦'}")
            print(f"   ğŸ¯ åˆ†æç‰ˆæœ¬: {metadata.get('version', 'Unknown')}")
            print(f"   ğŸ“ˆ ç”Ÿæˆå›¾è¡¨: {metadata.get('charts_generated', 0)}ä¸ª")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è‹±æ–‡
            analysis_text = result['professional_analysis']
            english_words = ['due to', 'contango', 'backwardation', 'and', 'the', 'of', 'to', 'in', 'for']
            found_english = [word for word in english_words if word in analysis_text.lower()]
            
            if found_english:
                print(f"   âš ï¸ å‘ç°è‹±æ–‡è¯æ±‡: {found_english}")
            else:
                print(f"   âœ… çº¯ä¸­æ–‡æ£€æŸ¥é€šè¿‡")
            
            # æ˜¾ç¤ºéƒ¨åˆ†åˆ†æå†…å®¹
            analysis_preview = result['professional_analysis'][:600] + "..." if len(result['professional_analysis']) > 600 else result['professional_analysis']
            print(f"\nğŸ“‹ ç»ˆæä¸“ä¸šåˆ†æé¢„è§ˆ:")
            print(f"   {analysis_preview}")
            
            # æµ‹è¯•Streamlitå…¼å®¹æ€§
            print(f"\nğŸ§ª Streamlitå…¼å®¹æ€§æµ‹è¯•:")
            compat_result = analyzer.analyze_variety_comprehensive("èšæ°¯ä¹™çƒ¯")
            print(f"   ç½®ä¿¡åº¦: {compat_result['confidence_score']}")
            print(f"   å›¾è¡¨æ•°é‡: {len(compat_result.get('charts', []))}ä¸ª")
            
            # å¯¼å‡ºæµ‹è¯•æŠ¥å‘Š
            analyzer.export_ultimate_report(result)
            
            print("\nğŸ‰ ç»ˆæå®Œå–„ç‰ˆä¸“ä¸šåˆ†æç³»ç»Ÿæµ‹è¯•æˆåŠŸï¼")
        else:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {result['error']}")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        test_ultimate_analysis()
    else:
        main()
