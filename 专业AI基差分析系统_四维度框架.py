#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸“ä¸šAIåŸºå·®åˆ†æç³»ç»Ÿ - åŸºäºæ·±åº¦ç†è®ºçš„å››ç»´åº¦åˆ†ææ¡†æ¶
é›†æˆå“è´¨ã€ç©ºé—´ã€æ—¶é—´ã€åº“å­˜å››å¤§ç»´åº¦åˆ†ææ¡†æ¶
ä¸¥ç¦æ•°æ®ç¼–é€ ï¼Œç¡®ä¿åˆ†æè¯šå®æ€§
"""

import pandas as pd
import numpy as np
from pathlib import Path
import json
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import warnings
import time
from dataclasses import dataclass
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import base64
from io import BytesIO

warnings.filterwarnings('ignore')

# é…ç½®å‚æ•°
DATA_ROOT = Path(r"D:\Cursor\cursoré¡¹ç›®\TradingAgent\qihuo\database")
OUTPUT_DIR = Path(r"D:\Cursor\cursoré¡¹ç›®\TradingAgent\qihuo\output")

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# APIé…ç½®
DEEPSEEK_API_KEY = "sk-293dec7fabb54606b4f8d4f606da3383"
DEEPSEEK_BASE_URL = "https://api.deepseek.com/v1/chat/completions"
SERPER_API_KEY = "d3654e36956e0bf331e901886c49c602cea72eb1"
SERPER_BASE_URL = "https://google.serper.dev/search"

# å“ç§ä¸­æ–‡åç§°æ˜ å°„ï¼ˆæ‰©å±•ç‰ˆ - æ”¯æŒæ›´å¤šå“ç§ï¼‰
VARIETY_NAMES = {
    # è´µé‡‘å±
    'AU': 'é»„é‡‘', 'AG': 'ç™½é“¶',
    
    # æœ‰è‰²é‡‘å±  
    'CU': 'æ²ªé“œ', 'AL': 'æ²ªé“', 'ZN': 'æ²ªé”Œ', 'PB': 'æ²ªé“…', 'NI': 'æ²ªé•', 'SN': 'æ²ªé”¡',
    'BC': 'å›½é™…é“œ', 'AO': 'æ°§åŒ–é“',
    
    # é»‘è‰²é‡‘å±
    'RB': 'èºçº¹é’¢', 'HC': 'çƒ­è½§å·æ¿', 'I': 'é“çŸ¿çŸ³', 'JM': 'ç„¦ç…¤', 'J': 'ç„¦ç‚­', 
    'SS': 'ä¸é”ˆé’¢', 'WR': 'çº¿æ', 'FG': 'ç»ç’ƒ', 'SA': 'çº¯ç¢±',
    
    # èƒ½æºåŒ–å·¥
    'SC': 'åŸæ²¹', 'FU': 'ç‡ƒæ–™æ²¹', 'LU': 'ä½ç¡«ç‡ƒæ–™æ²¹', 'BU': 'æ²¥é’', 'RU': 'æ©¡èƒ¶', 
    'NR': '20å·èƒ¶', 'BR': 'ä¸äºŒçƒ¯æ©¡èƒ¶', 'SP': 'çº¸æµ†', 'LG': 'æ¶²åŒ–æ°”',
    'TA': 'PTA', 'MA': 'ç”²é†‡', 'PP': 'èšä¸™çƒ¯', 'V': 'PVC', 'L': 'èšä¹™çƒ¯',
    'EB': 'è‹¯ä¹™çƒ¯', 'EG': 'ä¹™äºŒé†‡', 'PG': 'æ¶²åŒ–çŸ³æ²¹æ°”', 'PF': 'çŸ­çº¤',
    'UR': 'å°¿ç´ ', 'SF': 'ç¡…é“', 'SM': 'é”°ç¡…', 'PS': 'å¤šæ™¶ç¡…', 'LC': 'ç¢³é…¸é”‚', 
    'SI': 'å·¥ä¸šç¡…', 'PX': 'å¯¹äºŒç”²è‹¯', 'PR': 'ä¸™çƒ¯',
    
    # å†œäº§å“
    'A': 'è±†ä¸€', 'B': 'è±†äºŒ', 'M': 'è±†ç²•', 'Y': 'è±†æ²¹', 'C': 'ç‰ç±³', 'CS': 'ç‰ç±³æ·€ç²‰',
    'CF': 'æ£‰èŠ±', 'CY': 'æ£‰çº±', 'SR': 'ç™½ç³–', 'P': 'æ£•æ¦ˆæ²¹', 'OI': 'èœç±½æ²¹', 'RM': 'èœç²•',
    'RS': 'èœç±½', 'JD': 'é¸¡è›‹', 'LH': 'ç”ŸçŒª', 'PK': 'èŠ±ç”Ÿ', 'AP': 'è‹¹æœ', 'CJ': 'çº¢æ£',
    'WH': 'å¼ºéº¦', 'PM': 'æ™®éº¦', 'RI': 'æ—©ç±¼ç¨»', 'LR': 'æ™šç±¼ç¨»', 'JR': 'ç²³ç¨»',
    
    # å…¶ä»–
    'SH': 'çº¸æµ†'
}

# akshareå“ç§ä»£ç æ˜ å°„ï¼ˆç”¨äºè”ç½‘APIè°ƒç”¨ï¼‰
AKSHARE_SYMBOL_MAPPING = {
    # ä¸»è¦å“ç§çš„akshareç¬¦å·æ˜ å°„
    'RB': 'RB', 'CU': 'CU', 'AL': 'AL', 'ZN': 'ZN', 'PB': 'PB', 'NI': 'NI',
    'AU': 'AU', 'AG': 'AG', 'I': 'I', 'J': 'J', 'JM': 'JM', 'HC': 'HC',
    'FU': 'FU', 'BU': 'BU', 'RU': 'RU', 'TA': 'TA', 'MA': 'MA', 'PP': 'PP',
    'V': 'V', 'L': 'L', 'EB': 'EB', 'EG': 'EG', 'PG': 'PG', 'M': 'M',
    'Y': 'Y', 'A': 'A', 'C': 'C', 'CF': 'CF', 'SR': 'SR', 'P': 'P',
    'OI': 'OI', 'RM': 'RM', 'JD': 'JD', 'LH': 'LH', 'AP': 'AP', 'CJ': 'CJ',
    'FG': 'FG', 'SA': 'SA', 'UR': 'UR', 'SF': 'SF', 'SM': 'SM', 'SS': 'SS',
    'SN': 'SN', 'WR': 'WR', 'SP': 'SP', 'NR': 'NR', 'BR': 'BR', 'PF': 'PF',
    'CY': 'CY', 'LU': 'LU', 'PS': 'PS', 'LC': 'LC', 'SI': 'SI', 'PX': 'PX',
    'PR': 'PR', 'B': 'B', 'CS': 'CS', 'PK': 'PK', 'RS': 'RS', 'AO': 'AO',
    'BC': 'BC', 'SC': 'SC', 'LG': 'LG'
}

# å“ç§åˆ†ç±»ï¼ˆç”¨äºå­£èŠ‚æ€§åˆ†æï¼‰
VARIETY_CATEGORIES = {
    "éæ ‡å†œäº§å“": ['C', 'JD', 'LH', 'CF', 'SR', 'A'],  # å…·æœ‰æ˜æ˜¾å“è´¨å·®å¼‚
    "æ ‡å‡†åŒ–å†œäº§å“": ['M', 'Y', 'P', 'OI', 'RM'],  # å·¥ä¸šåŒ–åŠ å·¥å“
    "å·¥ä¸šå“": ['RB', 'HC', 'I', 'JM', 'CU', 'AL', 'ZN', 'PB', 'NI'],
    "èƒ½æºåŒ–å·¥": ['FU', 'BU', 'RU', 'TA', 'MA', 'PP', 'V', 'L', 'EB', 'EG']
}

@dataclass
class BasisDataPackage:
    """åŸºå·®æ•°æ®åŒ…ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    # æœ¬åœ°æ•°æ®
    basis_data: pd.DataFrame
    inventory_data: pd.DataFrame
    term_structure_data: pd.DataFrame
    positioning_data: Dict
    receipt_data: pd.DataFrame
    
    # è”ç½‘æ•°æ®ï¼ˆæ–°å¢ï¼‰
    online_basis_data: pd.DataFrame = None
    online_search_results: Dict = None
    
    # å…ƒæ•°æ®
    variety: str = ""
    variety_name: str = ""
    analysis_date: str = ""
    data_quality: Dict[str, str] = None
    
    # æ–°å¢å­—æ®µ
    analysis_mode: str = "local_only"  # "local_only", "hybrid", "network_only"
    data_sources: list = None
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†"""
        if self.online_basis_data is None:
            self.online_basis_data = pd.DataFrame()
        if self.online_search_results is None:
            self.online_search_results = {}
        if self.data_quality is None:
            self.data_quality = {}
        if self.data_sources is None:
            self.data_sources = []

class SerperSearchClient:
    """SERPERæœç´¢å®¢æˆ·ç«¯ - è·å–å®æ—¶å¸‚åœºæ•°æ®"""
    
    def __init__(self, api_key: str = SERPER_API_KEY):
        self.api_key = api_key
        self.base_url = SERPER_BASE_URL
        self.search_results = []  # å­˜å‚¨æœç´¢ç»“æœç”¨äºå¼•ç”¨æ ‡æ³¨
        
    def search_with_citation(self, query: str, num_results: int = 5) -> Dict:
        """æ‰§è¡Œæœç´¢å¹¶è¿”å›å¸¦å¼•ç”¨æ ‡æ³¨çš„ç»“æœ"""
        try:
            payload = {
                "q": query,
                "num": num_results,
                "gl": "cn",
                "hl": "zh"
            }
            
            headers = {
                "X-API-KEY": self.api_key,
                "Content-Type": "application/json"
            }
            
            response = requests.post(self.base_url, json=payload, headers=headers, timeout=10)
            response.raise_for_status()
            
            result = response.json()
            
            # ä¸ºæ¯ä¸ªæœç´¢ç»“æœæ·»åŠ å¼•ç”¨ç¼–å·
            if "organic" in result:
                for i, item in enumerate(result["organic"]):
                    citation_id = f"[{len(self.search_results) + 1}]"
                    item["citation_id"] = citation_id
                    self.search_results.append({
                        "id": citation_id,
                        "title": item.get("title", ""),
                        "link": item.get("link", ""),
                        "snippet": item.get("snippet", "")
                    })
            
            return result
            
        except Exception as e:
            return {"error": f"æœç´¢å¤±è´¥: {str(e)}"}
    
    def get_citations(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å¼•ç”¨ä¿¡æ¯"""
        return self.search_results.copy()

class MultidimensionalBasisAnalyzer:
    """å¤šç»´åº¦åŸºå·®åˆ†æå™¨ï¼ˆè”ç½‘å¢å¼ºç‰ˆï¼‰"""
    
    def __init__(self):
        self.searcher = SerperSearchClient()
        self.akshare_available = self._check_akshare_availability()
        print("ğŸš€ å¤šç»´åº¦åŸºå·®åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        if self.akshare_available:
            print("âœ… akshareå¯ç”¨ï¼Œæ”¯æŒè”ç½‘æ•°æ®è·å–")
        else:
            print("âš ï¸ akshareä¸å¯ç”¨ï¼Œä»…æ”¯æŒæœ¬åœ°æ•°æ®å’Œæœç´¢å¢å¼º")
    
    def _check_akshare_availability(self) -> bool:
        """æ£€æŸ¥akshareæ˜¯å¦å¯ç”¨"""
        try:
            import akshare as ak
            return True
        except ImportError:
            return False
        
    def fetch_online_basis_data(self, variety: str, analysis_date: str = None, days_back: int = 90) -> Tuple[pd.DataFrame, List[str]]:
        """è”ç½‘è·å–åŸºå·®æ•°æ®"""
        
        if not self.akshare_available:
            return pd.DataFrame(), ["akshareä¸å¯ç”¨"]
        
        print(f"ğŸ“¡ è”ç½‘è·å–{variety}åŸºå·®æ•°æ®...")
        data_sources = []
        combined_data = pd.DataFrame()
        
        try:
            import akshare as ak
            
            # è·å–akshareç¬¦å·
            ak_symbol = AKSHARE_SYMBOL_MAPPING.get(variety, variety)
            
            # è®¡ç®—æ—¥æœŸèŒƒå›´
            if analysis_date:
                end_date = pd.to_datetime(analysis_date)
            else:
                end_date = pd.Timestamp.now()
            
            start_date = end_date - pd.Timedelta(days=days_back)
            
            # æ–¹æ³•1: è·å–å†å²åŸºå·®æ•°æ®
            try:
                print(f"  ğŸ“Š è·å–{variety}å†å²åŸºå·®æ•°æ®...")
                
                basis_data = ak.futures_spot_price_daily(
                    start_day=start_date.strftime('%Y%m%d'),
                    end_day=end_date.strftime('%Y%m%d'),
                    vars_list=[ak_symbol]
                )
                
                if basis_data is not None and not basis_data.empty:
                    # æ•°æ®é¢„å¤„ç†
                    if 'date' in basis_data.columns:
                        basis_data['date'] = pd.to_datetime(basis_data['date'])
                    
                    combined_data = basis_data
                    data_sources.append(f"akshareå†å²åŸºå·®æ•°æ®ï¼ˆ{len(basis_data)}æ¡ï¼‰")
                    print(f"  âœ… è·å–å†å²åŸºå·®æ•°æ®æˆåŠŸï¼š{len(basis_data)}æ¡è®°å½•")
                else:
                    print(f"  âš ï¸ å†å²åŸºå·®æ•°æ®ä¸ºç©º")
                    
            except Exception as e:
                print(f"  âŒ è·å–å†å²åŸºå·®æ•°æ®å¤±è´¥: {e}")
            
            # æ–¹æ³•2: è·å–æœ€æ–°åŸºå·®æ•°æ®
            try:
                print(f"  ğŸ“Š è·å–{variety}æœ€æ–°åŸºå·®æ•°æ®...")
                
                latest_basis = ak.futures_spot_price(
                    date=end_date.strftime('%Y%m%d'),
                    vars_list=[ak_symbol]
                )
                
                if latest_basis is not None and not latest_basis.empty:
                    # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œä½¿ç”¨æœ€æ–°æ•°æ®ä½œä¸ºåŸºç¡€
                    if combined_data.empty:
                        combined_data = latest_basis
                    
                    data_sources.append(f"akshareæœ€æ–°åŸºå·®æ•°æ®ï¼ˆ{end_date.strftime('%Y-%m-%d')}ï¼‰")
                    print(f"  âœ… è·å–æœ€æ–°åŸºå·®æ•°æ®æˆåŠŸ")
                else:
                    print(f"  âš ï¸ æœ€æ–°åŸºå·®æ•°æ®ä¸ºç©º")
                    
            except Exception as e:
                print(f"  âŒ è·å–æœ€æ–°åŸºå·®æ•°æ®å¤±è´¥: {e}")
            
            # æ•°æ®æ ‡å‡†åŒ–
            if not combined_data.empty:
                combined_data = self._standardize_basis_data(combined_data, variety)
                print(f"âœ… è”ç½‘åŸºå·®æ•°æ®è·å–å®Œæˆï¼š{len(combined_data)}æ¡è®°å½•")
            else:
                print(f"âŒ æœªè·å–åˆ°{variety}çš„è”ç½‘åŸºå·®æ•°æ®")
            
        except Exception as e:
            print(f"âŒ è”ç½‘åŸºå·®æ•°æ®è·å–å¼‚å¸¸: {e}")
            data_sources.append(f"æ•°æ®è·å–å¤±è´¥: {str(e)}")
        
        return combined_data, data_sources
    
    def _standardize_basis_data(self, df: pd.DataFrame, variety: str) -> pd.DataFrame:
        """æ ‡å‡†åŒ–åŸºå·®æ•°æ®æ ¼å¼"""
        
        if df.empty:
            return df
        
        try:
            # ç¡®ä¿å¿…éœ€çš„åˆ—å­˜åœ¨
            existing_columns = df.columns.tolist()
            
            # å¦‚æœæœ‰varåˆ—ä¸”ç­‰äºå½“å‰å“ç§ï¼Œä¿ç•™æ•°æ®
            if 'var' in existing_columns:
                ak_symbol = AKSHARE_SYMBOL_MAPPING.get(variety, variety)
                df = df[df['var'] == ak_symbol].copy()
            
            # æ ‡å‡†åŒ–åˆ—åæ˜ å°„
            column_mapping = {
                'dom_basis': 'main_basis',        # ä¸»åŠ›åŸºå·®
                'near_basis': 'continuous_basis',  # è¿ç»­åŸºå·®
                'sp': 'spot_price',               # ç°è´§ä»·æ ¼
                'dom_price': 'main_price',        # ä¸»åŠ›åˆçº¦ä»·æ ¼
                'near_price': 'continuous_price', # è¿ç»­åˆçº¦ä»·æ ¼
                'dom_basis_rate': 'main_basis_rate',
                'near_basis_rate': 'continuous_basis_rate'
            }
            
            for old_name, new_name in column_mapping.items():
                if old_name in df.columns:
                    df[new_name] = df[old_name]
            
            # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
                df = df.sort_values('date').reset_index(drop=True)
            
            # è®¡ç®—åŸºå·®å¦‚æœç¼ºå¤±
            if 'spot_price' in df.columns and 'main_price' in df.columns:
                if 'main_basis' not in df.columns and 'dom_basis' not in df.columns:
                    df['main_basis'] = df['spot_price'] - df['main_price']
            
            return df
            
        except Exception as e:
            print(f"âš ï¸ åŸºå·®æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return df
    
    def load_comprehensive_data(self, variety: str, analysis_date: str = None) -> BasisDataPackage:
        """åŠ è½½ç»¼åˆæ•°æ®åŒ…ï¼ˆå¢å¼ºç‰ˆ - æ”¯æŒè”ç½‘æ•°æ®ï¼‰"""
        
        variety_name = VARIETY_NAMES.get(variety, variety)
        print(f"ğŸ“Š å¼€å§‹åŠ è½½{variety}({variety_name})çš„ç»¼åˆæ•°æ®...")
        
        data_quality = {}
        data_sources = []
        
        # 1. åŠ è½½æœ¬åœ°åŸºå·®æ•°æ®
        basis_file = DATA_ROOT / "basis" / variety / "basis_data.csv"
        if basis_file.exists():
            try:
                basis_data = pd.read_csv(basis_file)
                if analysis_date:
                    basis_data = basis_data[basis_data['date'] <= analysis_date]
                data_quality['basis'] = 'å¯ç”¨' if not basis_data.empty else 'æ•°æ®ä¸ºç©º'
                if not basis_data.empty:
                    data_sources.append(f"æœ¬åœ°åŸºå·®æ•°æ®ï¼ˆ{len(basis_data)}æ¡ï¼‰")
                    print(f"âœ… æœ¬åœ°åŸºå·®æ•°æ®åŠ è½½æˆåŠŸï¼š{len(basis_data)}æ¡è®°å½•")
            except Exception as e:
                basis_data = pd.DataFrame()
                data_quality['basis'] = f'è¯»å–å¤±è´¥: {str(e)}'
        else:
            basis_data = pd.DataFrame()
            data_quality['basis'] = 'æ–‡ä»¶ä¸å­˜åœ¨'
            print(f"â„¹ï¸ æœ¬åœ°åŸºå·®æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•è”ç½‘è·å–...")
        
        # 2. è”ç½‘è·å–åŸºå·®æ•°æ®ï¼ˆå¦‚æœæœ¬åœ°æ•°æ®ä¸è¶³æˆ–ä¸å­˜åœ¨ï¼‰
        online_basis_data = pd.DataFrame()
        if basis_data.empty or len(basis_data) < 30:  # å¦‚æœæœ¬åœ°æ•°æ®ä¸ºç©ºæˆ–æ•°æ®é‡ä¸è¶³
            online_basis_data, online_sources = self.fetch_online_basis_data(variety, analysis_date)
            data_sources.extend(online_sources)
        
        # 3. è”ç½‘æœç´¢å¸‚åœºä¿¡æ¯
        search_results = {}
        try:
            print(f"ğŸ” æœç´¢{variety_name}å¸‚åœºä¿¡æ¯...")
            search_queries = [
                f"{variety_name} åŸºå·® ç°è´§ä»·æ ¼ æœ€æ–°",
                f"{variety_name} æœŸè´§ç°è´§ å‡è´´æ°´ åˆ†æ"
            ]
            
            for query in search_queries:
                try:
                    result = self.searcher.search_with_citation(query, num_results=3)
                    if "organic" in result:
                        search_results[query] = result["organic"]
                    time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
                except Exception as e:
                    print(f"âš ï¸ æœç´¢æŸ¥è¯¢å¤±è´¥ '{query}': {e}")
            
            if search_results:
                data_sources.append(f"è”ç½‘å¸‚åœºä¿¡æ¯ï¼ˆ{len(search_results)}ä¸ªæŸ¥è¯¢ï¼‰")
            
        except Exception as e:
            print(f"âš ï¸ è”ç½‘æœç´¢å¤±è´¥: {e}")
        
        # 4. ç¡®å®šåˆ†ææ¨¡å¼
        has_local_basis = not basis_data.empty
        has_online_basis = not online_basis_data.empty
        
        if has_local_basis and has_online_basis:
            analysis_mode = "hybrid"
            print(f"âœ… ä½¿ç”¨æ··åˆåˆ†ææ¨¡å¼ï¼ˆæœ¬åœ°æ•°æ® + è”ç½‘æ•°æ®ï¼‰")
        elif has_local_basis:
            analysis_mode = "local_only" 
            print(f"âœ… ä½¿ç”¨æœ¬åœ°æ•°æ®åˆ†ææ¨¡å¼")
        elif has_online_basis:
            analysis_mode = "network_only"
            print(f"âœ… ä½¿ç”¨çº¯ç½‘ç»œåˆ†ææ¨¡å¼")
        else:
            analysis_mode = "limited"
            print(f"âš ï¸ ä½¿ç”¨å—é™åˆ†ææ¨¡å¼ï¼ˆåŸºå·®æ•°æ®è·å–å›°éš¾ï¼‰")
        
        # 2. åº“å­˜æ•°æ®
        inventory_file = DATA_ROOT / "inventory" / variety / "inventory.csv"
        if inventory_file.exists():
            try:
                inventory_data = pd.read_csv(inventory_file)
                if analysis_date:
                    inventory_data = inventory_data[inventory_data['date'] <= analysis_date]
                data_quality['inventory'] = 'å¯ç”¨' if not inventory_data.empty else 'æ•°æ®ä¸ºç©º'
            except Exception as e:
                inventory_data = pd.DataFrame()
                data_quality['inventory'] = f'è¯»å–å¤±è´¥: {str(e)}'
        else:
            inventory_data = pd.DataFrame()
            data_quality['inventory'] = 'æ–‡ä»¶ä¸å­˜åœ¨'
        
        # 3. æœŸé™ç»“æ„æ•°æ®
        term_structure_file = DATA_ROOT / "term_structure" / variety / "term_structure.csv"
        if term_structure_file.exists():
            try:
                term_structure_data = pd.read_csv(term_structure_file)
                if analysis_date:
                    # æœŸé™ç»“æ„æ•°æ®çš„æ—¥æœŸæ ¼å¼å¯èƒ½æ˜¯YYYYMMDD
                    if 'date' in term_structure_data.columns:
                        term_structure_data['date'] = pd.to_datetime(term_structure_data['date'], format='%Y%m%d', errors='coerce')
                        if analysis_date:
                            analysis_dt = pd.to_datetime(analysis_date)
                            term_structure_data = term_structure_data[term_structure_data['date'] <= analysis_dt]
                data_quality['term_structure'] = 'å¯ç”¨' if not term_structure_data.empty else 'æ•°æ®ä¸ºç©º'
            except Exception as e:
                term_structure_data = pd.DataFrame()
                data_quality['term_structure'] = f'è¯»å–å¤±è´¥: {str(e)}'
        else:
            term_structure_data = pd.DataFrame()
            data_quality['term_structure'] = 'æ–‡ä»¶ä¸å­˜åœ¨'
        
        # 4. æŒä»“æ•°æ®
        positioning_summary_file = DATA_ROOT / "positioning" / variety / "positioning_summary.json"
        if positioning_summary_file.exists():
            try:
                with open(positioning_summary_file, 'r', encoding='utf-8') as f:
                    positioning_data = json.load(f)
                data_quality['positioning'] = 'å¯ç”¨'
            except Exception as e:
                positioning_data = {}
                data_quality['positioning'] = f'è¯»å–å¤±è´¥: {str(e)}'
        else:
            positioning_data = {}
            data_quality['positioning'] = 'æ–‡ä»¶ä¸å­˜åœ¨'
        
        # 5. åŠ è½½å…¶ä»–æœ¬åœ°æ•°æ®ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        inventory_file = DATA_ROOT / "inventory" / variety / "inventory.csv"
        if inventory_file.exists():
            try:
                inventory_data = pd.read_csv(inventory_file)
                if analysis_date:
                    inventory_data = inventory_data[inventory_data['date'] <= analysis_date]
                data_quality['inventory'] = 'å¯ç”¨' if not inventory_data.empty else 'æ•°æ®ä¸ºç©º'
                if not inventory_data.empty:
                    data_sources.append(f"æœ¬åœ°åº“å­˜æ•°æ®ï¼ˆ{len(inventory_data)}æ¡ï¼‰")
            except Exception as e:
                inventory_data = pd.DataFrame()
                data_quality['inventory'] = f'è¯»å–å¤±è´¥: {str(e)}'
        else:
            inventory_data = pd.DataFrame()
            data_quality['inventory'] = 'æ–‡ä»¶ä¸å­˜åœ¨'
        
        # 6. æœŸé™ç»“æ„æ•°æ®
        term_structure_file = DATA_ROOT / "term_structure" / variety / "term_structure.csv"
        if term_structure_file.exists():
            try:
                term_structure_data = pd.read_csv(term_structure_file)
                if analysis_date:
                    if 'date' in term_structure_data.columns:
                        term_structure_data['date'] = pd.to_datetime(term_structure_data['date'], format='%Y%m%d', errors='coerce')
                        if analysis_date:
                            analysis_dt = pd.to_datetime(analysis_date)
                            term_structure_data = term_structure_data[term_structure_data['date'] <= analysis_dt]
                data_quality['term_structure'] = 'å¯ç”¨' if not term_structure_data.empty else 'æ•°æ®ä¸ºç©º'
                if not term_structure_data.empty:
                    data_sources.append(f"æœ¬åœ°æœŸé™ç»“æ„æ•°æ®ï¼ˆ{len(term_structure_data)}æ¡ï¼‰")
            except Exception as e:
                term_structure_data = pd.DataFrame()
                data_quality['term_structure'] = f'è¯»å–å¤±è´¥: {str(e)}'
        else:
            term_structure_data = pd.DataFrame()
            data_quality['term_structure'] = 'æ–‡ä»¶ä¸å­˜åœ¨'
        
        # 7. æŒä»“æ•°æ®
        positioning_summary_file = DATA_ROOT / "positioning" / variety / "positioning_summary.json"
        if positioning_summary_file.exists():
            try:
                with open(positioning_summary_file, 'r', encoding='utf-8') as f:
                    positioning_data = json.load(f)
                data_quality['positioning'] = 'å¯ç”¨'
                data_sources.append("æœ¬åœ°æŒä»“æ±‡æ€»æ•°æ®")
            except Exception as e:
                positioning_data = {}
                data_quality['positioning'] = f'è¯»å–å¤±è´¥: {str(e)}'
        else:
            positioning_data = {}
            data_quality['positioning'] = 'æ–‡ä»¶ä¸å­˜åœ¨'
        
        # 8. ä»“å•æ•°æ®
        receipt_file = DATA_ROOT / "receipt" / variety / "receipt.csv"
        if receipt_file.exists():
            try:
                receipt_data = pd.read_csv(receipt_file)
                if analysis_date:
                    receipt_data = receipt_data[receipt_data['date'] <= analysis_date]
                data_quality['receipt'] = 'å¯ç”¨' if not receipt_data.empty else 'æ•°æ®ä¸ºç©º'
                if not receipt_data.empty:
                    data_sources.append(f"æœ¬åœ°ä»“å•æ•°æ®ï¼ˆ{len(receipt_data)}æ¡ï¼‰")
            except Exception as e:
                receipt_data = pd.DataFrame()
                data_quality['receipt'] = f'è¯»å–å¤±è´¥: {str(e)}'
        else:
            receipt_data = pd.DataFrame()
            data_quality['receipt'] = 'æ–‡ä»¶ä¸å­˜åœ¨'
        
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œåˆ†ææ¨¡å¼ï¼š{analysis_mode}ï¼Œæ•°æ®æºï¼š{len(data_sources)}ä¸ª")
        
        # è¿”å›å¢å¼ºç‰ˆæ•°æ®åŒ…
        return BasisDataPackage(
            # æœ¬åœ°æ•°æ®
            basis_data=basis_data,
            inventory_data=inventory_data,
            term_structure_data=term_structure_data,
            positioning_data=positioning_data,
            receipt_data=receipt_data,
            
            # è”ç½‘æ•°æ®
            online_basis_data=online_basis_data,
            online_search_results=search_results,
            
            # å…ƒæ•°æ®
            variety=variety,
            variety_name=variety_name,
            analysis_date=analysis_date or datetime.now().strftime('%Y-%m-%d'),
            data_quality=data_quality,
            analysis_mode=analysis_mode,
            data_sources=data_sources
        )
    
    def analyze_continuous_basis(self, data_package: BasisDataPackage) -> Dict:
        """è¿ç»­åŸºå·®åˆ†æï¼ˆæ—¶é—´ç»´åº¦ï¼‰"""
        
        if data_package.basis_data.empty:
            return {"error": "åŸºå·®æ•°æ®ä¸å¯ç”¨"}
        
        df = data_package.basis_data.copy()
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').reset_index(drop=True)
        
        if len(df) == 0:
            return {"error": "åŸºå·®æ•°æ®ä¸ºç©º"}
        
        latest = df.iloc[-1]
        
        analysis = {
            "current_continuous_basis": float(latest['near_basis']) if pd.notna(latest.get('near_basis')) else None,
            "current_main_basis": float(latest['dom_basis']) if pd.notna(latest.get('dom_basis')) else None,
            "basis_spread": None,
            "convergence_analysis": {},
            "time_decay_characteristic": "è¿ç»­åŸºå·®å…·æœ‰æœŸæƒæ—¶é—´è¡°å‡ç‰¹å¾"
        }
        
        # åŸºå·®ä»·å·®è®¡ç®—
        if pd.notna(latest.get('dom_basis')) and pd.notna(latest.get('near_basis')):
            analysis["basis_spread"] = float(latest['dom_basis'] - latest['near_basis'])
        
        # æ”¶æ•›æ€§åˆ†æ
        if len(df) >= 30 and 'near_basis' in df.columns:
            near_basis_std = df['near_basis'].std()
            recent_volatility = df['near_basis'].tail(10).std()
            
            analysis["convergence_analysis"] = {
                "historical_volatility": float(near_basis_std) if pd.notna(near_basis_std) else None,
                "recent_volatility": float(recent_volatility) if pd.notna(recent_volatility) else None,
                "convergence_tendency": "æ”¶æ•›" if recent_volatility < near_basis_std else "å‘æ•£"
            }
        
        return analysis
    
    def analyze_seasonal_pattern(self, data_package: BasisDataPackage) -> Dict:
        """å­£èŠ‚æ€§åŸºå·®åˆ†æ"""
        
        if data_package.basis_data.empty:
            return {"error": "åŸºå·®æ•°æ®ä¸å¯ç”¨"}
        
        df = data_package.basis_data.copy()
        df['date'] = pd.to_datetime(df['date'])
        df['month'] = df['date'].dt.month
        
        # è®¡ç®—æœˆåº¦åŸºå·®å‡å€¼
        monthly_avg = df.groupby('month')['dom_basis'].mean().to_dict()
        
        # å½“å‰æœˆä»½åŸºå·®ä¸å†å²åŒæœŸå¯¹æ¯”
        current_month = datetime.now().month
        current_basis = df.iloc[-1]['dom_basis'] if not df.empty and 'dom_basis' in df.columns else None
        historical_same_month = monthly_avg.get(current_month)
        
        analysis = {
            "monthly_average_basis": monthly_avg,
            "current_month": current_month,
            "current_basis": float(current_basis) if pd.notna(current_basis) else None,
            "historical_same_month_avg": float(historical_same_month) if pd.notna(historical_same_month) else None,
            "seasonal_deviation": None,
            "seasonal_strength": "æœªçŸ¥"
        }
        
        # å­£èŠ‚æ€§åç¦»è®¡ç®—
        if pd.notna(current_basis) and pd.notna(historical_same_month):
            deviation = current_basis - historical_same_month
            analysis["seasonal_deviation"] = float(deviation)
            
            if abs(deviation) > 50:
                analysis["seasonal_strength"] = "å¼ºåç¦»"
            elif abs(deviation) > 20:
                analysis["seasonal_strength"] = "ä¸­ç­‰åç¦»"
            else:
                analysis["seasonal_strength"] = "æ­£å¸¸èŒƒå›´"
        
        return analysis
    
    def analyze_inventory_basis_relationship(self, data_package: BasisDataPackage) -> Dict:
        """åº“å­˜-åŸºå·®å…³ç³»åˆ†æï¼ˆåº“å­˜ç†è®ºï¼‰"""
        
        analysis = {
            "inventory_level": "æœªçŸ¥",
            "basis_level": "æœªçŸ¥",
            "region_classification": "æœªç¡®å®š",
            "theoretical_framework": "åŸºäºåº“å­˜ç†è®ºçš„ä¸‰åŒºåŸŸåˆ†ææ¡†æ¶",
            "trading_implications": []
        }
        
        # åº“å­˜æ°´å¹³è¯„ä¼°
        if not data_package.inventory_data.empty:
            inventory_df = data_package.inventory_data.copy()
            inventory_df['date'] = pd.to_datetime(inventory_df['date'])
            
            if len(inventory_df) > 0 and 'value' in inventory_df.columns:
                current_inventory = inventory_df.iloc[-1]['value']
                historical_inventory = inventory_df['value']
                
                percentile = (historical_inventory <= current_inventory).mean() * 100
                
                if percentile <= 20:
                    analysis["inventory_level"] = "æä½åº“å­˜"
                    analysis["region_classification"] = "åŒºåŸŸA - è´§æƒé›†ä¸­"
                elif percentile <= 80:
                    analysis["inventory_level"] = "æ­£å¸¸åº“å­˜"
                    analysis["region_classification"] = "åŒºåŸŸB - æ­£å¸¸æ³¢åŠ¨"
                else:
                    analysis["inventory_level"] = "é«˜åº“å­˜"
                    analysis["region_classification"] = "åŒºåŸŸC - åº“å­˜å‹åˆ¶"
        
        # åŸºå·®æ°´å¹³è¯„ä¼°
        if not data_package.basis_data.empty and 'dom_basis' in data_package.basis_data.columns:
            basis_df = data_package.basis_data.copy()
            if len(basis_df) > 0:
                current_basis = basis_df.iloc[-1]['dom_basis']
                
                if pd.notna(current_basis):
                    if current_basis > 50:
                        analysis["basis_level"] = "å¼ºå‡æ°´"
                    elif current_basis > 0:
                        analysis["basis_level"] = "å¼±å‡æ°´"
                    elif current_basis > -50:
                        analysis["basis_level"] = "å¼±è´´æ°´"
                    else:
                        analysis["basis_level"] = "å¼ºè´´æ°´"
        
        # äº¤æ˜“å«ä¹‰
        if analysis["inventory_level"] == "æä½åº“å­˜" and analysis["basis_level"] in ["å¼ºè´´æ°´", "å¼±è´´æ°´"]:
            analysis["trading_implications"].append("ä¾›åº”ç´§å¼ ï¼ŒåŸºå·®èµ°å¼ºé¢„æœŸ")
        elif analysis["inventory_level"] == "é«˜åº“å­˜" and analysis["basis_level"] in ["å¼ºå‡æ°´", "å¼±å‡æ°´"]:
            analysis["trading_implications"].append("åº“å­˜å‹åˆ¶ï¼ŒåŸºå·®èµ°å¼±é¢„æœŸ")
        
        return analysis
    
    def analyze_spatial_basis_differences(self, data_package: BasisDataPackage, external_data: Dict) -> Dict:
        """ç©ºé—´åŸºå·®å·®å¼‚åˆ†æ"""
        
        analysis = {
            "delivery_warehouse_analysis": "åŸºå‡†åº“åˆ†æ",
            "regional_imbalance": "ç©ºé—´ä¸å‡è¡¡ç‰¹å¾",
            "arbitrage_opportunities": [],
            "spatial_spread_analysis": "åŒºåŸŸä»·å·®åˆ†æ"
        }
        
        # ä»å¤–éƒ¨æœç´¢æ•°æ®ä¸­æå–åŒºåŸŸä»·æ ¼ä¿¡æ¯
        if external_data.get("regional_premium_discount", {}).get("results"):
            regional_data = external_data["regional_premium_discount"]["results"]
            analysis["regional_price_info"] = [
                f"åŒºåŸŸä»·æ ¼ä¿¡æ¯: {item['title']} - {item['snippet']}"
                for item in regional_data[:3]
            ]
        
        # åŸºäºå“ç§ç‰¹æ€§çš„ç©ºé—´åˆ†æ
        variety = data_package.variety
        if variety in ['C', 'A', 'M']:  # å†œäº§å“
            analysis["spatial_characteristics"] = "å†œäº§å“åŸºå‡†åº“é è¿‘äº§åŒºï¼Œå­˜åœ¨æ˜æ˜¾çš„å­£èŠ‚æ€§è¿è¾“æˆæœ¬å·®å¼‚"
        elif variety in ['CU', 'AL', 'ZN']:  # æœ‰è‰²é‡‘å±
            analysis["spatial_characteristics"] = "æœ‰è‰²é‡‘å±åŸºå‡†åº“é è¿‘æ¸¯å£ï¼Œè¿›å£ä¾èµ–åº¦é«˜"
        elif variety in ['RB', 'HC', 'I']:  # é»‘è‰²ç³»
            analysis["spatial_characteristics"] = "é»‘è‰²ç³»åŸºå‡†åº“åˆ†å¸ƒå¹¿æ³›ï¼ŒåŒºåŸŸä¾›éœ€å·®å¼‚æ˜¾è‘—"
        else:
            analysis["spatial_characteristics"] = "å“ç§ç©ºé—´ç‰¹å¾å¾…åˆ†æ"
        
        return analysis
    
    def analyze_quality_basis_differences(self, data_package: BasisDataPackage) -> Dict:
        """å“è´¨å·®å¼‚åŸºå·®åˆ†æ"""
        
        variety = data_package.variety
        analysis = {
            "quality_standardization": "æ ‡å‡†åŒ–ç¨‹åº¦",
            "premium_discount_structure": "å‡è´´æ°´ç»“æ„",
            "quality_spread_analysis": "å“è´¨ä»·å·®åˆ†æ"
        }
        
        # æ ¹æ®å“ç§åˆ†ç±»è¿›è¡Œå“è´¨åˆ†æ
        if variety in VARIETY_CATEGORIES.get("éæ ‡å†œäº§å“", []):
            analysis.update({
                "quality_standardization": "éæ ‡å‡†åŒ–å•†å“ï¼Œå­˜åœ¨æ˜æ˜¾å“è´¨å·®å¼‚",
                "premium_discount_structure": "äº¤å‰²æ ‡å‡†ä»¥ä¸Šå‡æ°´ï¼Œä»¥ä¸‹è´´æ°´",
                "market_segmentation": "éœ€æ±‚å¸‚åœºæŒ‰å“è´¨è¿›è¡Œåˆ†å‰²",
                "hedonic_price_model": "å¯åº”ç”¨ç‰¹å¾ä»·æ ¼æ¨¡å‹åˆ†æå“è´¨ä»·å·®"
            })
        elif variety in VARIETY_CATEGORIES.get("æ ‡å‡†åŒ–å†œäº§å“", []):
            analysis.update({
                "quality_standardization": "å·¥ä¸šåŒ–åŠ å·¥å“ï¼Œæ ‡å‡†åŒ–ç¨‹åº¦é«˜",
                "premium_discount_structure": "å“è´¨å·®å¼‚è¾ƒå°ï¼Œå‡è´´æ°´å¹…åº¦æœ‰é™",
                "market_segmentation": "å¸‚åœºç»Ÿä¸€æ€§è¾ƒå¼º"
            })
        else:
            analysis.update({
                "quality_standardization": "å·¥ä¸šå“æ ‡å‡†åŒ–ç¨‹åº¦é«˜",
                "premium_discount_structure": "ä¸¥æ ¼æŒ‰äº¤å‰²æ ‡å‡†æ‰§è¡Œ",
                "market_segmentation": "å¸‚åœºç»Ÿä¸€æ€§å¼º"
            })
        
        return analysis
    
    def create_professional_charts(self, data_package: BasisDataPackage) -> Dict:
        """åˆ›å»ºä¸“ä¸šå›¾è¡¨"""
        
        charts = {}
        
        # 1. åŸºå·®èµ°åŠ¿å›¾
        if not data_package.basis_data.empty:
            basis_chart = self._create_basis_trend_chart(data_package.basis_data, data_package.variety_name)
            charts['basis_trend'] = basis_chart
        
        # 2. åº“å­˜æ°´å¹³å›¾
        if not data_package.inventory_data.empty:
            inventory_chart = self._create_inventory_chart(data_package.inventory_data, data_package.variety_name)
            charts['inventory_level'] = inventory_chart
        
        # 3. æœŸé™ç»“æ„å›¾
        if not data_package.term_structure_data.empty:
            term_structure_chart = self._create_term_structure_chart(data_package.term_structure_data, data_package.variety_name)
            charts['term_structure'] = term_structure_chart
        
        # 4. å­£èŠ‚æ€§åŸºå·®å¯¹æ¯”å›¾
        if not data_package.basis_data.empty:
            seasonal_chart = self._create_seasonal_basis_chart(data_package.basis_data, data_package.variety_name)
            charts['seasonal_pattern'] = seasonal_chart
        
        return charts
    
    def _create_basis_trend_chart(self, basis_data: pd.DataFrame, variety_name: str):
        """åˆ›å»ºåŸºå·®èµ°åŠ¿å›¾"""
        
        df = basis_data.copy()
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').tail(60)  # æœ€è¿‘60å¤©
        
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=['åŸºå·®èµ°åŠ¿', 'åŸºå·®æ”¶æ•›æ€§åˆ†æ'],
            vertical_spacing=0.1
        )
        
        # ä¸»åŠ›åŸºå·®çº¿
        fig.add_trace(
            go.Scatter(
                x=df['date'], 
                y=df['dom_basis'],
                name='ä¸»åŠ›åŸºå·®',
                line=dict(color='blue', width=2),
                mode='lines'
            ),
            row=1, col=1
        )
        
        # è¿ç»­åŸºå·®çº¿
        if 'near_basis' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df['date'], 
                    y=df['near_basis'],
                    name='è¿ç»­åŸºå·®',
                    line=dict(color='red', width=2),
                    mode='lines'
                ),
                row=1, col=1
            )
        
        # åŸºå·®æ”¶æ•›æ€§ï¼ˆæ»šåŠ¨æ ‡å‡†å·®ï¼‰
        if len(df) >= 10:
            rolling_std = df['dom_basis'].rolling(10).std()
            fig.add_trace(
                go.Scatter(
                    x=df['date'], 
                    y=rolling_std,
                    name='10æ—¥æ»šåŠ¨æ³¢åŠ¨ç‡',
                    line=dict(color='green', width=1),
                    mode='lines'
                ),
                row=2, col=1
            )
        
        fig.update_layout(
            title=f'{variety_name} åŸºå·®èµ°åŠ¿åˆ†æ',
            height=600,
            showlegend=True
        )
        
        fig.update_xaxes(title_text="æ—¥æœŸ", row=2, col=1)
        fig.update_yaxes(title_text="åŸºå·® (å…ƒ/å¨)", row=1, col=1)
        fig.update_yaxes(title_text="æ³¢åŠ¨ç‡", row=2, col=1)
        
        return fig  # è¿”å›Plotlyå¯¹è±¡è€Œä¸æ˜¯HTMLå­—ç¬¦ä¸²
    
    def _create_inventory_chart(self, inventory_data: pd.DataFrame, variety_name: str):
        """åˆ›å»ºåº“å­˜æ°´å¹³å›¾"""
        
        df = inventory_data.copy()
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').tail(90)  # æœ€è¿‘90å¤©
        
        # è®¡ç®—å†å²åˆ†ä½æ•°
        current_inventory = df.iloc[-1]['value']
        percentile = (df['value'] <= current_inventory).mean() * 100
        
        fig = go.Figure()
        
        # åº“å­˜èµ°åŠ¿
        fig.add_trace(
            go.Scatter(
                x=df['date'], 
                y=df['value'],
                name='åº“å­˜æ°´å¹³',
                line=dict(color='purple', width=2),
                mode='lines+markers'
            )
        )
        
        # æ·»åŠ åˆ†ä½æ•°çº¿
        percentiles = [20, 50, 80]
        colors = ['red', 'orange', 'green']
        for p, color in zip(percentiles, colors):
            pct_value = df['value'].quantile(p/100)
            fig.add_hline(
                y=pct_value, 
                line_dash="dash", 
                line_color=color,
                annotation_text=f"{p}%åˆ†ä½æ•°: {pct_value:.0f}"
            )
        
        fig.update_layout(
            title=f'{variety_name} åº“å­˜æ°´å¹³åˆ†æ (å½“å‰åˆ†ä½æ•°: {percentile:.1f}%)',
            xaxis_title="æ—¥æœŸ",
            yaxis_title="åº“å­˜ (ä¸‡å¨)",
            height=400
        )
        
        return fig  # è¿”å›Plotlyå¯¹è±¡è€Œä¸æ˜¯HTMLå­—ç¬¦ä¸²
    
    def _create_term_structure_chart(self, term_structure_data: pd.DataFrame, variety_name: str):
        """åˆ›å»ºæœŸé™ç»“æ„å›¾"""
        
        df = term_structure_data.copy()
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'], format='%Y%m%d', errors='coerce')
            latest_data = df[df['date'] == df['date'].max()]
        else:
            latest_data = df.tail(10)  # å–æœ€æ–°10æ¡è®°å½•
        
        if latest_data.empty:
            return "<p>æœŸé™ç»“æ„æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨</p>"
        
        fig = go.Figure()
        
        # æŒ‰åˆçº¦æœˆä»½æ’åº
        if 'symbol' in latest_data.columns and 'close' in latest_data.columns:
            latest_data = latest_data.sort_values('symbol')
            
            fig.add_trace(
                go.Scatter(
                    x=latest_data['symbol'], 
                    y=latest_data['close'],
                    name='åˆçº¦ä»·æ ¼',
                    line=dict(color='blue', width=3),
                    mode='lines+markers',
                    marker=dict(size=8)
                )
            )
        
        fig.update_layout(
            title=f'{variety_name} æœŸé™ç»“æ„æ›²çº¿',
            xaxis_title="åˆçº¦æœˆä»½",
            yaxis_title="ä»·æ ¼ (å…ƒ/å¨)",
            height=400
        )
        
        return fig  # è¿”å›Plotlyå¯¹è±¡è€Œä¸æ˜¯HTMLå­—ç¬¦ä¸²
    
    def _create_seasonal_basis_chart(self, basis_data: pd.DataFrame, variety_name: str):
        """åˆ›å»ºå­£èŠ‚æ€§åŸºå·®å¯¹æ¯”å›¾"""
        
        df = basis_data.copy()
        df['date'] = pd.to_datetime(df['date'])
        df['month'] = df['date'].dt.month
        
        # è®¡ç®—æœˆåº¦ç»Ÿè®¡
        monthly_stats = df.groupby('month')['dom_basis'].agg(['mean', 'std', 'count']).reset_index()
        monthly_stats = monthly_stats[monthly_stats['count'] >= 3]  # è‡³å°‘3ä¸ªæ•°æ®ç‚¹
        
        if monthly_stats.empty:
            return "<p>å­£èŠ‚æ€§æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨</p>"
        
        fig = go.Figure()
        
        # æœˆåº¦å‡å€¼
        fig.add_trace(
            go.Scatter(
                x=monthly_stats['month'], 
                y=monthly_stats['mean'],
                name='å†å²æœˆåº¦å‡å€¼',
                line=dict(color='blue', width=2),
                mode='lines+markers'
            )
        )
        
        # æ ‡å‡†å·®åŒºé—´
        fig.add_trace(
            go.Scatter(
                x=monthly_stats['month'], 
                y=monthly_stats['mean'] + monthly_stats['std'],
                name='ä¸Šé™ (+1Ïƒ)',
                line=dict(color='lightblue', width=1),
                mode='lines',
                showlegend=False
            )
        )
        
        fig.add_trace(
            go.Scatter(
                x=monthly_stats['month'], 
                y=monthly_stats['mean'] - monthly_stats['std'],
                name='ä¸‹é™ (-1Ïƒ)',
                line=dict(color='lightblue', width=1),
                mode='lines',
                fill='tonexty',
                fillcolor='rgba(173,216,230,0.3)',
                showlegend=False
            )
        )
        
        # å½“å‰æœˆä»½æ ‡è®°
        current_month = datetime.now().month
        current_basis = df[df['month'] == current_month]['dom_basis'].iloc[-1] if len(df[df['month'] == current_month]) > 0 else None
        
        if current_basis is not None:
            fig.add_trace(
                go.Scatter(
                    x=[current_month], 
                    y=[current_basis],
                    name=f'å½“å‰({current_month}æœˆ)',
                    mode='markers',
                    marker=dict(color='red', size=12, symbol='star')
                )
            )
        
        fig.update_layout(
            title=f'{variety_name} å­£èŠ‚æ€§åŸºå·®è§„å¾‹',
            xaxis_title="æœˆä»½",
            yaxis_title="åŸºå·® (å…ƒ/å¨)",
            height=400
        )
        
        return fig  # è¿”å›Plotlyå¯¹è±¡è€Œä¸æ˜¯HTMLå­—ç¬¦ä¸²
    
    def search_enhanced_market_context(self, data_package: BasisDataPackage) -> Dict:
        """æœç´¢å¢å¼ºçš„å¸‚åœºèƒŒæ™¯åˆ†æ"""
        
        variety = data_package.variety
        variety_name = data_package.variety_name
        
        # å®šåˆ¶åŒ–æœç´¢æŸ¥è¯¢
        search_queries = [
            f"{variety_name}æœŸè´§ ç°è´§ä»·æ ¼ åŸºå·® æœ€æ–° 2025å¹´",
            f"{variety_name}åº“å­˜ ä»“å• ä¾›éœ€å¹³è¡¡ 2025å¹´",
            f"{variety_name}åŒºåŸŸä»·å·® å‡è´´æ°´ äº¤å‰² æœ€æ–°",
            f"{variety_name}å­£èŠ‚æ€§è§„å¾‹ åŸºå·®èµ°åŠ¿ å†å²åˆ†æ",
            f"{variety_name}äº§ä¸šé“¾ ä¸Šä¸‹æ¸¸ åˆ©æ¶¦ æˆæœ¬åˆ†æ"
        ]
        
        market_context = {
            "price_basis_info": {},
            "inventory_supply_demand": {},
            "regional_premium_discount": {},
            "seasonal_patterns": {},
            "industry_chain_analysis": {},
            "search_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        context_keys = [
            "price_basis_info", "inventory_supply_demand", 
            "regional_premium_discount", "seasonal_patterns", 
            "industry_chain_analysis"
        ]
        
        for i, query in enumerate(search_queries):
            print(f"  ğŸ” æœç´¢ä¸­: {query}")
            result = self.searcher.search_with_citation(query, num_results=3)
            
            if "error" not in result and "organic" in result:
                context_key = context_keys[i]
                market_context[context_key] = {
                    "query": query,
                    "results": []
                }
                
                for item in result["organic"]:
                    market_context[context_key]["results"].append({
                        "title": item.get("title", ""),
                        "snippet": item.get("snippet", ""),
                        "link": item.get("link", ""),
                        "citation_id": item.get("citation_id", "")
                    })
            
            time.sleep(0.5)
        
        return market_context
    
    def create_comprehensive_analysis_prompt(self, data_package: BasisDataPackage, 
                                           continuous_analysis: Dict,
                                           seasonal_analysis: Dict,
                                           inventory_analysis: Dict,
                                           spatial_analysis: Dict,
                                           quality_analysis: Dict,
                                           market_context: Dict) -> str:
        """åˆ›å»ºç»¼åˆåˆ†æprompt"""
        
        # æ„å»ºå¸‚åœºèƒŒæ™¯ä¿¡æ¯ï¼ˆå¸¦å¼•ç”¨ï¼‰
        market_info = ""
        for section_name, section_data in market_context.items():
            if isinstance(section_data, dict) and "results" in section_data:
                market_info += f"\n{section_name}:\n"
                for result in section_data["results"][:2]:
                    citation = result.get("citation_id", "")
                    market_info += f"- {citation} {result['title']}: {result['snippet']}\n"
        
        prompt = f"""
ä½ æ˜¯ä¸­å›½æœŸè´§å¸‚åœºé¡¶çº§åŸºå·®åˆ†æä¸“å®¶ï¼Œæ‹¥æœ‰20å¹´å®æˆ˜ç»éªŒã€‚è¯·åŸºäºä»¥ä¸‹çœŸå®æ•°æ®å’Œç†è®ºæ¡†æ¶è¿›è¡Œä¸“ä¸šåˆ†æã€‚

é‡è¦åˆ†æåŸåˆ™:
1. ä¸¥ç¦ç¼–é€ ä»»ä½•æ•°æ®ã€æ¯”ç‡ã€æˆæœ¬å‚æ•°
2. æ‰€æœ‰ç»“è®ºå¿…é¡»åŸºäºæä¾›çš„çœŸå®æ•°æ®
3. è”ç½‘æœç´¢çš„ä¿¡æ¯å·²æ ‡æ³¨å¼•ç”¨ç¼–å·ï¼Œè¯·åœ¨åˆ†æä¸­ä½¿ç”¨
4. ä¸ä½¿ç”¨ä»»ä½•markdownç¬¦å·ï¼ˆå¦‚ #ã€**ã€###ç­‰ï¼‰ï¼Œé‡‡ç”¨çº¯æ–‡æœ¬æ ¼å¼
5. åˆ†ææŠ¥å‘Šè¦å…¼å…·ä¸“ä¸šæ€§å’Œå¯è¯»æ€§

åˆ†ææ ‡çš„: {data_package.variety}ï¼ˆ{data_package.variety_name}ï¼‰
åˆ†ææ—¶ç‚¹: {data_package.analysis_date}

âš ï¸ é‡è¦æé†’: 
- æœ¬æ¬¡åˆ†æçš„å“ç§ä»£ç æ˜¯ {data_package.variety}ï¼Œå¯¹åº”å“ç§åç§°æ˜¯ {data_package.variety_name}
- è¯·ç¡®ä¿æ‰€æœ‰åˆ†æå†…å®¹éƒ½å›´ç»• {data_package.variety} å“ç§è¿›è¡Œï¼Œä¸è¦æ··æ·†å…¶ä»–å“ç§
- åˆçº¦ä»£ç åº”ä½¿ç”¨ {data_package.variety}XXXX æ ¼å¼ï¼Œå¦‚ {data_package.variety}2410ã€{data_package.variety}2501 ç­‰
- ä¸¥ç¦ä½¿ç”¨å…¶ä»–å“ç§çš„åˆçº¦ä»£ç æˆ–å“ç§åç§°

æ•°æ®è´¨é‡è¯„ä¼°:
- åŸºå·®æ•°æ®: {data_package.data_quality.get('basis', 'æœªçŸ¥')}
- åº“å­˜æ•°æ®: {data_package.data_quality.get('inventory', 'æœªçŸ¥')}
- æœŸé™ç»“æ„æ•°æ®: {data_package.data_quality.get('term_structure', 'æœªçŸ¥')}
- æŒä»“æ•°æ®: {data_package.data_quality.get('positioning', 'æœªçŸ¥')}
- ä»“å•æ•°æ®: {data_package.data_quality.get('receipt', 'æœªçŸ¥')}

{market_info}

ä¸€ã€è¿ç»­åŸºå·®ä¸æ—¶é—´ç»´åº¦åˆ†æ
å½“å‰è¿ç»­åŸºå·®: {continuous_analysis.get('current_continuous_basis', 'N/A')} å…ƒ/å¨
å½“å‰ä¸»åŠ›åŸºå·®: {continuous_analysis.get('current_main_basis', 'N/A')} å…ƒ/å¨
åŸºå·®ä»·å·®: {continuous_analysis.get('basis_spread', 'N/A')} å…ƒ/å¨
æ”¶æ•›ç‰¹å¾: {continuous_analysis.get('convergence_analysis', {})}

äºŒã€å­£èŠ‚æ€§åŸºå·®è§„å¾‹åˆ†æ
å½“å‰æœˆä»½: {seasonal_analysis.get('current_month', 'N/A')}æœˆ
å½“å‰åŸºå·®: {seasonal_analysis.get('current_basis', 'N/A')} å…ƒ/å¨
å†å²åŒæœŸå‡å€¼: {seasonal_analysis.get('historical_same_month_avg', 'N/A')} å…ƒ/å¨
å­£èŠ‚æ€§åç¦»: {seasonal_analysis.get('seasonal_deviation', 'N/A')} å…ƒ/å¨
å­£èŠ‚æ€§å¼ºåº¦: {seasonal_analysis.get('seasonal_strength', 'æœªçŸ¥')}

ä¸‰ã€åº“å­˜-åŸºå·®å…³ç³»åˆ†æï¼ˆåº“å­˜ç†è®ºï¼‰
åº“å­˜æ°´å¹³: {inventory_analysis.get('inventory_level', 'æœªçŸ¥')}
åŸºå·®æ°´å¹³: {inventory_analysis.get('basis_level', 'æœªçŸ¥')}
åŒºåŸŸåˆ†ç±»: {inventory_analysis.get('region_classification', 'æœªç¡®å®š')}
äº¤æ˜“å«ä¹‰: {inventory_analysis.get('trading_implications', [])}

å››ã€ç©ºé—´åŸºå·®å·®å¼‚åˆ†æ
ç©ºé—´ç‰¹å¾: {spatial_analysis.get('spatial_characteristics', 'æœªçŸ¥')}
åŒºåŸŸä¸å‡è¡¡: {spatial_analysis.get('regional_imbalance', 'åˆ†æä¸­')}

äº”ã€å“è´¨å·®å¼‚åŸºå·®åˆ†æ
æ ‡å‡†åŒ–ç¨‹åº¦: {quality_analysis.get('quality_standardization', 'æœªçŸ¥')}
å‡è´´æ°´ç»“æ„: {quality_analysis.get('premium_discount_structure', 'æœªçŸ¥')}
å¸‚åœºåˆ†å‰²: {quality_analysis.get('market_segmentation', 'æœªçŸ¥')}

è¯·æŒ‰ä»¥ä¸‹æ¡†æ¶è¿›è¡Œæ·±åº¦åˆ†æï¼ˆæ¯éƒ¨åˆ†600-800å­—ï¼‰:

ç¬¬ä¸€éƒ¨åˆ†: è¿ç»­åŸºå·®æ”¶æ•›æ€§ä¸æ—¶é—´è¡°å‡åˆ†æ
åŸºäºè¿ç»­åŸºå·®çš„æ—¶é—´è¡°å‡ç‰¹å¾ï¼Œåˆ†æå½“å‰åŸºå·®æ”¶æ•›æƒ…å†µï¼Œç»“åˆä¸»åŠ›åˆçº¦åˆ‡æ¢çš„è·³è·ƒç°è±¡ï¼Œè¯„ä¼°åŸºå·®èµ°åŠ¿ã€‚

ç¬¬äºŒéƒ¨åˆ†: å­£èŠ‚æ€§åŸºå·®è§„å¾‹ä¸å†å²å¯¹æ¯”
åŸºäºæœˆåº¦åŸºå·®å‡å€¼å’Œå½“å‰å­£èŠ‚æ€§åç¦»ï¼Œåˆ†æå­£èŠ‚æ€§èµ°å¼ºæˆ–èµ°å¼±çš„å¯èƒ½æ€§ï¼Œç»“åˆäº§ä¸šç”Ÿäº§æ¶ˆè´¹å‘¨æœŸã€‚

ç¬¬ä¸‰éƒ¨åˆ†: åº“å­˜ç†è®ºæ¡†æ¶ä¸‹çš„åŸºå·®-åº“å­˜å…³ç³»
åŸºäºåº“å­˜ç†è®ºçš„ä¸‰åŒºåŸŸåˆ†ææ¡†æ¶ï¼Œè¯„ä¼°å½“å‰å¸‚åœºæ‰€å¤„é˜¶æ®µã€‚å¿…é¡»åœ¨é¦–æ¬¡æåˆ°åŒºåŸŸåˆ†ç±»æ—¶è¯¦ç»†è§£é‡Šï¼š
- åŒºåŸŸAï¼ˆè´§æƒé›†ä¸­ï¼‰ï¼šåº“å­˜æä½ï¼ˆå†å²åˆ†ä½æ•°â‰¤20%ï¼‰ï¼Œç°è´§ç¨€ç¼ºï¼ŒåŸºå·®é€šå¸¸å‘ˆç°å¼ºå‡æ°´
- åŒºåŸŸBï¼ˆæ­£å¸¸æ³¢åŠ¨ï¼‰ï¼šåº“å­˜æ­£å¸¸ï¼ˆå†å²åˆ†ä½æ•°20%-80%ï¼‰ï¼Œä¾›éœ€ç›¸å¯¹å¹³è¡¡ï¼ŒåŸºå·®æ³¢åŠ¨é€‚ä¸­  
- åŒºåŸŸCï¼ˆåº“å­˜å‹åˆ¶ï¼‰ï¼šåº“å­˜é«˜ä¼ï¼ˆå†å²åˆ†ä½æ•°â‰¥80%ï¼‰ï¼Œä¾›åº”å……è£•ï¼ŒåŸºå·®æ‰¿å—å‹åŠ›
ç„¶ååˆ†æå½“å‰å¸‚åœºæ‰€å¤„çš„å…·ä½“åŒºåŸŸåŠå…¶äº¤æ˜“å«ä¹‰ã€‚

é‡è¦è¦æ±‚ï¼šå¿…é¡»æ˜ç¡®æ ‡æ³¨åº“å­˜æ•°æ®æ¥æºï¼ŒåŒ…æ‹¬ï¼š
- æ•°æ®æ¥æºï¼šä¸ŠæœŸæ‰€åº“å­˜æ•°æ®ï¼ˆæœ¬åœ°æ•°æ®åº“ï¼‰
- æ•°æ®è·¯å¾„ï¼šqihuo/database/inventory/å“ç§/inventory.csv
- æ•°æ®ç‰¹å¾ï¼šæ—¥åº¦æ›´æ–°ï¼Œå®Œæ•´æ— ç¼ºå¤±ï¼ŒçœŸå®å¯é 
- å†å²åˆ†ä½æ•°è®¡ç®—åŸºäºå®Œæ•´å†å²æ•°æ®åºåˆ—

ç¬¬å››éƒ¨åˆ†: ç©ºé—´ä¸å‡è¡¡ä¸åŒºåŸŸåŸºå·®å·®å¼‚
åˆ†æåŸºå·®çš„ç©ºé—´å±æ€§ï¼Œè¯„ä¼°åŒºåŸŸå¸‚åœºå¼ºå¼±å·®å¼‚ï¼Œè¯†åˆ«ç©ºé—´å¥—åˆ©æœºä¼šã€‚

ç¬¬äº”éƒ¨åˆ†: å“è´¨å·®å¼‚å¯¹åŸºå·®ç»“æ„çš„å½±å“
åŸºäºå“ç§æ ‡å‡†åŒ–ç¨‹åº¦ï¼Œåˆ†æå“è´¨å·®å¼‚å¦‚ä½•å½±å“åŸºå·®ç»“æ„å’Œå‡è´´æ°´å…³ç³»ã€‚

ç¬¬å…­éƒ¨åˆ†: ç»¼åˆäº¤æ˜“ç­–ç•¥ä¸é£é™©ç®¡ç†
æ•´åˆå››ç»´åˆ†æç»“æœï¼Œæå‡ºå…·ä½“çš„æœŸç°å¥—åˆ©ã€è·¨æœŸå¥—åˆ©ç­–ç•¥ï¼Œæ˜ç¡®é£é™©æ§åˆ¶æªæ–½ã€‚

è¾“å‡ºè¦æ±‚:
- ä¸¥æ ¼åŸºäºçœŸå®æ•°æ®ï¼Œç¦æ­¢ç¼–é€ 
- ä¸“ä¸šæœ¯è¯­å‡†ç¡®ï¼Œé€»è¾‘æ¸…æ™°
- æ€»å­—æ•°3000-4000å­—
- å¼•ç”¨å¤–éƒ¨ä¿¡æ¯æ—¶ä½¿ç”¨æ ‡æ³¨çš„å¼•ç”¨ç¼–å·
- ä¸¥ç¦ä½¿ç”¨ä»»ä½•markdownç¬¦å·ï¼ˆåŒ…æ‹¬ä½†ä¸é™äº: #ã€##ã€###ã€**ã€*ã€_ã€```ç­‰ï¼‰ï¼Œé‡‡ç”¨çº¯æ–‡æœ¬æ ¼å¼
- ç»å¯¹ä¸å…è®¸ä½¿ç”¨ä»»ä½•å½¢å¼çš„æ ‡é¢˜ç¬¦å·ï¼ŒåŒ…æ‹¬ # ## ### ç­‰ï¼Œæ‰€æœ‰æ ‡é¢˜éƒ½ç”¨çº¯æ–‡æœ¬è¡¨ç¤º
- åœ¨ç›¸åº”åˆ†æä¸­å¼•ç”¨å¯¹åº”å›¾è¡¨ï¼Œæ ¼å¼å¦‚"å¦‚å›¾1æ‰€ç¤º"æˆ–"å›¾2æ˜¾ç¤º"
- æ¯ä¸ªéƒ¨åˆ†ç»“å°¾è¦æœ‰æ˜ç¡®çš„ç»“è®º
"""
        
        return prompt

class EnhancedDeepSeekClient:
    """å¢å¼ºç‰ˆDeepSeekå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str = DEEPSEEK_API_KEY):
        self.api_key = api_key
        self.base_url = DEEPSEEK_BASE_URL
        
    def chat(self, messages: List[Dict], model: str = "deepseek-chat", 
             temperature: float = 0.1, max_tokens: int = 4000) -> str:
        """å‘é€èŠå¤©è¯·æ±‚"""
        try:
            payload = {
                "model": model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens
            }
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            response = requests.post(self.base_url, json=payload, headers=headers, timeout=120)
            response.raise_for_status()
            
            data = response.json()
            return data["choices"][0]["message"]["content"]
            
        except Exception as e:
            return f"åˆ†æå¤±è´¥: {str(e)}"

class ProfessionalBasisAnalysisSystem:
    """ä¸“ä¸šåŸºå·®åˆ†æç³»ç»Ÿ - å››ç»´åº¦åˆ†ææ¡†æ¶"""
    
    def __init__(self):
        self.analyzer = MultidimensionalBasisAnalyzer()
        self.llm_client = EnhancedDeepSeekClient()
        print("ğŸ¤– ä¸“ä¸šåŸºå·®åˆ†æç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print("ğŸ“Š é›†æˆå››ç»´åº¦åˆ†ææ¡†æ¶: å“è´¨ã€ç©ºé—´ã€æ—¶é—´ã€åº“å­˜")
    
    def get_available_varieties(self) -> List[str]:
        """è·å–å¯ç”¨å“ç§åˆ—è¡¨ï¼ˆæ‰©å±•ç‰ˆ - æ”¯æŒæœ¬åœ°æ•°æ®+è”ç½‘è·å–ï¼‰"""
        # è¿”å›æ‰©å±•çš„å“ç§åˆ—è¡¨ï¼Œç†è®ºä¸Šæ”¯æŒæ‰€æœ‰åœ¨VARIETY_NAMESä¸­çš„å“ç§
        return sorted(list(VARIETY_NAMES.keys()))
    
    def show_available_varieties(self):
        """æ˜¾ç¤ºå¯ç”¨å“ç§ï¼ˆå¢å¼ºç‰ˆ - æ˜¾ç¤ºæœ¬åœ°æ•°æ®å’Œè”ç½‘è·å–çŠ¶æ€ï¼‰"""
        varieties = self.get_available_varieties()
        
        # æ£€æŸ¥æœ¬åœ°æ•°æ®å¯ç”¨æ€§
        local_varieties = []
        basis_dir = DATA_ROOT / "basis"
        if basis_dir.exists():
            for d in basis_dir.iterdir():
                if d.is_dir() and (d / "basis_data.csv").exists():
                    local_varieties.append(d.name)
        
        # æŒ‰æ¿å—åˆ†ç±»
        categories = {
            "è´µé‡‘å±": ['AU', 'AG'],
            "æœ‰è‰²é‡‘å±": ['CU', 'AL', 'ZN', 'PB', 'NI', 'SN', 'BC', 'AO'],
            "é»‘è‰²ç³»": ['RB', 'HC', 'I', 'JM', 'J', 'SS', 'WR', 'FG', 'SA'],
            "èƒ½æºåŒ–å·¥": ['SC', 'FU', 'LU', 'BU', 'RU', 'NR', 'BR', 'SP', 'LG', 'TA', 'MA', 'PP', 'V', 'L', 'EB', 'EG', 'PG', 'PF', 'UR', 'SF', 'SM', 'PS', 'LC', 'SI', 'PX', 'PR'],
            "å†œäº§å“": ['A', 'B', 'M', 'Y', 'C', 'CS', 'CF', 'CY', 'SR', 'P', 'OI', 'RM', 'RS', 'JD', 'LH', 'PK', 'AP', 'CJ', 'WH', 'PM', 'RI', 'LR', 'JR'],
            "å…¶ä»–": ['SH']
        }
        
        print("\n" + "="*90)
        print("ğŸ“Š å¯ç”¨å“ç§åˆ—è¡¨ - è”ç½‘å¢å¼ºç‰ˆåŸºå·®åˆ†æç³»ç»Ÿ")
        print("="*90)
        print("å›¾ä¾‹: âœ… æœ¬åœ°æ•°æ®  ğŸŒ è”ç½‘è·å–  â­ æ··åˆæ¨¡å¼")
        print("="*90)
        
        total_local = 0
        total_network = 0
        
        for category, symbols in categories.items():
            available_in_category = [s for s in symbols if s in varieties]
            if available_in_category:
                print(f"\n{category} ({len(available_in_category)}ä¸ª):")
                for symbol in available_in_category:
                    name = VARIETY_NAMES.get(symbol, symbol)
                    if symbol in local_varieties:
                        print(f"  âœ… {symbol}({name}) - æœ¬åœ°æ•°æ®å¯ç”¨")
                        total_local += 1
                    else:
                        print(f"  ğŸŒ {symbol}({name}) - è”ç½‘è·å–")
                        total_network += 1
        
        print(f"\n" + "="*90)
        print(f"ğŸ“ˆ åˆ†æèƒ½åŠ›:")
        print(f"  âœ… æœ¬åœ°æ•°æ®å“ç§: {total_local}ä¸ª (æ··åˆåˆ†ææ¨¡å¼)")
        print(f"  ğŸŒ è”ç½‘è·å–å“ç§: {total_network}ä¸ª (çº¯ç½‘ç»œåˆ†ææ¨¡å¼)")
        print(f"  ğŸ“Š æ€»æ”¯æŒå“ç§: {len(varieties)}ä¸ª")
        
        print(f"\nğŸš€ ç³»ç»Ÿç‰¹è‰²:")
        print(f"  â€¢ æœ¬åœ°æ•°æ®ä¼˜å…ˆï¼Œè”ç½‘è¡¥å……çš„æ™ºèƒ½ç­–ç•¥")
        print(f"  â€¢ è‡ªåŠ¨åˆ¤æ–­åˆ†ææ¨¡å¼ï¼Œæ— éœ€ç”¨æˆ·å…³å¿ƒæ•°æ®æ¥æº") 
        print(f"  â€¢ ç†è®ºä¸Šæ”¯æŒæ‰€æœ‰ä¸­å›½æœŸè´§å“ç§åˆ†æ")
        print(f"  â€¢ akshare API + Serperæœç´¢åŒé‡æ•°æ®ä¿éšœ")
        print("="*90)
    
    def analyze_variety_comprehensive(self, variety: str, analysis_date: str = None, 
                                    use_reasoner: bool = False) -> Dict:
        """ç»¼åˆå››ç»´åº¦åŸºå·®åˆ†æ"""
        
        print(f"\nğŸš€ å¼€å§‹åˆ†æ {variety}({VARIETY_NAMES.get(variety, variety)}) - å››ç»´åº¦åˆ†ææ¡†æ¶")
        print("=" * 80)
        
        # 1. åŠ è½½ç»¼åˆæ•°æ®åŒ…
        print("ğŸ“Š æ­¥éª¤1: åŠ è½½å¤šæºæ•°æ®...")
        data_package = self.analyzer.load_comprehensive_data(variety, analysis_date)
        
        if data_package.basis_data.empty:
            return {"error": f"å“ç§ {variety} çš„åŸºå·®æ•°æ®ä¸å¯ç”¨"}
        
        # 2. å››ç»´åº¦åˆ†æ
        print("ğŸ” æ­¥éª¤2: æ‰§è¡Œå››ç»´åº¦åˆ†æ...")
        
        # æ—¶é—´ç»´åº¦ - è¿ç»­åŸºå·®åˆ†æ
        continuous_analysis = self.analyzer.analyze_continuous_basis(data_package)
        
        # å­£èŠ‚æ€§åˆ†æ
        seasonal_analysis = self.analyzer.analyze_seasonal_pattern(data_package)
        
        # åº“å­˜ç»´åº¦ - åº“å­˜åŸºå·®å…³ç³»
        inventory_analysis = self.analyzer.analyze_inventory_basis_relationship(data_package)
        
        # ç©ºé—´ç»´åº¦ - åŒºåŸŸå·®å¼‚åˆ†æ  
        spatial_analysis = self.analyzer.analyze_spatial_basis_differences(data_package, {})
        
        # å“è´¨ç»´åº¦ - å“è´¨å·®å¼‚åˆ†æ
        quality_analysis = self.analyzer.analyze_quality_basis_differences(data_package)
        
        # 3. æœç´¢å¢å¼ºå¸‚åœºèƒŒæ™¯
        print("ğŸŒ æ­¥éª¤3: æœç´¢å¸‚åœºèƒŒæ™¯ä¿¡æ¯...")
        market_context = self.analyzer.search_enhanced_market_context(data_package)
        
        # æ›´æ–°ç©ºé—´åˆ†æï¼ˆåŒ…å«æœç´¢ç»“æœï¼‰
        spatial_analysis = self.analyzer.analyze_spatial_basis_differences(data_package, market_context)
        
        # 4. ç”Ÿæˆä¸“ä¸šå›¾è¡¨
        print("ğŸ“Š æ­¥éª¤4: ç”Ÿæˆä¸“ä¸šå›¾è¡¨...")
        professional_charts = self.analyzer.create_professional_charts(data_package)
        
        # 5. ç”Ÿæˆç»¼åˆåˆ†æprompt
        print("ğŸ§  æ­¥éª¤5: ç”ŸæˆAIåˆ†æ...")
        prompt = self.analyzer.create_comprehensive_analysis_prompt(
            data_package, continuous_analysis, seasonal_analysis,
            inventory_analysis, spatial_analysis, quality_analysis, market_context
        )
        
        # 6. AIæ·±åº¦åˆ†æ
        model = "deepseek-reasoner" if use_reasoner else "deepseek-chat"
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸“ä¸šçš„æœŸè´§åŸºå·®åˆ†æå¸ˆï¼Œä¸¥æ ¼åŸºäºäº‹å®æ•°æ®è¿›è¡Œå››ç»´åº¦åˆ†æï¼Œç»ä¸ç¼–é€ ä¿¡æ¯ã€‚"
            },
            {
                "role": "user", 
                "content": prompt
            }
        ]
        
        ai_analysis = self.llm_client.chat(messages, model=model, temperature=0.1, max_tokens=5000)
        
        # 7. æ•´åˆç»“æœ
        result = {
            "variety": variety,
            "variety_name": data_package.variety_name,
            "analysis_date": data_package.analysis_date,
            "analysis_framework": "å››ç»´åº¦åŸºå·®åˆ†ææ¡†æ¶",
            "analysis_mode": "Reasoneræ·±åº¦æ¨ç†" if use_reasoner else "æ ‡å‡†åˆ†æ",
            "data_quality": data_package.data_quality,
            "continuous_basis_analysis": continuous_analysis,
            "seasonal_analysis": seasonal_analysis,
            "inventory_basis_analysis": inventory_analysis,
            "spatial_analysis": spatial_analysis,
            "quality_analysis": quality_analysis,
            "market_context": market_context,
            "professional_charts": professional_charts,
            "ai_comprehensive_analysis": ai_analysis,
            "external_citations": self.analyzer.searcher.get_citations(),
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # 8. æ˜¾ç¤ºç»“æœ
        self.display_comprehensive_result(result)
        
        return result
    
    def display_comprehensive_result(self, result: Dict):
        """æ˜¾ç¤ºç»¼åˆåˆ†æç»“æœ"""
        
        variety = result["variety"]
        variety_name = result["variety_name"]
        analysis_date = result["analysis_date"]
        
        print("\n" + "="*100)
        print(f"ğŸ¯ {variety}({variety_name}) ä¸“ä¸šåŸºå·®åˆ†ææŠ¥å‘Š")
        print(f"ğŸ“… åˆ†ææ—¥æœŸ: {analysis_date}")
        print(f"ğŸ§  åˆ†ææ¨¡å¼: {result['analysis_mode']}")
        print(f"ğŸ“Š åˆ†ææ¡†æ¶: {result['analysis_framework']}")
        print("="*100)
        
        # æ•°æ®è´¨é‡æ¦‚è§ˆ
        print("\nğŸ“‹ æ•°æ®è´¨é‡è¯„ä¼°:")
        for data_type, quality in result["data_quality"].items():
            status = "âœ…" if quality == "å¯ç”¨" else "âŒ"
            print(f"  {status} {data_type}: {quality}")
        
        # æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ
        continuous = result["continuous_basis_analysis"]
        seasonal = result["seasonal_analysis"]
        inventory = result["inventory_basis_analysis"]
        
        print(f"\nğŸ” æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ:")
        print(f"  è¿ç»­åŸºå·®: {continuous.get('current_continuous_basis', 'N/A')} å…ƒ/å¨")
        print(f"  ä¸»åŠ›åŸºå·®: {continuous.get('current_main_basis', 'N/A')} å…ƒ/å¨")
        print(f"  å­£èŠ‚æ€§åç¦»: {seasonal.get('seasonal_deviation', 'N/A')} å…ƒ/å¨")
        print(f"  åº“å­˜æ°´å¹³: {inventory.get('inventory_level', 'æœªçŸ¥')}")
        print(f"  åŒºåŸŸåˆ†ç±»: {inventory.get('region_classification', 'æœªç¡®å®š')}")
        
        # AIåˆ†æç»“æœä¸å›¾è¡¨é›†æˆæ˜¾ç¤º
        print(f"\nğŸ§  AIç»¼åˆåˆ†æç»“æœ:")
        print("-" * 80)
        
        # åˆ†æ®µæ˜¾ç¤ºåˆ†æå†…å®¹ï¼Œå¹¶åœ¨ç›¸åº”ä½ç½®æ’å…¥å›¾è¡¨
        ai_analysis = result["ai_comprehensive_analysis"]
        charts = result.get("professional_charts", {})
        
        # å°†åˆ†æå†…å®¹æŒ‰éƒ¨åˆ†åˆ†å‰²
        sections = ai_analysis.split("ç¬¬ä¸€éƒ¨åˆ†:")
        if len(sections) > 1:
            # æ˜¾ç¤ºå‰è¨€
            print(sections[0].strip())
            
            # å¤„ç†å„ä¸ªéƒ¨åˆ†
            remaining_content = "ç¬¬ä¸€éƒ¨åˆ†:" + sections[1]
            parts = remaining_content.split("ç¬¬")
            
            for i, part in enumerate(parts):
                if not part.strip():
                    continue
                
                if i == 0:
                    print(f"\nç¬¬{part}")
                else:
                    print(f"\nç¬¬{part}")
                
                # åœ¨ç›¸åº”éƒ¨åˆ†åæ’å…¥å›¾è¡¨
                if "ä¸€éƒ¨åˆ†:" in part and 'basis_trend' in charts:
                    print("\n" + "="*60)
                    print("ğŸ“Š å›¾1: åŸºå·®èµ°åŠ¿åˆ†æ")
                    print("="*60)
                    # è¿™é‡Œæ˜¾ç¤ºå›¾è¡¨çš„æ–‡å­—æè¿°ï¼Œå®é™…HTMLå›¾è¡¨ä¼šåœ¨ä¸‹æ–¹æ˜¾ç¤º
                    print("åŸºå·®èµ°åŠ¿å›¾æ˜¾ç¤ºäº†ä¸»åŠ›åŸºå·®å’Œè¿ç»­åŸºå·®çš„å˜åŒ–è¶‹åŠ¿ï¼Œä»¥åŠæ”¶æ•›æ€§åˆ†æ")
                    
                elif "äºŒéƒ¨åˆ†:" in part and 'seasonal_pattern' in charts:
                    print("\n" + "="*60)
                    print("ğŸ“Š å›¾2: å­£èŠ‚æ€§åŸºå·®è§„å¾‹")
                    print("="*60)
                    print("å­£èŠ‚æ€§å›¾è¡¨æ˜¾ç¤ºäº†æœˆåº¦åŸºå·®å‡å€¼ã€æ ‡å‡†å·®åŒºé—´ä»¥åŠå½“å‰æœˆä»½çš„ä½ç½®")
                    
                elif "ä¸‰éƒ¨åˆ†:" in part and 'inventory_level' in charts:
                    print("\n" + "="*60)
                    print("ğŸ“Š å›¾3: åº“å­˜æ°´å¹³åˆ†æ")
                    print("="*60)
                    print("åº“å­˜å›¾è¡¨æ˜¾ç¤ºäº†åº“å­˜èµ°åŠ¿ä»¥åŠå†å²åˆ†ä½æ•°å‚è€ƒçº¿")
                    
                elif "äº”éƒ¨åˆ†:" in part and 'term_structure' in charts:
                    print("\n" + "="*60)
                    print("ğŸ“Š å›¾4: æœŸé™ç»“æ„æ›²çº¿")
                    print("="*60)
                    print("æœŸé™ç»“æ„å›¾è¡¨æ˜¾ç¤ºäº†å„åˆçº¦çš„ä»·æ ¼åˆ†å¸ƒæƒ…å†µ")
        else:
            print(ai_analysis)
        
        print("-" * 80)
        
        # æ˜¾ç¤ºä¸“ä¸šå›¾è¡¨
        if result.get("professional_charts"):
            print(f"\nğŸ“Š ä¸“ä¸šå›¾è¡¨é›†æˆå±•ç¤º:")
            print("="*80)
            charts = result["professional_charts"]
            
            if 'basis_trend' in charts:
                print("\nğŸ“ˆ å›¾1: åŸºå·®èµ°åŠ¿åˆ†æ")
                print("-"*40)
                try:
                    # å°è¯•åœ¨æ”¯æŒHTMLçš„ç¯å¢ƒä¸­æ˜¾ç¤ºå›¾è¡¨
                    from IPython.display import display, HTML
                    display(HTML(charts['basis_trend']))
                except:
                    # åœ¨å‘½ä»¤è¡Œç¯å¢ƒä¸­æ˜¾ç¤ºå›¾è¡¨æè¿°
                    print("åŸºå·®èµ°åŠ¿å›¾åŒ…å«ï¼š")
                    print("- ä¸»åŠ›åŸºå·®èµ°åŠ¿çº¿ï¼ˆè“è‰²ï¼‰")
                    print("- è¿ç»­åŸºå·®èµ°åŠ¿çº¿ï¼ˆçº¢è‰²ï¼‰") 
                    print("- 10æ—¥æ»šåŠ¨æ³¢åŠ¨ç‡ï¼ˆç»¿è‰²ï¼Œä¸‹å›¾ï¼‰")
                    print("- æ˜¾ç¤ºåŸºå·®æ”¶æ•›æ€§å’Œæ—¶é—´è¡°å‡ç‰¹å¾")
                    
            if 'seasonal_pattern' in charts:
                print("\nğŸ“Š å›¾2: å­£èŠ‚æ€§åŸºå·®è§„å¾‹")
                print("-"*40)
                try:
                    from IPython.display import display, HTML
                    display(HTML(charts['seasonal_pattern']))
                except:
                    print("å­£èŠ‚æ€§åŸºå·®å›¾åŒ…å«ï¼š")
                    print("- æœˆåº¦åŸºå·®å‡å€¼æ›²çº¿ï¼ˆè“è‰²ï¼‰")
                    print("- æ ‡å‡†å·®åŒºé—´ï¼ˆæµ…è“è‰²é˜´å½±ï¼‰")
                    print("- å½“å‰æœˆä»½ä½ç½®æ ‡è®°ï¼ˆçº¢è‰²æ˜Ÿæ ‡ï¼‰")
                    print("- æ˜¾ç¤ºå­£èŠ‚æ€§åç¦»ç¨‹åº¦")
                    
            if 'inventory_level' in charts:
                print("\nğŸ“¦ å›¾3: åº“å­˜æ°´å¹³åˆ†æ")
                print("-"*40)
                try:
                    from IPython.display import display, HTML
                    display(HTML(charts['inventory_level']))
                except:
                    print("åº“å­˜æ°´å¹³å›¾åŒ…å«ï¼š")
                    print("- åº“å­˜èµ°åŠ¿çº¿ï¼ˆç´«è‰²ï¼‰")
                    print("- 20%åˆ†ä½æ•°çº¿ï¼ˆçº¢è‰²è™šçº¿ï¼‰")
                    print("- 50%åˆ†ä½æ•°çº¿ï¼ˆæ©™è‰²è™šçº¿ï¼‰")
                    print("- 80%åˆ†ä½æ•°çº¿ï¼ˆç»¿è‰²è™šçº¿ï¼‰")
                    print("- æ˜¾ç¤ºå½“å‰åº“å­˜å†å²åˆ†ä½æ•°")
                    
            if 'term_structure' in charts:
                print("\nğŸ“‰ å›¾4: æœŸé™ç»“æ„æ›²çº¿")
                print("-"*40)
                try:
                    from IPython.display import display, HTML
                    display(HTML(charts['term_structure']))
                except:
                    print("æœŸé™ç»“æ„å›¾åŒ…å«ï¼š")
                    print("- å„åˆçº¦ä»·æ ¼æ›²çº¿ï¼ˆè“è‰²ï¼‰")
                    print("- åˆçº¦æŒ‰æœˆä»½æ’åº")
                    print("- æ˜¾ç¤ºContango/Backwardationç»“æ„")
                    print("- åæ˜ å¸‚åœºå¯¹æœªæ¥ä»·æ ¼é¢„æœŸ")
            
            print("\nğŸ’¡ å›¾è¡¨è¯´æ˜ï¼š")
            print("- åœ¨Jupyterç¯å¢ƒä¸­å¯æŸ¥çœ‹äº¤äº’å¼å›¾è¡¨")
            print("- åœ¨å‘½ä»¤è¡Œç¯å¢ƒä¸­æ˜¾ç¤ºå›¾è¡¨æè¿°")
            print("="*80)
        
        # å¤–éƒ¨å¼•ç”¨ä¿¡æ¯
        if result.get("external_citations"):
            print(f"\nğŸ“š å¤–éƒ¨æ•°æ®æ¥æº:")
            for citation in result["external_citations"][:10]:  # æ˜¾ç¤ºå‰10ä¸ªå¼•ç”¨
                print(f"  {citation['id']} {citation['title']}")
                print(f"      é“¾æ¥: {citation['link']}")
        
        print(f"\nâ° åˆ†æå®Œæˆæ—¶é—´: {result['timestamp']}")
        print("="*100)
    
    def _save_charts_to_files(self, charts: Dict, variety: str, analysis_date: str):
        """ä¿å­˜å›¾è¡¨åˆ°æ–‡ä»¶"""
        
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            chart_dir = OUTPUT_DIR / "charts" / variety
            chart_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜å„ä¸ªå›¾è¡¨
            chart_names = {
                'basis_trend': 'åŸºå·®èµ°åŠ¿åˆ†æ',
                'seasonal_pattern': 'å­£èŠ‚æ€§åŸºå·®è§„å¾‹', 
                'inventory_level': 'åº“å­˜æ°´å¹³åˆ†æ',
                'term_structure': 'æœŸé™ç»“æ„æ›²çº¿'
            }
            
            for chart_key, chart_html in charts.items():
                if chart_key in chart_names:
                    filename = f"{variety}_{chart_key}_{analysis_date}.html"
                    filepath = chart_dir / filename
                    
                    with open(filepath, 'w', encoding='utf-8') as f:
                        f.write(chart_html)
                    
                    print(f"    ğŸ“ {chart_names[chart_key]}: {filepath}")
            
        except Exception as e:
            print(f"    âŒ å›¾è¡¨ä¿å­˜å¤±è´¥: {str(e)}")
    
    def start_interactive_analysis(self):
        """å¯åŠ¨äº¤äº’å¼åˆ†æ"""
        
        print("\n" + "="*100)
        print("ğŸ¤– ä¸“ä¸šAIåŸºå·®åˆ†æç³»ç»Ÿ - å››ç»´åº¦åˆ†ææ¡†æ¶")
        print("ğŸ“Š é›†æˆå“è´¨ã€ç©ºé—´ã€æ—¶é—´ã€åº“å­˜å››å¤§ç»´åº¦åˆ†æ")
        print("âœ… ä¸¥ç¦æ•°æ®ç¼–é€ ï¼Œç¡®ä¿åˆ†æè¯šå®æ€§")
        print("ğŸŒ é›†æˆå®æ—¶æœç´¢ï¼Œæ ‡æ³¨å¤–éƒ¨å¼•ç”¨")
        print("="*100)
        
        while True:
            try:
                print("\n" + "-"*60)
                print("è¯·è¾“å…¥åˆ†æå‚æ•° (è¾“å…¥ 'quit' é€€å‡ºï¼Œ'help' æŸ¥çœ‹å¸®åŠ©):")
                
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nè¯·è¾“å…¥å‘½ä»¤: ").strip()
                
                if user_input.lower() == 'quit':
                    print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ä¸“ä¸šåŸºå·®åˆ†æç³»ç»Ÿï¼")
                    break
                elif user_input.lower() == 'help':
                    self.show_help()
                    continue
                elif user_input.lower() == 'varieties':
                    self.show_available_varieties()
                    continue
                
                # è§£æè¾“å…¥å‚æ•°
                if ',' in user_input:
                    parts = [p.strip() for p in user_input.split(',')]
                else:
                    parts = [user_input]
                
                if len(parts) < 1:
                    print("âŒ è¯·è‡³å°‘è¾“å…¥å“ç§ä»£ç ")
                    continue
                
                variety = parts[0].upper()
                analysis_date = parts[1] if len(parts) > 1 and parts[1] else None
                model_mode = parts[2] if len(parts) > 2 else "chat"
                
                # éªŒè¯å“ç§
                available_varieties = self.get_available_varieties()
                if variety not in available_varieties:
                    print(f"âŒ å“ç§ {variety} ä¸å¯ç”¨")
                    print("ğŸ’¡ è¾“å…¥ 'varieties' æŸ¥çœ‹å¯ç”¨å“ç§")
                    continue
                
                # éªŒè¯æ—¥æœŸ
                if analysis_date:
                    try:
                        datetime.strptime(analysis_date, '%Y-%m-%d')
                    except ValueError:
                        print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
                        continue
                
                # éªŒè¯æ¨¡å‹æ¨¡å¼
                use_reasoner = model_mode.lower() in ['reasoner', 'r']
                
                # æ‰§è¡Œåˆ†æ
                print(f"\nğŸš€ å¼€å§‹åˆ†æ {variety}...")
                if analysis_date:
                    print(f"ğŸ“… åˆ†ææ—¥æœŸ: {analysis_date}")
                print(f"ğŸ¤– åˆ†ææ¨¡å‹: {'DeepSeek Reasoner' if use_reasoner else 'DeepSeek Chat'}")
                
                result = self.analyze_variety_comprehensive(variety, analysis_date, use_reasoner)
                
                if "error" in result:
                    print(f"âŒ åˆ†æå¤±è´¥: {result['error']}")
                else:
                    print("\nâœ… åˆ†æå®Œæˆï¼")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ åˆ†æå·²ä¸­æ–­ï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
                continue
    
    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        print("\n" + "="*80)
        print("ğŸ“– ä½¿ç”¨å¸®åŠ©")
        print("="*80)
        print("è¾“å…¥æ ¼å¼: å“ç§ä»£ç [,åˆ†ææ—¥æœŸ,æ¨¡å‹æ¨¡å¼]")
        print("\nå‚æ•°è¯´æ˜:")
        print("  å“ç§ä»£ç : å¿…éœ€ï¼Œå¦‚ RB, CU, M ç­‰")
        print("  åˆ†ææ—¥æœŸ: å¯é€‰ï¼Œæ ¼å¼ YYYY-MM-DDï¼Œé»˜è®¤ä¸ºæœ€æ–°æ•°æ®")
        print("  æ¨¡å‹æ¨¡å¼: å¯é€‰ï¼Œchat(é»˜è®¤) æˆ– reasoner")
        print("\nä½¿ç”¨ç¤ºä¾‹:")
        print("  RB                    # åˆ†æèºçº¹é’¢ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
        print("  CU,2025-01-01         # åˆ†ææ²ªé“œï¼ŒæŒ‡å®šæ—¥æœŸ")
        print("  M,,reasoner           # åˆ†æè±†ç²•ï¼Œä½¿ç”¨Reasoneræ¨¡å‹")
        print("  RM,2024-12-01,r       # åˆ†æèœç²•ï¼ŒæŒ‡å®šæ—¥æœŸå’ŒReasoneræ¨¡å‹")
        print("\nå…¶ä»–å‘½ä»¤:")
        print("  varieties             # æŸ¥çœ‹å¯ç”¨å“ç§")
        print("  help                  # æ˜¾ç¤ºå¸®åŠ©")
        print("  quit                  # é€€å‡ºç³»ç»Ÿ")
        print("="*80)

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    system = ProfessionalBasisAnalysisSystem()
    system.start_interactive_analysis()
