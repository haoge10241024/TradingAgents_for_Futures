#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Streamlitå¢å¼ºç‰ˆæŒä»“åˆ†æé€‚é…å™¨
å°†enhanced_positioning_analysis_system.pyé€‚é…åˆ°Streamlitç³»ç»Ÿä¸­
"""

import asyncio
import sys
from pathlib import Path
from typing import Dict, Any, Optional
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# å¯¼å…¥å¢å¼ºç‰ˆæŒä»“åˆ†æç³»ç»Ÿ
from enhanced_positioning_analysis_system import (
    EnhancedPositioningAnalysisEngine,
    SYMBOL_NAMES
)

class StreamlitEnhancedPositioningAdapter:
    """Streamlitå¢å¼ºç‰ˆæŒä»“åˆ†æé€‚é…å™¨"""
    
    def __init__(self):
        self.engine = EnhancedPositioningAnalysisEngine()
    
    def analyze_positioning_for_streamlit(self, symbol: str, analysis_date: str = None, 
                                        use_reasoner: bool = True) -> Dict[str, Any]:
        """
        ä¸ºStreamlitç³»ç»Ÿæä¾›æŒä»“åˆ†æ
        
        Args:
            symbol: å“ç§ä»£ç 
            analysis_date: åˆ†ææ—¥æœŸ
            use_reasoner: æ˜¯å¦ä½¿ç”¨reasoneræ¨¡å‹
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        try:
            # è¿è¡Œå¼‚æ­¥åˆ†æ - ä¿®å¤äº‹ä»¶å¾ªç¯é—®é¢˜
            try:
                # å°è¯•è·å–å½“å‰äº‹ä»¶å¾ªç¯
                loop = asyncio.get_running_loop()
                # å¦‚æœå·²æœ‰äº‹ä»¶å¾ªç¯ï¼Œä½¿ç”¨create_task
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(
                        asyncio.run,
                        self.engine.analyze_variety_comprehensive(
                            symbol=symbol,
                            analysis_date=analysis_date,
                            use_reasoner=use_reasoner
                        )
                    )
                    result = future.result()
            except RuntimeError:
                # æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œç›´æ¥ä½¿ç”¨asyncio.run
                result = asyncio.run(
                    self.engine.analyze_variety_comprehensive(
                        symbol=symbol,
                        analysis_date=analysis_date,
                        use_reasoner=use_reasoner
                    )
                )
            
            # å¤„ç†ç»“æœæ ¼å¼åŒ–
            if result.get("success"):
                return self._format_for_streamlit(result)
            else:
                return {
                    "success": False,
                    "error": result.get("error", "åˆ†æå¤±è´¥"),
                    "symbol": symbol,
                    "symbol_name": SYMBOL_NAMES.get(symbol.upper(), symbol)
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"æŒä»“åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                "symbol": symbol,
                "symbol_name": SYMBOL_NAMES.get(symbol.upper(), symbol)
            }
    
    def _format_for_streamlit(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–ç»“æœä»¥é€‚é…Streamlitæ˜¾ç¤º"""
        
        formatted_result = {
            "success": True,
            "symbol": result.get("symbol", ""),
            "symbol_name": result.get("symbol_name", ""),
            "analysis_date": result.get("analysis_date", ""),
            "model_used": result.get("model_used", ""),
            "data_points": result.get("data_points", 0),
            "data_quality_score": result.get("data_quality_score", 0.0)
        }
        
        # æå–æ ¸å¿ƒåˆ†æç»“æœ
        if "professional_analysis" in result:
            professional_content = result["professional_analysis"]
            formatted_result["ai_analysis"] = professional_content
            
            # æ£€æŸ¥professional_analysisæ˜¯å¦ä¸ºJSONæ ¼å¼
            if isinstance(professional_content, str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ä¸”ä¸ä¸ºç©ºï¼Œç›´æ¥ä½¿ç”¨
                if len(professional_content.strip()) > 0:
                    formatted_result["analysis_content"] = professional_content
                else:
                    # å¦‚æœprofessional_analysisä¸ºç©ºï¼Œå°è¯•ä»structured_analysisç”Ÿæˆ
                    if "structured_analysis" in result:
                        analysis_content = self._generate_analysis_content_from_structured(result["structured_analysis"])
                        formatted_result["analysis_content"] = analysis_content
            else:
                # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                formatted_result["analysis_content"] = str(professional_content)
        else:
            # å¦‚æœæ²¡æœ‰professional_analysiså­—æ®µï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç»“æ„åŒ–åˆ†ææ•°æ®
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›´æ¥çš„ç»“æ„åŒ–åˆ†æå­—æ®µï¼ˆå¦‚spider_web_analysisç­‰ï¼‰
            structured_data = {}
            analysis_fields = ["spider_web_analysis", "smart_money_analysis", "seat_behavior_analysis", 
                             "concentration_analysis", "comprehensive_conclusion", "trading_recommendations"]
            
            for field in analysis_fields:
                if field in result:
                    structured_data[field] = result[field]
            
            if structured_data:
                # æœ‰ç»“æ„åŒ–æ•°æ®ï¼Œç”Ÿæˆæ–‡æœ¬åˆ†æ
                analysis_content = self._generate_analysis_content_from_structured(structured_data)
                formatted_result["ai_analysis"] = analysis_content
                formatted_result["analysis_content"] = analysis_content
                formatted_result["structured_analysis"] = structured_data
            elif "structured_analysis" in result:
                # ä»structured_analysisç”Ÿæˆæ–‡æœ¬åˆ†æ
                analysis_content = self._generate_analysis_content_from_structured(result["structured_analysis"])
                formatted_result["ai_analysis"] = analysis_content
                formatted_result["analysis_content"] = analysis_content
        
        # æå–ç»“æ„åŒ–åˆ†æç»“æœï¼ˆå¦‚æœæœ‰JSONæ ¼å¼ï¼‰
        analysis_sections = {}
        
        # å°è¯•è§£æç»“æ„åŒ–åˆ†æç»“æœ
        for key in ["spider_web_analysis", "smart_money_analysis", "seat_behavior_analysis", 
                   "concentration_analysis", "comprehensive_conclusion", "trading_recommendations"]:
            if key in result:
                analysis_sections[key] = result[key]
        
        if analysis_sections:
            formatted_result["structured_analysis"] = analysis_sections
        
        # æå–æ–¹æ³•è®ºè§£é‡Š
        if "methodology_explanation" in result:
            formatted_result["methodology"] = result["methodology_explanation"]
        
        # æå–æ”¯æ’‘æ•°æ®
        if "supporting_data" in result:
            formatted_result["supporting_data"] = result["supporting_data"]
        
        # æå–å›¾è¡¨ - è½¬æ¢ä¸ºä¸»ç•Œé¢æœŸæœ›çš„æ ¼å¼
        if "professional_charts" in result:
            charts_dict = result["professional_charts"]

            if charts_dict:
                if len(charts_dict) == 1:
                    # å•ä¸ªå›¾è¡¨ï¼Œç›´æ¥ä½¿ç”¨å›¾è¡¨å¯¹è±¡
                    chart_key = list(charts_dict.keys())[0]
                    formatted_result["charts_html"] = charts_dict[chart_key]
                    print(f"âœ… æŒä»“åˆ†æå›¾è¡¨æ•°æ®å·²è½¬æ¢: å•ä¸ªå›¾è¡¨ '{chart_key}'")
                else:
                    # å¤šä¸ªå›¾è¡¨ï¼Œä¿æŒå­—å…¸æ ¼å¼
                    formatted_result["charts_html"] = charts_dict
                    print(f"âœ… æŒä»“åˆ†æå›¾è¡¨æ•°æ®å·²è½¬æ¢: {len(charts_dict)}ä¸ªå›¾è¡¨")
            else:
                formatted_result["charts_html"] = None
        
        # æå–å¤–éƒ¨å¼•ç”¨
        if "external_citations" in result:
            formatted_result["citations"] = result["external_citations"]
        
        # æå–å¸­ä½åˆ†ç±»æ‘˜è¦
        if "seat_classification_summary" in result:
            formatted_result["seat_classification"] = result["seat_classification_summary"]
        
        # æå–å†å²åˆ†æ
        if "historical_analysis" in result:
            formatted_result["historical_analysis"] = result["historical_analysis"]
        
        return formatted_result
    
    def _generate_analysis_content_from_structured(self, structured_analysis: Dict[str, Any]) -> str:
        """ä»ç»“æ„åŒ–åˆ†ææ•°æ®ç”Ÿæˆå¯è¯»çš„æ–‡æœ¬åˆ†æå†…å®¹"""
        
        content_parts = []
        
        # 1. èœ˜è››ç½‘åˆ†æ
        if "spider_web_analysis" in structured_analysis:
            spider_data = structured_analysis["spider_web_analysis"]
            content_parts.append("ğŸ•¸ï¸ **èœ˜è››ç½‘ç­–ç•¥åˆ†æ**")
            content_parts.append(f"ä¿¡å·æ–¹å‘: {spider_data.get('signal', 'æœªçŸ¥')}")
            content_parts.append(f"ä¿¡å·å¼ºåº¦: {spider_data.get('strength', 0):.1f}")
            content_parts.append(f"åˆ†æä¿¡å¿ƒ: {spider_data.get('confidence', 0):.1f}")
            content_parts.append(f"æ ¸å¿ƒé€»è¾‘: {spider_data.get('reasoning', 'æš‚æ— ')}")
            content_parts.append("")
        
        # 2. èªæ˜é’±åˆ†æ
        if "smart_money_analysis" in structured_analysis:
            smart_data = structured_analysis["smart_money_analysis"]
            content_parts.append("ğŸ§  **èªæ˜é’±åˆ†æ**")
            content_parts.append(f"ä¿¡å·æ–¹å‘: {smart_data.get('signal', 'æœªçŸ¥')}")
            content_parts.append(f"ä¿¡å·å¼ºåº¦: {smart_data.get('strength', 0):.1f}")
            content_parts.append(f"åˆ†æä¿¡å¿ƒ: {smart_data.get('confidence', 0):.1f}")
            content_parts.append(f"æ ¸å¿ƒé€»è¾‘: {smart_data.get('reasoning', 'æš‚æ— ')}")
            content_parts.append("")
        
        # 3. å¸­ä½è¡Œä¸ºåˆ†æ
        if "seat_behavior_analysis" in structured_analysis:
            seat_data = structured_analysis["seat_behavior_analysis"]
            content_parts.append("ğŸ’º **å¸­ä½è¡Œä¸ºåˆ†æ**")
            content_parts.append(f"ä¿¡å·æ–¹å‘: {seat_data.get('signal', 'æœªçŸ¥')}")
            content_parts.append(f"ä¿¡å·å¼ºåº¦: {seat_data.get('strength', 0):.1f}")
            content_parts.append(f"åˆ†æä¿¡å¿ƒ: {seat_data.get('confidence', 0):.1f}")
            content_parts.append(f"æ ¸å¿ƒé€»è¾‘: {seat_data.get('reasoning', 'æš‚æ— ')}")
            content_parts.append("")
        
        # 4. é›†ä¸­åº¦åˆ†æ
        if "concentration_analysis" in structured_analysis:
            conc_data = structured_analysis["concentration_analysis"]
            content_parts.append("ğŸ“Š **æŒä»“é›†ä¸­åº¦åˆ†æ**")
            content_parts.append(f"ä¿¡å·æ–¹å‘: {conc_data.get('signal', 'æœªçŸ¥')}")
            content_parts.append(f"ä¿¡å·å¼ºåº¦: {conc_data.get('strength', 0):.1f}")
            content_parts.append(f"åˆ†æä¿¡å¿ƒ: {conc_data.get('confidence', 0):.1f}")
            content_parts.append(f"æ ¸å¿ƒé€»è¾‘: {conc_data.get('reasoning', 'æš‚æ— ')}")
            content_parts.append("")
        
        # 5. ç»¼åˆç»“è®º
        if "comprehensive_conclusion" in structured_analysis:
            conclusion_data = structured_analysis["comprehensive_conclusion"]
            content_parts.append("ğŸ¯ **ç»¼åˆç»“è®º**")
            
            # å¤„ç†ä¸åŒçš„æ•°æ®ç±»å‹
            if isinstance(conclusion_data, dict):
                content_parts.append(f"æ€»ä½“ä¿¡å·: {conclusion_data.get('overall_signal', 'æœªçŸ¥')}")
                content_parts.append(f"åˆ†æä¿¡å¿ƒ: {conclusion_data.get('confidence', 0):.1f}")
                content_parts.append(f"æ—¶é—´å‘¨æœŸ: {conclusion_data.get('time_horizon', 'æœªçŸ¥')}")
                
                key_factors = conclusion_data.get('key_factors', [])
                if key_factors:
                    content_parts.append(f"å…³é”®å› ç´ : {', '.join(key_factors)}")
                
                supporting_evidence = conclusion_data.get('supporting_evidence', '')
                if supporting_evidence:
                    content_parts.append(f"æ”¯æ’‘è¯æ®: {supporting_evidence}")
                
                risk_factors = conclusion_data.get('risk_factors', [])
                if risk_factors:
                    content_parts.append(f"é£é™©å› ç´ : {', '.join(risk_factors)}")
            elif isinstance(conclusion_data, str):
                content_parts.append(f"ç»“è®º: {conclusion_data}")
            else:
                content_parts.append(f"ç»“è®º: {str(conclusion_data)}")
            
            content_parts.append("")
        
        # 6. äº¤æ˜“å»ºè®®
        if "trading_recommendations" in structured_analysis:
            trade_data = structured_analysis["trading_recommendations"]
            content_parts.append("ğŸ’¼ **äº¤æ˜“å»ºè®®**")
            
            # å¤„ç†ä¸åŒçš„æ•°æ®ç±»å‹
            if isinstance(trade_data, dict):
                content_parts.append(f"ä¸»è¦ç­–ç•¥: {trade_data.get('primary_strategy', 'æš‚æ— ')}")
                content_parts.append(f"è¿›åœºæ—¶æœº: {trade_data.get('entry_timing', 'æš‚æ— ')}")
                content_parts.append(f"ä»“ä½è§„æ¨¡: {trade_data.get('position_sizing', 'æš‚æ— ')}")
                content_parts.append(f"æ­¢æŸè®¾ç½®: {trade_data.get('stop_loss', 'æš‚æ— ')}")
                content_parts.append(f"ç›ˆåˆ©ç›®æ ‡: {trade_data.get('profit_target', 'æš‚æ— ')}")
                content_parts.append(f"é£é™©ç®¡ç†: {trade_data.get('risk_management', 'æš‚æ— ')}")
            elif isinstance(trade_data, str):
                content_parts.append(f"å»ºè®®: {trade_data}")
            else:
                content_parts.append(f"å»ºè®®: {str(trade_data)}")
        
        return "\n".join(content_parts)

def analyze_positioning_for_streamlit(symbol: str, analysis_date: str = None, 
                                    use_reasoner: bool = True) -> Dict[str, Any]:
    """
    Streamlitç³»ç»Ÿè°ƒç”¨çš„æŒä»“åˆ†ææ¥å£
    
    Args:
        symbol: å“ç§ä»£ç 
        analysis_date: åˆ†ææ—¥æœŸ
        use_reasoner: æ˜¯å¦ä½¿ç”¨reasoneræ¨¡å‹
        
    Returns:
        Dict: æ ¼å¼åŒ–çš„åˆ†æç»“æœ
    """
    # æ¯æ¬¡è°ƒç”¨éƒ½åˆ›å»ºæ–°çš„é€‚é…å™¨å®ä¾‹ï¼Œé¿å…çŠ¶æ€æ±¡æŸ“
    adapter = StreamlitEnhancedPositioningAdapter()
    return adapter.analyze_positioning_for_streamlit(symbol, analysis_date, use_reasoner)

# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•Streamlitå¢å¼ºç‰ˆæŒä»“åˆ†æé€‚é…å™¨")
    
    # æµ‹è¯•åˆ†æ
    test_symbol = "RB"
    print(f"ğŸ“Š æµ‹è¯•åˆ†æå“ç§: {test_symbol}")
    
    result = analyze_positioning_for_streamlit(test_symbol, use_reasoner=False)
    
    if result.get("success"):
        print("âœ… æµ‹è¯•æˆåŠŸ!")
        print(f"ğŸ“ˆ å“ç§: {result['symbol_name']}({result['symbol']})")
        print(f"ğŸ“… åˆ†ææ—¥æœŸ: {result['analysis_date']}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {result['model_used']}")
        print(f"ğŸ“Š æ•°æ®ç‚¹æ•°: {result['data_points']}")
        print(f"ğŸ¯ æ•°æ®è´¨é‡: {result['data_quality_score']:.1%}")
        
        if "ai_analysis" in result:
            print(f"ğŸ¤– AIåˆ†æé•¿åº¦: {len(result['ai_analysis'])} å­—ç¬¦")
        
        if "charts" in result:
            print(f"ğŸ“Š å›¾è¡¨æ•°é‡: {len(result['charts'])} ä¸ª")
        
        if "citations" in result:
            print(f"ğŸ”— å¤–éƒ¨å¼•ç”¨: {len(result['citations'])} æ¡")
            
    else:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
