#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ€æœ¯åˆ†ææ•°æ®æ›´æ–°å™¨
åŸºäºæ™ºèƒ½æŠ€æœ¯åˆ†ææ•°æ®æ›´æ–°å™¨ï¼Œæ”¯æŒOHLCæ•°æ®è·å–å’ŒæŠ€æœ¯æŒ‡æ ‡è®¡ç®—
"""

import akshare as ak
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import time
import random
import json
import warnings
from typing import Dict, List, Optional, Tuple
try:
    import talib
    import numpy as np
    TALIB_AVAILABLE = True
except ImportError:
    TALIB_AVAILABLE = False
    print("âš ï¸ è­¦å‘Š: talibåº“æœªå®‰è£…ï¼ŒæŠ€æœ¯æŒ‡æ ‡è®¡ç®—åŠŸèƒ½å°†è¢«ç¦ç”¨")
    print("   å®‰è£…æ–¹æ³•: pip install TA-Lib")

warnings.filterwarnings('ignore')

# å“ç§åˆçº¦æ˜ å°„
SYMBOL_MAPPING = {
    'A': 'a2409', 'AG': 'ag2412', 'AL': 'al2411', 'AU': 'au2412', 'B': 'b2409',
    'BU': 'bu2412', 'C': 'c2409', 'CF': 'CF409', 'CU': 'cu2411', 'CY': 'CY409',
    'EB': 'eb2411', 'EG': 'eg2411', 'FG': 'FG409', 'FU': 'fu2409', 'HC': 'hc2410',
    'I': 'i2409', 'J': 'j2409', 'JD': 'jd2409', 'JM': 'jm2409', 'L': 'l2409',
    'LC': 'lc2409', 'LH': 'lh2409', 'M': 'm2409', 'MA': 'MA409', 'NI': 'ni2411',
    'OI': 'OI409', 'P': 'p2409', 'PB': 'pb2411', 'PF': 'PF409', 'PG': 'pg2411',
    'PP': 'pp2409', 'RB': 'rb2410', 'RM': 'RM409', 'RU': 'ru2409', 'SA': 'SA409',
    'SF': 'sf2411', 'SI': 'si2409', 'SM': 'sm2409', 'SN': 'sn2411', 'SP': 'sp2409',
    'SR': 'SR409', 'SS': 'ss2410', 'TA': 'TA409', 'UR': 'UR409', 'V': 'v2409',
    'Y': 'y2409', 'ZN': 'zn2411'
}

class TechnicalDataUpdater:
    """æŠ€æœ¯åˆ†ææ•°æ®æ›´æ–°å™¨"""
    
    def __init__(self, database_path: str = "D:/Cursor/cursoré¡¹ç›®/TradingAgent/qihuo/database/technical_analysis"):
        """
        åˆå§‹åŒ–æŠ€æœ¯åˆ†ææ•°æ®æ›´æ–°å™¨
        
        Args:
            database_path: æ•°æ®åº“è·¯å¾„
        """
        self.base_dir = Path(database_path)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        self.update_stats = {
            "start_time": None,
            "end_time": None,
            "target_date": None,
            "updated_varieties": [],
            "failed_varieties": [],
            "skipped_varieties": [],
            "new_varieties": [],
            "total_new_records": 0,
            "error_messages": []
        }
    
    def get_existing_data_status(self) -> Tuple[List[str], Dict]:
        """
        è·å–ç°æœ‰æ•°æ®çŠ¶æ€
        
        Returns:
            varieties: ç°æœ‰å“ç§åˆ—è¡¨
            variety_info: å„å“ç§è¯¦ç»†ä¿¡æ¯
        """
        print("ğŸ” æ£€æŸ¥ç°æœ‰æŠ€æœ¯åˆ†ææ•°æ®çŠ¶æ€...")
        
        varieties = []
        variety_info = {}
        
        if not self.base_dir.exists():
            return [], {}
        
        variety_folders = [d for d in self.base_dir.iterdir() if d.is_dir()]
        print(f"ğŸ“‚ å‘ç° {len(variety_folders)} ä¸ªå“ç§æ–‡ä»¶å¤¹")
        
        for folder in variety_folders:
            variety = folder.name
            ohlc_file = folder / "ohlc_data.csv"
            
            if ohlc_file.exists():
                try:
                    df = pd.read_csv(ohlc_file)
                    if len(df) > 0 and 'æ—¶é—´' in df.columns:
                        df['æ—¶é—´'] = pd.to_datetime(df['æ—¶é—´'])
                        variety_latest = df['æ—¶é—´'].max()
                        variety_earliest = df['æ—¶é—´'].min()
                        record_count = len(df)
                        
                        variety_info[variety] = {
                            "earliest_date": variety_earliest,
                            "latest_date": variety_latest,
                            "record_count": record_count,
                            "ohlc_file": ohlc_file
                        }
                        
                        varieties.append(variety)
                        print(f"  {variety}: {record_count} æ¡è®°å½• ({variety_earliest.strftime('%Y-%m-%d')} ~ {variety_latest.strftime('%Y-%m-%d')})")
                        
                except Exception as e:
                    print(f"  âŒ {variety}: è¯»å–å¤±è´¥ - {str(e)[:50]}")
                    self.update_stats["error_messages"].append(f"{variety}: æ•°æ®è¯»å–å¤±è´¥ - {str(e)}")
        
        print(f"\nğŸ“Š æ€»è®¡: {len(varieties)} ä¸ªæœ‰æ•ˆå“ç§")
        return varieties, variety_info
    
    def fetch_ohlc_data(self, symbol: str, contract_name: str, start_date: Optional[datetime] = None) -> Optional[pd.DataFrame]:
        """
        è·å–OHLCæ•°æ® - ä½¿ç”¨ä¸­æ–‡ä¸»è¿åˆçº¦åç§°
        
        Args:
            symbol: å“ç§ä»£ç 
            contract_name: åˆçº¦åç§°
            start_date: å¼€å§‹æ—¥æœŸï¼ˆç”¨äºå¢é‡æ›´æ–°ï¼‰
        
        Returns:
            æ•°æ®DataFrameæˆ–None
        """
        # å“ç§ä»£ç åˆ°ä¸­æ–‡ä¸»è¿åˆçº¦åç§°çš„æ˜ å°„
        SYMBOL_TO_CHINESE = {
            # é’¢é“å»ºæ
            "RB": "èºçº¹é’¢ä¸»è¿", "HC": "çƒ­å·ä¸»è¿", "I": "é“çŸ¿çŸ³ä¸»è¿", "J": "ç„¦ç‚­ä¸»è¿", 
            "JM": "ç„¦ç…¤ä¸»è¿", "SS": "ä¸é”ˆé’¢ä¸»è¿",
            # æœ‰è‰²é‡‘å±  
            "CU": "æ²ªé“œä¸»è¿", "AL": "æ²ªé“ä¸»è¿", "ZN": "æ²ªé”Œä¸»è¿", "NI": "æ²ªé•ä¸»è¿", 
            "SN": "æ²ªé”¡ä¸»è¿", "PB": "æ²ªé“…ä¸»è¿", "AO": "æ°§åŒ–é“ä¸»è¿",
            # è´µé‡‘å±
            "AU": "æ²ªé‡‘ä¸»è¿", "AG": "æ²ªé“¶ä¸»è¿",
            # åŒ–å·¥èƒ½æº
            "RU": "æ©¡èƒ¶ä¸»è¿", "NR": "20å·èƒ¶ä¸»è¿", "BU": "æ²¥é’ä¸»è¿", "FU": "ç‡ƒæ²¹ä¸»è¿",
            "LU": "ä½ç¡«ç‡ƒæ²¹ä¸»è¿", "PG": "LPGä¸»è¿", "EB": "è‹¯ä¹™çƒ¯ä¸»è¿", 
            "EG": "ä¹™äºŒé†‡ä¸»è¿", "MA": "ç”²é†‡ä¸»è¿", "TA": "PTAä¸»è¿", "PX": "å¯¹äºŒç”²è‹¯ä¸»è¿", 
            "PL": "èšçƒ¯çƒƒä¸»è¿", "PF": "çŸ­çº¤ä¸»è¿", "CY": "æ£‰çº±ä¸»è¿", "PR": "ç“¶ç‰‡ä¸»è¿",
            "SH": "çƒ§ç¢±ä¸»è¿", "SC": "åŸæ²¹ä¸»è¿",
            # å†œäº§å“
            "SR": "ç™½ç³–ä¸»è¿", "CF": "æ£‰èŠ±ä¸»è¿", "AP": "è‹¹æœä¸»è¿", "CJ": "çº¢æ£ä¸»è¿", 
            "SP": "çº¸æµ†ä¸»è¿", "P": "æ£•æ¦ˆæ²¹ä¸»è¿", "Y": "è±†æ²¹ä¸»è¿", "M": "è±†ç²•ä¸»è¿", 
            "RM": "èœç²•ä¸»è¿", "OI": "èœæ²¹ä¸»è¿", "RS": "èœç±½ä¸»è¿", "PK": "èŠ±ç”Ÿä¸»è¿", 
            "A": "è±†ä¸€ä¸»è¿", "B": "è±†äºŒä¸»è¿", "C": "ç‰ç±³ä¸»è¿", "CS": "æ·€ç²‰ä¸»è¿", 
            "JD": "é¸¡è›‹ä¸»è¿", "LH": "ç”ŸçŒªä¸»è¿", "LG": "åŸæœ¨ä¸»è¿",
            # ç»ç’ƒ
            "FG": "ç»ç’ƒä¸»è¿", "SA": "çº¯ç¢±ä¸»è¿",
            # å¡‘æ–™
            "L": "å¡‘æ–™ä¸»è¿", "PP": "èšä¸™çƒ¯ä¸»è¿", "V": "PVCä¸»è¿", "UR": "å°¿ç´ ä¸»è¿",
            # çººç»‡
            "SF": "ç¡…é“ä¸»è¿", "SM": "é”°ç¡…ä¸»è¿",
            # æ–°èƒ½æº
            "LC": "ç¢³é…¸é”‚ä¸»è¿", "SI": "å·¥ä¸šç¡…ä¸»è¿", "PS": "å¤šæ™¶ç¡…ä¸»è¿"
        }
        
        chinese_name = SYMBOL_TO_CHINESE.get(symbol, f"{symbol}ä¸»è¿")
        print(f"  ğŸ“¡ è·å– {symbol} ({chinese_name}) çš„OHLCæ•°æ®...")
        
        # æ–¹æ³•1: ä½¿ç”¨ä¸­æ–‡ä¸»è¿åˆçº¦åç§°è°ƒç”¨futures_hist_em
        try:
            print(f"    ğŸ“¡ æ–¹æ³•1: futures_hist_em({chinese_name})")
            df = ak.futures_hist_em(symbol=chinese_name, period="daily")
            
            if df is not None and not df.empty:
                print(f"    âœ… ä¸œæ–¹è´¢å¯Œæ¥å£æˆåŠŸ: {len(df)} æ¡è®°å½•")
                processed_df = self._process_em_data(df, symbol, start_date)
                if not processed_df.empty:
                    return processed_df
            else:
                print(f"    âš ï¸ ä¸œæ–¹è´¢å¯Œæ¥å£è¿”å›ç©ºæ•°æ®")
                
        except Exception as e:
            print(f"    âš ï¸ ä¸œæ–¹è´¢å¯Œæ¥å£å¤±è´¥: {str(e)[:50]}")
        
        # æ–¹æ³•2: å°è¯•æ–°æµªæ—¥çº¿æ¥å£
        try:
            print(f"    ğŸ“¡ æ–¹æ³•2: futures_zh_daily_sina({symbol})")
            df = ak.futures_zh_daily_sina(symbol=symbol)
            
            if df is not None and not df.empty:
                print(f"    âœ… æ–°æµªæ—¥çº¿æ¥å£æˆåŠŸ: {len(df)} æ¡è®°å½•")
                processed_df = self._process_sina_daily_data(df, symbol, start_date)
                if not processed_df.empty:
                    return processed_df
            else:
                print(f"    âš ï¸ æ–°æµªæ—¥çº¿æ¥å£è¿”å›ç©ºæ•°æ®")
                
        except Exception as e:
            print(f"    âš ï¸ æ–°æµªæ—¥çº¿æ¥å£å¤±è´¥: {str(e)[:50]}")
        
        # æ–¹æ³•3: å°è¯•æ–°æµªä¸»åŠ›åˆçº¦æ¥å£
        try:
            print(f"    ğŸ“¡ æ–¹æ³•3: futures_main_sina({symbol})")
            df = ak.futures_main_sina(symbol=symbol)
            
            if df is not None and not df.empty:
                print(f"    âœ… æ–°æµªä¸»åŠ›æ¥å£æˆåŠŸ: {len(df)} æ¡è®°å½•")
                processed_df = self._process_sina_main_data(df, symbol, start_date)
                if not processed_df.empty:
                    return processed_df
            else:
                print(f"    âš ï¸ æ–°æµªä¸»åŠ›æ¥å£è¿”å›ç©ºæ•°æ®")
                
        except Exception as e:
            print(f"    âš ï¸ æ–°æµªä¸»åŠ›æ¥å£å¤±è´¥: {str(e)[:50]}")
        
        print(f"    âŒ æ‰€æœ‰æ¥å£éƒ½å¤±è´¥")
        return None
    
    def _process_em_data(self, df: pd.DataFrame, symbol: str, start_date: Optional[datetime] = None) -> pd.DataFrame:
        """å¤„ç†ä¸œæ–¹è´¢å¯Œæ•°æ®"""
        try:
            print(f"    ğŸ”§ å¤„ç†ä¸œæ–¹è´¢å¯Œæ•°æ®...")
            
            # æ ‡å‡†åŒ–åˆ—å - ä¸œæ–¹è´¢å¯Œè¿”å›çš„åˆ—å
            column_mapping = {
                'æ—¶é—´': 'æ—¶é—´', 'å¼€ç›˜': 'å¼€ç›˜', 'æ”¶ç›˜': 'æ”¶ç›˜',
                'æœ€é«˜': 'æœ€é«˜', 'æœ€ä½': 'æœ€ä½', 'æˆäº¤é‡': 'æˆäº¤é‡',
                'æˆäº¤é¢': 'æˆäº¤é¢', 'æŒä»“é‡': 'æŒä»“é‡',
                'æ¶¨è·Œ': 'æ¶¨è·Œ', 'æ¶¨è·Œå¹…': 'æ¶¨è·Œå¹…'
            }
            
            # ç¡®ä¿æ•°æ®æ˜¯DataFrameæ ¼å¼
            if not isinstance(df, pd.DataFrame):
                print(f"    âŒ æ•°æ®ä¸æ˜¯DataFrameæ ¼å¼: {type(df)}")
                return pd.DataFrame()
            
            # å¤„ç†æ—¥æœŸæ ¼å¼
            if 'æ—¶é—´' not in df.columns:
                print(f"    âŒ æœªæ‰¾åˆ°æ—¶é—´åˆ—ï¼Œå¯ç”¨åˆ—: {list(df.columns)}")
                return pd.DataFrame()
            
            try:
                df['æ—¶é—´'] = pd.to_datetime(df['æ—¶é—´'])
            except Exception as time_error:
                print(f"    âŒ æ—¶é—´æ ¼å¼è½¬æ¢å¤±è´¥: {time_error}")
                return pd.DataFrame()
            
            # å¦‚æœæŒ‡å®šäº†å¼€å§‹æ—¥æœŸï¼Œè¿‡æ»¤æ•°æ®
            if start_date:
                df = df[df['æ—¶é—´'] > start_date]
            
            if df.empty:
                print(f"    â„¹ï¸ æ— æ–°æ•°æ®éœ€è¦æ›´æ–°")
                return pd.DataFrame()
            
            # æ’åºå¹¶é‡ç½®ç´¢å¼•
            df = df.sort_values('æ—¶é—´').reset_index(drop=True)
            
            print(f"    âœ… ä¸œæ–¹è´¢å¯Œæ•°æ®å¤„ç†å®Œæˆ: {len(df)} æ¡è®°å½•")
            if len(df) > 0:
                print(f"    ğŸ“… æ—¥æœŸèŒƒå›´: {df['æ—¶é—´'].min().strftime('%Y-%m-%d')} ~ {df['æ—¶é—´'].max().strftime('%Y-%m-%d')}")
            
            return df
            
        except Exception as e:
            print(f"    âŒ ä¸œæ–¹è´¢å¯Œæ•°æ®å¤„ç†å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _process_sina_daily_data(self, df: pd.DataFrame, symbol: str, start_date: Optional[datetime] = None) -> pd.DataFrame:
        """å¤„ç†æ–°æµªæ—¥çº¿æ•°æ®"""
        try:
            print(f"    ğŸ”§ å¤„ç†æ–°æµªæ—¥çº¿æ•°æ®...")
            
            # å¤„ç†æ—¥æœŸï¼ˆé€šå¸¸åœ¨ç´¢å¼•ä¸­ï¼‰
            if hasattr(df.index, 'to_series'):
                df = df.reset_index()
                df['æ—¶é—´'] = pd.to_datetime(df.index if 'date' not in df.columns else df['date'], errors='coerce')
            
            # æ ‡å‡†åŒ–åˆ—å
            column_mapping = {
                'date': 'æ—¶é—´', 'open': 'å¼€ç›˜', 'high': 'æœ€é«˜', 'low': 'æœ€ä½', 
                'close': 'æ”¶ç›˜', 'volume': 'æˆäº¤é‡', 'hold': 'æŒä»“é‡'
            }
            
            for old_col, new_col in column_mapping.items():
                if old_col in df.columns:
                    df = df.rename(columns={old_col: new_col})
            
            # ç¡®ä¿æ—¶é—´æ ¼å¼
            if 'æ—¶é—´' not in df.columns:
                # å°è¯•å…¶ä»–å¯èƒ½çš„æ—¶é—´åˆ—å
                time_cols = [col for col in df.columns if any(name in col.lower() for name in ['time', 'date', 'æ—¶é—´', 'æ—¥æœŸ'])]
                if time_cols:
                    df = df.rename(columns={time_cols[0]: 'æ—¶é—´'})
                else:
                    print(f"    âŒ æœªæ‰¾åˆ°æ—¶é—´åˆ—")
                    return pd.DataFrame()
            
            try:
                df['æ—¶é—´'] = pd.to_datetime(df['æ—¶é—´'])
            except Exception as time_error:
                print(f"    âŒ æ—¶é—´æ ¼å¼è½¬æ¢å¤±è´¥: {time_error}")
                return pd.DataFrame()
            
            # å¦‚æœæŒ‡å®šäº†å¼€å§‹æ—¥æœŸï¼Œè¿‡æ»¤æ•°æ®
            if start_date:
                df = df[df['æ—¶é—´'] > start_date]
            
            if df.empty:
                print(f"    â„¹ï¸ æ— æ–°æ•°æ®éœ€è¦æ›´æ–°")
                return pd.DataFrame()
            
            # æ’åºå¹¶é‡ç½®ç´¢å¼•
            df = df.sort_values('æ—¶é—´').reset_index(drop=True)
            
            print(f"    âœ… æ–°æµªæ—¥çº¿æ•°æ®å¤„ç†å®Œæˆ: {len(df)} æ¡è®°å½•")
            return df
            
        except Exception as e:
            print(f"    âŒ æ–°æµªæ—¥çº¿æ•°æ®å¤„ç†å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _process_sina_main_data(self, df: pd.DataFrame, symbol: str, start_date: Optional[datetime] = None) -> pd.DataFrame:
        """å¤„ç†æ–°æµªä¸»åŠ›åˆçº¦æ•°æ®"""
        try:
            print(f"    ğŸ”§ å¤„ç†æ–°æµªä¸»åŠ›æ•°æ®...")
            
            # æ ‡å‡†åŒ–åˆ—å
            column_mapping = {
                'æ—¥æœŸ': 'æ—¶é—´', 'Date': 'æ—¶é—´', 'date': 'æ—¶é—´',
                'å¼€ç›˜ä»·': 'å¼€ç›˜', 'Open': 'å¼€ç›˜', 'open': 'å¼€ç›˜',
                'æœ€é«˜ä»·': 'æœ€é«˜', 'High': 'æœ€é«˜', 'high': 'æœ€é«˜',
                'æœ€ä½ä»·': 'æœ€ä½', 'Low': 'æœ€ä½', 'low': 'æœ€ä½',
                'æ”¶ç›˜ä»·': 'æ”¶ç›˜', 'Close': 'æ”¶ç›˜', 'close': 'æ”¶ç›˜',
                'æˆäº¤é‡': 'æˆäº¤é‡', 'Volume': 'æˆäº¤é‡', 'volume': 'æˆäº¤é‡',
                'æŒä»“é‡': 'æŒä»“é‡', 'OpenInterest': 'æŒä»“é‡', 'open_interest': 'æŒä»“é‡'
            }
            
            for old_col, new_col in column_mapping.items():
                if old_col in df.columns:
                    df = df.rename(columns={old_col: new_col})
            
            # å¤„ç†æ—¥æœŸ
            if 'æ—¶é—´' not in df.columns:
                # å°è¯•ä»ç´¢å¼•è·å–æ—¥æœŸ
                if hasattr(df.index, 'to_series'):
                    df = df.reset_index()
                    df['æ—¶é—´'] = pd.to_datetime(df.index, errors='coerce')
                else:
                    print(f"    âŒ æ— æ³•æ‰¾åˆ°æ—¶é—´åˆ—")
                    return pd.DataFrame()
            
            df['æ—¶é—´'] = pd.to_datetime(df['æ—¶é—´'], errors='coerce')
            df = df.dropna(subset=['æ—¶é—´'])
            
            if start_date:
                df = df[df['æ—¶é—´'] > start_date]
            
            if df.empty:
                print(f"    â„¹ï¸ æ— æ–°æ•°æ®éœ€è¦æ›´æ–°")
                return pd.DataFrame()
            
            df = df.sort_values('æ—¶é—´').reset_index(drop=True)
            
            print(f"    âœ… æ–°æµªä¸»åŠ›æ•°æ®å¤„ç†å®Œæˆ: {len(df)} æ¡è®°å½•")
            return df
            
        except Exception as e:
            print(f"    âŒ æ–°æµªä¸»åŠ›æ•°æ®å¤„ç†å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _process_general_data(self, df: pd.DataFrame, symbol: str, start_date: Optional[datetime] = None) -> pd.DataFrame:
        """å¤„ç†é€šç”¨æœŸè´§æ•°æ®"""
        try:
            print(f"    ğŸ”§ å¤„ç†é€šç”¨æœŸè´§æ•°æ®...")
            
            # æ ‡å‡†åŒ–åˆ—å
            column_mapping = {
                'date': 'æ—¶é—´', 'trade_date': 'æ—¶é—´',
                'open': 'å¼€ç›˜', 'high': 'æœ€é«˜', 'low': 'æœ€ä½', 'close': 'æ”¶ç›˜',
                'volume': 'æˆäº¤é‡', 'open_interest': 'æŒä»“é‡'
            }
            
            for old_col, new_col in column_mapping.items():
                if old_col in df.columns:
                    df = df.rename(columns={old_col: new_col})
            
            if 'æ—¶é—´' not in df.columns:
                print(f"    âŒ æ— æ³•æ‰¾åˆ°æ—¶é—´åˆ—")
                return pd.DataFrame()
            
            df['æ—¶é—´'] = pd.to_datetime(df['æ—¶é—´'], errors='coerce')
            df = df.dropna(subset=['æ—¶é—´'])
            
            if start_date:
                df = df[df['æ—¶é—´'] > start_date]
            
            if df.empty:
                print(f"    â„¹ï¸ æ— æ–°æ•°æ®éœ€è¦æ›´æ–°")
                return pd.DataFrame()
            
            df = df.sort_values('æ—¶é—´').reset_index(drop=True)
            
            print(f"    âœ… é€šç”¨æ•°æ®å¤„ç†å®Œæˆ: {len(df)} æ¡è®°å½•")
            return df
            
        except Exception as e:
            print(f"    âŒ é€šç”¨æ•°æ®å¤„ç†å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ - å®‰å…¨ç‰ˆæœ¬ï¼Œé¿å…æ•°æ®ç±»å‹é”™è¯¯
        
        Args:
            df: OHLCæ•°æ®
        
        Returns:
            å¸¦æŠ€æœ¯æŒ‡æ ‡çš„æ•°æ®
        """
        try:
            print("      ğŸ”§ å¼€å§‹å®‰å…¨æŒ‡æ ‡è®¡ç®—...")
            
            # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
            df = df.sort_values('æ—¶é—´').reset_index(drop=True)
            
            # å¼ºåˆ¶æ•°æ®ç±»å‹è½¬æ¢å’Œæ¸…ç†
            close = pd.to_numeric(df["æ”¶ç›˜"], errors='coerce')
            high = pd.to_numeric(df["æœ€é«˜"], errors='coerce') 
            low = pd.to_numeric(df["æœ€ä½"], errors='coerce')
            open_ = pd.to_numeric(df.get("å¼€ç›˜", close), errors='coerce')
            volume = pd.to_numeric(df.get("æˆäº¤é‡", pd.Series(0, index=close.index)), errors='coerce')
            
            # ä½¿ç”¨å‰å‘å¡«å……å¤„ç†NaNï¼Œç„¶åç”¨0å¡«å……å‰©ä½™çš„NaN
            close = close.ffill().bfill().fillna(0)
            high = high.ffill().bfill().fillna(0)
            low = low.ffill().bfill().fillna(0) 
            open_ = open_.ffill().bfill().fillna(0)
            volume = volume.fillna(0)
            
            # ç¡®ä¿ä»·æ ¼é€»è¾‘æ­£ç¡®
            high = np.maximum(high, np.maximum(open_, close))
            low = np.minimum(low, np.minimum(open_, close))
            
            print("        âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
            
            # ========== åŸºç¡€æŒ‡æ ‡ ==========
            
            # ç§»åŠ¨å¹³å‡çº¿
            df["MA5"] = close.rolling(5, min_periods=1).mean()
            df["MA10"] = close.rolling(10, min_periods=1).mean()
            df["MA20"] = close.rolling(20, min_periods=1).mean()
            df["MA60"] = close.rolling(60, min_periods=1).mean()
            df["EMA20"] = close.ewm(span=20, adjust=False, min_periods=1).mean()
            
            # ATR
            tr1 = (high - low).abs()
            tr2 = (high - close.shift(1)).abs().fillna(0)
            tr3 = (low - close.shift(1)).abs().fillna(0)
            tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
            df["ATR14"] = tr.rolling(14, min_periods=1).mean()
            
            # RSI
            delta = close.diff().fillna(0)
            gain = delta.where(delta > 0, 0).rolling(14, min_periods=1).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(14, min_periods=1).mean()
            rs = gain / loss.replace(0, 1e-10)  # é¿å…é™¤é›¶
            df["RSI14"] = 100 - (100 / (1 + rs))
            
            # MACD
            ema12 = close.ewm(span=12, adjust=False, min_periods=1).mean()
            ema26 = close.ewm(span=26, adjust=False, min_periods=1).mean()
            df["MACD"] = ema12 - ema26
            df["MACD_SIGNAL"] = df["MACD"].ewm(span=9, adjust=False, min_periods=1).mean()
            df["MACD_HIST"] = df["MACD"] - df["MACD_SIGNAL"]
            
            # å¸ƒæ—å¸¦
            ma20 = df["MA20"]
            std20 = close.rolling(20, min_periods=1).std().fillna(0)
            df["BOLL_UP"] = ma20 + 2 * std20
            df["BOLL_LOW"] = ma20 - 2 * std20
            df["BOLL_MID"] = ma20
            df["BOLL_WIDTH"] = df["BOLL_UP"] - df["BOLL_LOW"]
            
            print("        âœ… åŸºç¡€æŒ‡æ ‡å®Œæˆ")
            
            # ========== é«˜çº§æŒ‡æ ‡ ==========
            
            # KDJ
            n = 9
            llv_n = low.rolling(n, min_periods=1).min()
            hhv_n = high.rolling(n, min_periods=1).max()
            rsv = 100 * (close - llv_n) / (hhv_n - llv_n).replace(0, 1e-10)
            k = rsv.ewm(alpha=1/3, adjust=False, min_periods=1).mean()
            d = k.ewm(alpha=1/3, adjust=False, min_periods=1).mean()
            j = 3 * k - 2 * d
            df["KDJ_K"] = k
            df["KDJ_D"] = d
            df["KDJ_J"] = j
            
            # Williams %R
            hhv14 = high.rolling(14, min_periods=1).max()
            llv14 = low.rolling(14, min_periods=1).min()
            df["WILLIAMS_R14"] = -100 * (hhv14 - close) / (hhv14 - llv14).replace(0, 1e-10)
            
            # CCI - ç®€åŒ–ç‰ˆæœ¬
            tp = (high + low + close) / 3
            sma = tp.rolling(20, min_periods=1).mean()
            std = tp.rolling(20, min_periods=1).std().fillna(1)
            df["CCI20"] = (tp - sma) / (0.02 * std)
            
            # Stochastic RSI
            rsi = df["RSI14"]
            stoch_rsi = 100 * (rsi - rsi.rolling(14, min_periods=1).min()) / (
                rsi.rolling(14, min_periods=1).max() - rsi.rolling(14, min_periods=1).min()
            ).replace(0, 1e-10)
            df["STOCH_RSI"] = stoch_rsi
            
            print("        âœ… é«˜çº§æŒ‡æ ‡å®Œæˆ")
            
            # ========== æˆäº¤é‡æŒ‡æ ‡ ==========
            
            df["VOL_MA20"] = volume.rolling(20, min_periods=1).mean()
            price_change = close.diff().fillna(0)
            sign = pd.Series(np.where(price_change > 0, 1, np.where(price_change < 0, -1, 0)), index=close.index)
            df["OBV"] = (sign * volume).cumsum()
            
            print("        âœ… æˆäº¤é‡æŒ‡æ ‡å®Œæˆ")
            
            # ========== æŒä»“é‡æŒ‡æ ‡ ==========
            
            if "æŒä»“é‡" in df.columns:
                oi = pd.to_numeric(df["æŒä»“é‡"], errors='coerce').fillna(0)
                
                df["OI_MA20"] = oi.rolling(20, min_periods=1).mean()
                df["OI_CHANGE"] = oi.diff().fillna(0)
                df["OI_CHANGE_PCT"] = oi.pct_change().fillna(0) * 100
                
                print("        âœ… æŒä»“é‡æŒ‡æ ‡å®Œæˆ")
            
            # ç»Ÿè®¡æŒ‡æ ‡æ•°é‡
            original_cols = ['æ—¶é—´', 'å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡', 'æŒä»“é‡']
            indicator_cols = [col for col in df.columns if col not in original_cols]
            
            print(f"      âœ… å®‰å…¨æŒ‡æ ‡è®¡ç®—å®Œæˆ: {len(indicator_cols)} ä¸ªæŒ‡æ ‡")
            
            return df
            
        except Exception as e:
            print(f"      âŒ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return df
    
    def save_variety_data(self, symbol: str, new_data: pd.DataFrame, existing_info: Optional[Dict] = None) -> bool:
        """
        ä¿å­˜å“ç§æ•°æ®
        
        Args:
            symbol: å“ç§ä»£ç 
            new_data: æ–°æ•°æ®
            existing_info: ç°æœ‰æ•°æ®ä¿¡æ¯
        
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            variety_dir = self.base_dir / symbol
            variety_dir.mkdir(parents=True, exist_ok=True)
            
            ohlc_file = variety_dir / "ohlc_data.csv"
            
            if existing_info and ohlc_file.exists():
                # è¯»å–ç°æœ‰æ•°æ®
                existing_df = pd.read_csv(ohlc_file)
                existing_df['æ—¶é—´'] = pd.to_datetime(existing_df['æ—¶é—´'])
                
                # åˆå¹¶æ•°æ®
                combined_df = pd.concat([existing_df, new_data], ignore_index=True)
                combined_df = combined_df.drop_duplicates(subset=['æ—¶é—´']).sort_values('æ—¶é—´').reset_index(drop=True)
                
                new_records = len(combined_df) - len(existing_df)
                if new_records > 0:
                    print(f"    âœ… {symbol}: æ–°å¢ {new_records} æ¡è®°å½•")
                    self.update_stats["updated_varieties"].append(symbol)
                    self.update_stats["total_new_records"] += new_records
                else:
                    print(f"    â„¹ï¸ {symbol}: æ— æ–°æ•°æ®")
                    self.update_stats["skipped_varieties"].append(symbol)
                    return True
            else:
                # æ–°å“ç§æˆ–æ— ç°æœ‰æ•°æ®
                combined_df = new_data
                print(f"    âœ… {symbol}: åˆ›å»º {len(new_data)} æ¡è®°å½•")
                self.update_stats["new_varieties"].append(symbol)
                self.update_stats["total_new_records"] += len(new_data)
            
            # é‡æ–°è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆåŸºäºå®Œæ•´æ•°æ®ï¼‰
            combined_df = self.calculate_technical_indicators(combined_df)
            
            # ä¿å­˜æ•°æ®
            combined_df.to_csv(ohlc_file, index=False, encoding='utf-8')
            
            # å¦å¤–ä¿å­˜æŠ€æœ¯æŒ‡æ ‡æ•°æ®
            tech_file = variety_dir / "technical_indicators.csv"
            tech_columns = [col for col in combined_df.columns if col not in ['æ—¶é—´', 'å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡', 'æŒä»“é‡']]
            
            if tech_columns:
                tech_df = combined_df[['æ—¶é—´'] + tech_columns]
                tech_df.to_csv(tech_file, index=False, encoding='utf-8')
            
            return True
            
        except Exception as e:
            print(f"    âŒ {symbol}: ä¿å­˜å¤±è´¥ - {str(e)}")
            self.update_stats["failed_varieties"].append(symbol)
            self.update_stats["error_messages"].append(f"{symbol}: ä¿å­˜å¤±è´¥ - {str(e)}")
            return False
    
    def update_to_date(self, target_date_str: str, specific_varieties: Optional[List[str]] = None) -> Dict:
        """
        æ›´æ–°æ•°æ®åˆ°æŒ‡å®šæ—¥æœŸ
        
        Args:
            target_date_str: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DDæ ¼å¼)
            specific_varieties: æŒ‡å®šå“ç§åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨å“ç§
        
        Returns:
            æ›´æ–°ç»“æœç»Ÿè®¡
        """
        print(f"ğŸš€ æŠ€æœ¯åˆ†ææ•°æ®æ›´æ–°å™¨")
        print("=" * 60)
        
        # è§£æç›®æ ‡æ—¥æœŸ
        try:
            target_date = datetime.strptime(target_date_str, '%Y-%m-%d')
        except ValueError:
            try:
                target_date = datetime.strptime(target_date_str, '%Y%m%d')
            except ValueError:
                raise ValueError(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {target_date_str}ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æˆ– YYYYMMDD æ ¼å¼")
        
        self.update_stats["start_time"] = datetime.now()
        self.update_stats["target_date"] = target_date_str
        
        print(f"ğŸ“… ç›®æ ‡æ›´æ–°æ—¥æœŸ: {target_date.strftime('%Y-%m-%d')}")
        
        # è·å–ç°æœ‰æ•°æ®çŠ¶æ€
        existing_varieties, variety_info = self.get_existing_data_status()
        
        # ç¡®å®šè¦æ›´æ–°çš„å“ç§
        if specific_varieties:
            target_symbols = [s for s in specific_varieties if s.upper() in SYMBOL_MAPPING]
            print(f"ğŸ¯ æŒ‡å®šæ›´æ–°å“ç§: {len(target_symbols)} ä¸ª")
        else:
            target_symbols = list(SYMBOL_MAPPING.keys())
            print(f"ğŸ¯ å…¨å“ç§æ›´æ–°: {len(target_symbols)} ä¸ª")
        
        # æ‰§è¡Œæ›´æ–°
        processed_count = 0
        
        for i, symbol in enumerate(target_symbols):
            print(f"\n[{i+1}/{len(target_symbols)}] å¤„ç†å“ç§: {symbol}")
            
            contract_name = SYMBOL_MAPPING[symbol]
            existing_info = variety_info.get(symbol)
            
            # ç¡®å®šèµ·å§‹æ—¥æœŸï¼ˆç”¨äºå¢é‡æ›´æ–°ï¼‰
            start_date = None
            if existing_info:
                latest_date = existing_info["latest_date"]
                days_gap = (target_date.date() - latest_date.date()).days
                
                if days_gap <= 1:
                    print(f"    â„¹ï¸ æ•°æ®å·²æ˜¯æœ€æ–° (æœ€æ–°: {latest_date.strftime('%Y-%m-%d')})")
                    self.update_stats["skipped_varieties"].append(symbol)
                    continue
                
                print(f"    ğŸ“… æœ€æ–°æ•°æ®: {latest_date.strftime('%Y-%m-%d')}, ç¼ºå£: {days_gap}å¤©")
                start_date = latest_date
            else:
                print(f"    ğŸ†• æ–°å“ç§ï¼Œå°†åˆ›å»ºå®Œæ•´æ•°æ®")
            
            # è·å–æ•°æ®
            new_data = self.fetch_ohlc_data(symbol, contract_name, start_date)
            
            if new_data is None:
                print(f"    âŒ {symbol}: æ•°æ®è·å–å¤±è´¥")
                self.update_stats["failed_varieties"].append(symbol)
                continue
            
            if new_data.empty:
                print(f"    â„¹ï¸ {symbol}: æ— æ–°æ•°æ®")
                self.update_stats["skipped_varieties"].append(symbol)
                continue
            
            # ä¿å­˜æ•°æ®
            if self.save_variety_data(symbol, new_data, existing_info):
                processed_count += 1
            
            # æ·»åŠ éšæœºå»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            if i < len(target_symbols) - 1:
                delay = random.uniform(0.5, 1.5)
                time.sleep(delay)
        
        # å®Œæˆç»Ÿè®¡
        self.update_stats["end_time"] = datetime.now()
        
        print(f"\nğŸ“Š æ›´æ–°å®Œæˆç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸæ›´æ–°å“ç§: {len(self.update_stats['updated_varieties'])} ä¸ª")
        print(f"  ğŸ†• æ–°å¢å“ç§: {len(self.update_stats['new_varieties'])} ä¸ª")
        print(f"  âŒ å¤±è´¥å“ç§: {len(self.update_stats['failed_varieties'])} ä¸ª")
        print(f"  â­ï¸ è·³è¿‡å“ç§: {len(self.update_stats['skipped_varieties'])} ä¸ª")
        print(f"  ğŸ“ˆ æ–°å¢è®°å½•æ€»æ•°: {self.update_stats['total_new_records']} æ¡")
        print(f"  â±ï¸ è€—æ—¶: {(self.update_stats['end_time'] - self.update_stats['start_time']).total_seconds():.1f} ç§’")
        
        if self.update_stats["failed_varieties"]:
            print(f"  âš ï¸ å¤±è´¥å“ç§åˆ—è¡¨: {', '.join(self.update_stats['failed_varieties'])}")
        
        return self.update_stats

def main():
    """æµ‹è¯•ä¸»å‡½æ•°"""
    updater = TechnicalDataUpdater()
    
    # è·å–ç°æœ‰æ•°æ®çŠ¶æ€
    varieties, info = updater.get_existing_data_status()
    
    # æ¨¡æ‹Ÿæ›´æ–°å‰3ä¸ªå“ç§åˆ°ä»Šå¤©
    target_date = datetime.now().strftime('%Y-%m-%d')
    test_varieties = ['RB', 'CU', 'AL'] if varieties else None
    
    result = updater.update_to_date(target_date, test_varieties)
    
    print(f"\nğŸ¯ æ›´æ–°ç»“æœ: {result}")

if __name__ == "__main__":
    main()
