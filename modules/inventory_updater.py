#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åº“å­˜æ•°æ®æ›´æ–°å™¨
åŸºäºå¢é‡æ›´æ–°åº“å­˜æ•°æ®é€»è¾‘ï¼Œæ”¯æŒæ™ºèƒ½æ•°æ®åˆå¹¶
"""

import akshare as ak
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import time
import random
import json
from typing import Dict, List, Optional, Tuple

# å“ç§æ˜ å°„é…ç½®
SYMBOL_MAPPING = {
    'A': 'è±†ä¸€', 'AG': 'æ²ªé“¶', 'AL': 'æ²ªé“', 'AO': 'æ°§åŒ–é“', 'AP': 'è‹¹æœ',
    'AU': 'æ²ªé‡‘', 'B': 'è±†äºŒ', 'BR': 'ä¸äºŒçƒ¯æ©¡èƒ¶', 'BU': 'æ²¥é’', 'C': 'ç‰ç±³',
    'CF': 'éƒ‘æ£‰', 'CJ': 'çº¢æ£', 'CS': 'ç‰ç±³æ·€ç²‰', 'CU': 'æ²ªé“œ', 'CY': 'æ£‰çº±',
    'EB': 'è‹¯ä¹™çƒ¯', 'EG': 'ä¹™äºŒé†‡', 'FG': 'ç»ç’ƒ', 'FU': 'ç‡ƒæ²¹', 'HC': 'çƒ­å·',
    'I': 'é“çŸ¿çŸ³', 'J': 'ç„¦ç‚­', 'JD': 'é¸¡è›‹', 'JM': 'ç„¦ç…¤', 'L': 'å¡‘æ–™',
    'LC': 'ç¢³é…¸é”‚', 'LG': 'åŸæœ¨', 'LH': 'ç”ŸçŒª', 'LU': 'ä½ç¡«ç‡ƒæ–™æ²¹', 'M': 'è±†ç²•',
    'MA': 'ç”²é†‡', 'NI': 'é•', 'NR': '20å·èƒ¶', 'OI': 'èœæ²¹', 'P': 'æ£•æ¦ˆ',
    'PB': 'æ²ªé“…', 'PF': 'çŸ­çº¤', 'PG': 'æ¶²åŒ–çŸ³æ²¹æ°”', 'PK': 'èŠ±ç”Ÿ', 'PP': 'èšä¸™çƒ¯',
    'PR': 'ç“¶ç‰‡', 'PS': 'å¤šæ™¶ç¡…', 'PTA': 'PTA', 'PX': 'å¯¹äºŒç”²è‹¯', 'RB': 'èºçº¹é’¢',
    'RM': 'èœç²•', 'RS': 'èœç±½', 'RU': 'æ©¡èƒ¶', 'SA': 'çº¯ç¢±', 'SF': 'ç¡…é“',
    'SH': 'çƒ§ç¢±', 'SI': 'å·¥ä¸šç¡…', 'SM': 'é”°ç¡…', 'SN': 'é”¡', 'SP': 'çº¸æµ†',
    'SR': 'ç™½ç³–', 'SS': 'ä¸é”ˆé’¢', 'TA': 'PTA', 'UR': 'å°¿ç´ ', 'V': 'PVC',
    'Y': 'è±†æ²¹', 'ZN': 'æ²ªé”Œ'
}

class InventoryDataUpdater:
    """åº“å­˜æ•°æ®æ›´æ–°å™¨"""
    
    def __init__(self, database_path: str = "D:/Cursor/cursoré¡¹ç›®/TradingAgent/qihuo/database/inventory"):
        """
        åˆå§‹åŒ–åº“å­˜æ•°æ®æ›´æ–°å™¨
        
        Args:
            database_path: æ•°æ®åº“è·¯å¾„
        """
        self.base_dir = Path(database_path)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        self.update_stats = {
            "start_time": None,
            "end_time": None,
            "target_date": None,
            "updated_varieties": [],
            "failed_varieties": [],
            "skipped_varieties": [],
            "new_varieties": [],
            "total_new_records": 0,
            "error_messages": []
        }
    
    def get_existing_data_status(self) -> Tuple[List[str], Dict]:
        """
        è·å–ç°æœ‰æ•°æ®çŠ¶æ€
        
        Returns:
            varieties: ç°æœ‰å“ç§åˆ—è¡¨
            variety_info: å„å“ç§è¯¦ç»†ä¿¡æ¯
        """
        print("ğŸ” æ£€æŸ¥ç°æœ‰åº“å­˜æ•°æ®çŠ¶æ€...")
        
        varieties = []
        variety_info = {}
        
        if not self.base_dir.exists():
            return [], {}
        
        variety_folders = [d for d in self.base_dir.iterdir() if d.is_dir()]
        print(f"ğŸ“‚ å‘ç° {len(variety_folders)} ä¸ªå“ç§æ–‡ä»¶å¤¹")
        
        for folder in variety_folders:
            variety = folder.name
            inventory_file = folder / "inventory.csv"
            
            if inventory_file.exists():
                try:
                    df = pd.read_csv(inventory_file)
                    if len(df) > 0 and 'date' in df.columns:
                        df['date'] = pd.to_datetime(df['date'])
                        variety_latest = df['date'].max()
                        variety_earliest = df['date'].min()
                        record_count = len(df)
                        
                        variety_info[variety] = {
                            "earliest_date": variety_earliest,
                            "latest_date": variety_latest,
                            "record_count": record_count,
                            "file_path": inventory_file
                        }
                        
                        varieties.append(variety)
                        print(f"  {variety}: {record_count} æ¡è®°å½• ({variety_earliest.strftime('%Y-%m-%d')} ~ {variety_latest.strftime('%Y-%m-%d')})")
                        
                except Exception as e:
                    print(f"  âŒ {variety}: è¯»å–å¤±è´¥ - {str(e)[:50]}")
                    self.update_stats["error_messages"].append(f"{variety}: æ•°æ®è¯»å–å¤±è´¥ - {str(e)}")
        
        print(f"\nğŸ“Š æ€»è®¡: {len(varieties)} ä¸ªæœ‰æ•ˆå“ç§")
        return varieties, variety_info
    
    def fetch_variety_data(self, symbol: str, series_cn: str, target_date: datetime, retries: int = 3) -> Optional[pd.DataFrame]:
        """
        è·å–å“ç§æ•°æ®
        
        Args:
            symbol: å“ç§ä»£ç 
            series_cn: ä¸­æ–‡å“ç§åç§°
            target_date: ç›®æ ‡æ—¥æœŸï¼ˆç”¨äºæ•°æ®è¿‡æ»¤ï¼‰
            retries: é‡è¯•æ¬¡æ•°
        
        Returns:
            æ•°æ®DataFrameæˆ–None
        """
        print(f"  ğŸ“¡ è·å– {symbol} ({series_cn}) çš„åº“å­˜æ•°æ®...")
        
        for attempt in range(retries):
            try:
                # è·å–æ•°æ®ï¼ˆæ³¨æ„ï¼šåº“å­˜æ•°æ®æ¥å£ä¸æ”¯æŒæ—¥æœŸå‚æ•°ï¼Œä¼šè¿”å›æ‰€æœ‰å†å²æ•°æ®ï¼‰
                raw_df = ak.futures_inventory_em(symbol=series_cn)
                
                if raw_df is None or raw_df.empty:
                    print(f"    âŒ ç¬¬{attempt+1}æ¬¡å°è¯•: æ— æ•°æ®è¿”å›")
                    if attempt < retries - 1:
                        time.sleep(random.uniform(1, 3))
                    continue
                
                # æ ‡å‡†åŒ–æ•°æ®
                new_df = raw_df.rename(columns={"æ—¥æœŸ": "date", "åº“å­˜": "value"})
                new_df["date"] = pd.to_datetime(new_df["date"])
                new_df["value"] = pd.to_numeric(new_df["value"], errors="coerce")
                
                # è®¡ç®—å¢å‡åˆ—ï¼ˆåŸºäºå‰ä¸€æ—¥æ•°æ®è®¡ç®—ï¼‰
                new_df = new_df.sort_values('date').reset_index(drop=True)
                new_df["å¢å‡"] = new_df["value"].diff().fillna(0)
                
                new_df = new_df.dropna(subset=["value"]).drop_duplicates(subset=["date"]).sort_values("date")
                
                # è¿‡æ»¤åˆ°ç›®æ ‡æ—¥æœŸï¼ˆåº“å­˜æ•°æ®ç‰¹æ®Šå¤„ç†ï¼‰
                new_df = new_df[new_df['date'] <= target_date]
                
                if new_df.empty:
                    print(f"    âš ï¸ æˆªæ­¢æ—¥æœŸå‰æ— æœ‰æ•ˆæ•°æ®")
                    return None
                
                new_start = new_df['date'].min().strftime('%Y-%m-%d')
                new_end = new_df['date'].max().strftime('%Y-%m-%d')
                print(f"    âœ… è·å–åˆ° {len(new_df)} æ¡è®°å½• ({new_start} ~ {new_end})")
                
                return new_df
                
            except Exception as e:
                print(f"    âŒ ç¬¬{attempt+1}æ¬¡å°è¯•å¤±è´¥: {str(e)[:50]}")
                if attempt < retries - 1:
                    time.sleep(random.uniform(1, 3))
        
        print(f"    âŒ æ‰€æœ‰å°è¯•å¤±è´¥")
        return None
    
    def save_variety_data(self, symbol: str, new_data: pd.DataFrame, existing_info: Optional[Dict] = None) -> bool:
        """
        ä¿å­˜å“ç§æ•°æ®ï¼ˆæ™ºèƒ½åˆå¹¶ï¼‰
        
        Args:
            symbol: å“ç§ä»£ç 
            new_data: æ–°æ•°æ®
            existing_info: ç°æœ‰æ•°æ®ä¿¡æ¯
        
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            variety_dir = self.base_dir / symbol
            variety_dir.mkdir(parents=True, exist_ok=True)
            
            inventory_file = variety_dir / "inventory.csv"
            
            if existing_info and inventory_file.exists():
                # è¯»å–ç°æœ‰æ•°æ®
                existing_df = pd.read_csv(inventory_file)
                existing_df['date'] = pd.to_datetime(existing_df['date'])
                
                # è®¡ç®—æ–°å¢æ•°æ®
                existing_dates = set(existing_df['date'].dt.date)
                new_dates = set(new_data['date'].dt.date)
                added_dates = new_dates - existing_dates
                
                if added_dates:
                    # æœ‰æ–°æ•°æ®ï¼Œåˆå¹¶
                    combined_df = pd.concat([existing_df, new_data]).drop_duplicates(subset=['date']).sort_values('date').reset_index(drop=True)
                    
                    # é‡æ–°è®¡ç®—å…¨éƒ¨å¢å‡å€¼
                    combined_df["å¢å‡"] = combined_df["value"].diff().fillna(0)
                    
                    latest_added = max(added_dates).strftime('%Y-%m-%d')
                    print(f"    âœ… {symbol}: æ–°å¢ {len(added_dates)} æ¡è®°å½• (è‡³ {latest_added})")
                    self.update_stats["updated_varieties"].append(symbol)
                    self.update_stats["total_new_records"] += len(added_dates)
                else:
                    # æ— æ–°æ•°æ®
                    combined_df = existing_df
                    print(f"    â„¹ï¸ {symbol}: æ— æ–°æ•°æ®")
                    self.update_stats["skipped_varieties"].append(symbol)
                    return True
            else:
                # æ–°å“ç§æˆ–æ— ç°æœ‰æ•°æ®
                combined_df = new_data
                data_span = f"{new_data['date'].min().strftime('%Y-%m-%d')} ~ {new_data['date'].max().strftime('%Y-%m-%d')}"
                print(f"    âœ… {symbol}: åˆ›å»º {len(new_data)} æ¡è®°å½• ({data_span})")
                self.update_stats["new_varieties"].append(symbol)
                self.update_stats["total_new_records"] += len(new_data)
            
            # ä¿å­˜æ•°æ®
            combined_df.to_csv(inventory_file, index=False, encoding='utf-8')
            return True
            
        except Exception as e:
            print(f"    âŒ {symbol}: ä¿å­˜å¤±è´¥ - {str(e)}")
            self.update_stats["failed_varieties"].append(symbol)
            self.update_stats["error_messages"].append(f"{symbol}: ä¿å­˜å¤±è´¥ - {str(e)}")
            return False
    
    def update_to_date(self, target_date_str: str, specific_varieties: Optional[List[str]] = None) -> Dict:
        """
        æ›´æ–°æ•°æ®åˆ°æŒ‡å®šæ—¥æœŸ
        
        Args:
            target_date_str: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DDæ ¼å¼)
            specific_varieties: æŒ‡å®šå“ç§åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨å“ç§
        
        Returns:
            æ›´æ–°ç»“æœç»Ÿè®¡
        """
        print(f"ğŸš€ åº“å­˜æ•°æ®æ›´æ–°å™¨")
        print("=" * 60)
        
        # è§£æç›®æ ‡æ—¥æœŸ
        try:
            target_date = datetime.strptime(target_date_str, '%Y-%m-%d')
        except ValueError:
            try:
                target_date = datetime.strptime(target_date_str, '%Y%m%d')
            except ValueError:
                raise ValueError(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {target_date_str}ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æˆ– YYYYMMDD æ ¼å¼")
        
        self.update_stats["start_time"] = datetime.now()
        self.update_stats["target_date"] = target_date_str
        
        print(f"ğŸ“… ç›®æ ‡æ›´æ–°æ—¥æœŸ: {target_date.strftime('%Y-%m-%d')}")
        print(f"âš ï¸ æ³¨æ„: åº“å­˜æ•°æ®æ¥å£æ— æ³•é€‰æ‹©æ—¥æœŸèŒƒå›´ï¼Œä¼šè·å–å®Œæ•´å†å²æ•°æ®ç„¶åè¿‡æ»¤")
        
        # è·å–ç°æœ‰æ•°æ®çŠ¶æ€
        existing_varieties, variety_info = self.get_existing_data_status()
        
        # ç¡®å®šè¦æ›´æ–°çš„å“ç§
        if specific_varieties:
            target_symbols = [(s, SYMBOL_MAPPING.get(s, s)) for s in specific_varieties if s in SYMBOL_MAPPING]
            print(f"ğŸ¯ æŒ‡å®šæ›´æ–°å“ç§: {len(target_symbols)} ä¸ª")
        else:
            target_symbols = list(SYMBOL_MAPPING.items())
            print(f"ğŸ¯ å…¨å“ç§æ›´æ–°: {len(target_symbols)} ä¸ª")
        
        # æ‰§è¡Œæ›´æ–°
        processed_count = 0
        
        for i, (symbol, series_cn) in enumerate(target_symbols):
            print(f"\n[{i+1}/{len(target_symbols)}] å¤„ç†å“ç§: {symbol} ({series_cn})")
            
            # è·å–å“ç§æ•°æ®
            new_data = self.fetch_variety_data(symbol, series_cn, target_date)
            
            if new_data is None or new_data.empty:
                print(f"  âŒ è·³è¿‡ {symbol}: æ•°æ®è·å–å¤±è´¥")
                self.update_stats["failed_varieties"].append(symbol)
                continue
            
            # ä¿å­˜æ•°æ®
            existing_info = variety_info.get(symbol)
            if self.save_variety_data(symbol, new_data, existing_info):
                processed_count += 1
            
            # æ·»åŠ éšæœºå»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            if i < len(target_symbols) - 1:
                delay = random.uniform(0.5, 1.5)
                time.sleep(delay)
        
        # å®Œæˆç»Ÿè®¡
        self.update_stats["end_time"] = datetime.now()
        
        print(f"\nğŸ“Š æ›´æ–°å®Œæˆç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸæ›´æ–°å“ç§: {len(self.update_stats['updated_varieties'])} ä¸ª")
        print(f"  ğŸ†• æ–°å¢å“ç§: {len(self.update_stats['new_varieties'])} ä¸ª")
        print(f"  âŒ å¤±è´¥å“ç§: {len(self.update_stats['failed_varieties'])} ä¸ª")
        print(f"  â­ï¸ è·³è¿‡å“ç§: {len(self.update_stats['skipped_varieties'])} ä¸ª")
        print(f"  ğŸ“ˆ æ–°å¢è®°å½•æ€»æ•°: {self.update_stats['total_new_records']} æ¡")
        print(f"  â±ï¸ è€—æ—¶: {(self.update_stats['end_time'] - self.update_stats['start_time']).total_seconds():.1f} ç§’")
        
        if self.update_stats["failed_varieties"]:
            print(f"  âš ï¸ å¤±è´¥å“ç§åˆ—è¡¨: {', '.join(self.update_stats['failed_varieties'])}")
        
        return self.update_stats

def main():
    """æµ‹è¯•ä¸»å‡½æ•°"""
    updater = InventoryDataUpdater()
    
    # è·å–ç°æœ‰æ•°æ®çŠ¶æ€
    varieties, info = updater.get_existing_data_status()
    
    # æ¨¡æ‹Ÿæ›´æ–°å‰3ä¸ªå“ç§åˆ°ä»Šå¤©
    target_date = datetime.now().strftime('%Y-%m-%d')
    test_varieties = ['RB', 'CU', 'AL'] if varieties else None
    
    result = updater.update_to_date(target_date, test_varieties)
    
    print(f"\nğŸ¯ æ›´æ–°ç»“æœ: {result}")

if __name__ == "__main__":
    main()
