#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Streamlitæ”¹è¿›ç‰ˆæŒä»“åˆ†æé€‚é…å™¨
å°†ç‹¬ç«‹æŒä»“åˆ†æç³»ç»Ÿ_Jupyterç‰ˆ.pyé›†æˆåˆ°Streamlitç³»ç»Ÿä¸­
æ”¯æŒå››ä¸ªå®Œæ•´ç­–ç•¥ï¼šèœ˜è››ç½‘ã€èªæ˜é’±ã€å®¶äººå¸­ä½åå‘æ“ä½œã€æŒä»“é›†ä¸­åº¦
"""

import asyncio
import sys
from pathlib import Path
from typing import Dict, Any, Optional
import json
import concurrent.futures
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
try:
    project_root = Path(__file__).parent
except NameError:
    project_root = Path.cwd()

if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# å¯¼å…¥æ”¹è¿›ç‰ˆæŒä»“åˆ†æç³»ç»Ÿ
try:
    from ç‹¬ç«‹æŒä»“åˆ†æç³»ç»Ÿ_Jupyterç‰ˆ import JupyterPositioningAnalyzer, SYMBOL_NAMES
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    # å¤‡ç”¨å¯¼å…¥
    class JupyterPositioningAnalyzer:
        def __init__(self):
            pass
        def analyze_symbol_sync(self, symbol, use_reasoner=False, days_back=14):
            return {"success": False, "error": "å¯¼å…¥å¤±è´¥"}
    SYMBOL_NAMES = {}

class StreamlitImprovedPositioningAdapter:
    """Streamlitæ”¹è¿›ç‰ˆæŒä»“åˆ†æé€‚é…å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é€‚é…å™¨"""
        try:
            self.analyzer = JupyterPositioningAnalyzer()
            self.initialized = True
            print("âœ… æ”¹è¿›ç‰ˆæŒä»“åˆ†æé€‚é…å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ é€‚é…å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.analyzer = None
            self.initialized = False
    
    def analyze_positioning_for_streamlit(self, symbol: str, analysis_date: str = None, 
                                        use_reasoner: bool = False, days_back: int = 14) -> Dict[str, Any]:
        """
        ä¸ºStreamlitç³»ç»Ÿæä¾›æ”¹è¿›ç‰ˆæŒä»“åˆ†æ
        
        Args:
            symbol: å“ç§ä»£ç 
            analysis_date: åˆ†ææ—¥æœŸï¼ˆæš‚æ—¶ä¸ä½¿ç”¨ï¼Œç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æœ€æ–°æ•°æ®ï¼‰
            use_reasoner: æ˜¯å¦ä½¿ç”¨reasoneræ¨¡å‹
            days_back: åˆ†æå¤©æ•°
            
        Returns:
            Dict: åˆ†æç»“æœï¼Œå…¼å®¹Streamlitæ˜¾ç¤ºæ ¼å¼
        """
        if not self.initialized or self.analyzer is None:
            return {
                "success": False,
                "error": "æŒä»“åˆ†æç³»ç»Ÿæœªæ­£ç¡®åˆå§‹åŒ–",
                "symbol": symbol,
                "symbol_name": SYMBOL_NAMES.get(symbol.upper(), symbol)
            }
        
        try:
            print(f"ğŸ” å¼€å§‹åˆ†æ {symbol}...")
            
            # ä½¿ç”¨åŒæ­¥æ–¹æ³•è¿›è¡Œåˆ†æï¼ˆé¿å…Streamlitä¸­çš„asyncioå†²çªï¼‰
            result = self.analyzer.analyze_symbol_sync(
                symbol=symbol.upper(),
                use_reasoner=use_reasoner,
                days_back=days_back
            )
            
            if result.get("success"):
                print(f"âœ… {symbol} åˆ†ææˆåŠŸ")
                return self._format_for_streamlit(result)
            else:
                print(f"âŒ {symbol} åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return {
                    "success": False,
                    "error": result.get("error", "åˆ†æå¤±è´¥"),
                    "symbol": symbol,
                    "symbol_name": SYMBOL_NAMES.get(symbol.upper(), symbol)
                }
                
        except Exception as e:
            print(f"âŒ æŒä»“åˆ†æå¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": f"æŒä»“åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                "symbol": symbol,
                "symbol_name": SYMBOL_NAMES.get(symbol.upper(), symbol)
            }
    
    def _format_for_streamlit(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–ç»“æœä»¥é€‚é…Streamlitæ˜¾ç¤º"""
        
        # åŸºç¡€ä¿¡æ¯
        formatted_result = {
            "success": True,
            "symbol": result.get("symbol", ""),
            "symbol_name": result.get("symbol_name", ""),
            "analysis_date": result.get("analysis_date", ""),
            "model_used": result.get("model_used", ""),
            "data_points": result.get("data_points", 0),
            "data_quality_score": result.get("data_quality_score", 0.0)
        }
        
        # AIåˆ†æç»“æœ
        if "ai_analysis" in result:
            formatted_result["ai_analysis"] = result["ai_analysis"]
        
        # å››ä¸ªç­–ç•¥çš„è¯¦ç»†æ•°æ®
        supporting_data = {}
        
        # 1. èœ˜è››ç½‘ç­–ç•¥æ•°æ®
        if "spider_web_data" in result:
            spider_data = result["spider_web_data"]
            supporting_data["spider_web_analysis"] = {
                "strategy_name": "èœ˜è››ç½‘ç­–ç•¥",
                "dB": spider_data.get("dB", 0),
                "dS": spider_data.get("dS", 0),
                "signal_strength": spider_data.get("signal_strength", 0),
                "long_total": spider_data.get("long_total_latest", 0),
                "short_total": spider_data.get("short_total_latest", 0),
                "description": "åŸºäºå‰20åå¤šç©ºæŒä»“å˜åŒ–åˆ†æèªæ˜èµ„é‡‘æµå‘"
            }
        
        # 2. èªæ˜é’±åˆ†ææ•°æ®
        if "smart_money_data" in result:
            smart_data = result["smart_money_data"]
            supporting_data["smart_money_analysis"] = {
                "strategy_name": "èªæ˜é’±åˆ†æ",
                "oi_volume_ratio": smart_data.get("oi_volume_ratio", 0),
                "position_efficiency": smart_data.get("position_efficiency", 0),
                "smart_money_score": smart_data.get("smart_money_score", 0),
                "normalized_score": smart_data.get("normalized_score", 0),
                "description": "é€šè¿‡æŒä»“æˆäº¤æ¯”å’ŒæŒä»“æ•ˆç‡è¯†åˆ«çŸ¥æƒ…èµ„é‡‘"
            }
        
        # 3. å®¶äººå¸­ä½åå‘æ“ä½œç­–ç•¥æ•°æ®
        if "seat_behavior_data" in result:
            seat_data = result["seat_behavior_data"]
            supporting_data["retail_reverse_analysis"] = {
                "strategy_name": "å®¶äººå¸­ä½åå‘æ“ä½œç­–ç•¥",
                "retail_long_change": seat_data.get("retail_long_change", 0),
                "retail_short_change": seat_data.get("retail_short_change", 0),
                "retail_long_position": seat_data.get("retail_long_position", 0),
                "retail_short_position": seat_data.get("retail_short_position", 0),
                "retail_long_ratio": seat_data.get("retail_long_ratio", 0),
                "retail_short_ratio": seat_data.get("retail_short_ratio", 0),
                "reverse_signal": seat_data.get("reverse_signal", "æœªçŸ¥"),
                "reverse_direction": seat_data.get("reverse_direction", "ä¸­æ€§"),
                "signal_strength": seat_data.get("signal_strength", 0),
                "retail_seats_found": seat_data.get("retail_seats_found", 0),
                "retail_seat_details": seat_data.get("retail_seat_details", []),
                "description": "åˆ†æå®¶äººå¸­ä½ï¼ˆä¸œè´¢ã€å¾½å•†ã€å¹³å®‰ï¼‰è¡Œä¸ºï¼Œæä¾›åå‘æ“ä½œå»ºè®®"
            }
        
        # 4. æŒä»“é›†ä¸­åº¦åˆ†ææ•°æ®
        if "concentration_data" in result:
            conc_data = result["concentration_data"]
            supporting_data["concentration_analysis"] = {
                "strategy_name": "æŒä»“é›†ä¸­åº¦åˆ†æ",
                "long_concentration_hhi": conc_data.get("long_concentration_hhi", 0),
                "short_concentration_hhi": conc_data.get("short_concentration_hhi", 0),
                "top5_long_ratio": conc_data.get("top5_long_ratio", 0),
                "top5_short_ratio": conc_data.get("top5_short_ratio", 0),
                "top10_long_ratio": conc_data.get("top10_long_ratio", 0),
                "top10_short_ratio": conc_data.get("top10_short_ratio", 0),
                "concentration_risk": conc_data.get("concentration_risk", "æœªçŸ¥"),
                "control_assessment": conc_data.get("control_assessment", "æœªçŸ¥"),
                "avg_concentration": conc_data.get("avg_concentration", 0),
                "description": "ä½¿ç”¨HHIæŒ‡æ•°è¯„ä¼°å¤§æˆ·æ§ç›˜ç¨‹åº¦å’Œå¸‚åœºæ“çºµé£é™©"
            }
        
        # 5. æŒä»“ç»Ÿè®¡æ•°æ®
        if "position_data" in result:
            pos_data = result["position_data"]
            supporting_data["position_statistics"] = {
                "long_top20_total": pos_data.get("long_top20_total", 0),
                "short_top20_total": pos_data.get("short_top20_total", 0),
                "net_position": pos_data.get("net_position", 0),
                "long_short_ratio": pos_data.get("long_short_ratio", 0)
            }
        
        formatted_result["supporting_data"] = supporting_data
        
        # å¸‚åœºæƒ…æŠ¥
        if "market_intelligence" in result:
            formatted_result["citations"] = [
                {
                    "index": i+1,
                    "title": item.get("title", ""),
                    "source": item.get("source", ""),
                    "snippet": item.get("snippet", "")
                }
                for i, item in enumerate(result["market_intelligence"])
            ]
        
        # åŸå§‹æ•°æ®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        if "raw_data" in result:
            formatted_result["raw_analysis_data"] = result["raw_data"]
        
        # ç”Ÿæˆç»“æ„åŒ–åˆ†ææ‘˜è¦
        formatted_result["structured_analysis"] = self._generate_structured_summary(supporting_data)
        
        return formatted_result
    
    def _generate_structured_summary(self, supporting_data: Dict) -> Dict:
        """ç”Ÿæˆç»“æ„åŒ–åˆ†ææ‘˜è¦"""
        summary = {}
        
        # èœ˜è››ç½‘ç­–ç•¥æ‘˜è¦
        if "spider_web_analysis" in supporting_data:
            spider = supporting_data["spider_web_analysis"]
            dB = spider.get("dB", 0)
            dS = spider.get("dS", 0)
            
            if dB > 0 and dS < 0:
                spider_signal = "çœ‹å¤š"
            elif dB < 0 and dS > 0:
                spider_signal = "çœ‹ç©º"
            else:
                spider_signal = "ä¸­æ€§"
            
            summary["spider_web_summary"] = {
                "signal": spider_signal,
                "strength": abs(dB) + abs(dS),
                "confidence": min(abs(dB + dS) / 10000, 1.0)
            }
        
        # èªæ˜é’±åˆ†ææ‘˜è¦
        if "smart_money_analysis" in supporting_data:
            smart = supporting_data["smart_money_analysis"]
            score = smart.get("normalized_score", 0)
            
            if score > 70:
                smart_signal = "å¼ºçƒˆçœ‹å¥½"
            elif score > 50:
                smart_signal = "æ¸©å’Œçœ‹å¥½"
            else:
                smart_signal = "ä¸­æ€§"
            
            summary["smart_money_summary"] = {
                "signal": smart_signal,
                "score": score,
                "confidence": score / 100.0
            }
        
        # å®¶äººå¸­ä½åå‘æ“ä½œæ‘˜è¦
        if "retail_reverse_analysis" in supporting_data:
            retail = supporting_data["retail_reverse_analysis"]
            direction = retail.get("reverse_direction", "ä¸­æ€§")
            strength = retail.get("signal_strength", 0)
            
            summary["retail_reverse_summary"] = {
                "signal": direction,
                "strength": strength,
                "confidence": min(strength / 5000, 1.0),
                "seats_found": retail.get("retail_seats_found", 0)
            }
        
        # æŒä»“é›†ä¸­åº¦æ‘˜è¦
        if "concentration_analysis" in supporting_data:
            conc = supporting_data["concentration_analysis"]
            risk = conc.get("concentration_risk", "æœªçŸ¥")
            control = conc.get("control_assessment", "æœªçŸ¥")
            
            summary["concentration_summary"] = {
                "risk_level": risk,
                "control_level": control,
                "avg_hhi": conc.get("avg_concentration", 0)
            }
        
        return summary

# åˆ›å»ºå…¨å±€é€‚é…å™¨å®ä¾‹
_improved_adapter = None

def get_improved_positioning_adapter():
    """è·å–æ”¹è¿›ç‰ˆæŒä»“åˆ†æé€‚é…å™¨å®ä¾‹"""
    global _improved_adapter
    if _improved_adapter is None:
        _improved_adapter = StreamlitImprovedPositioningAdapter()
    return _improved_adapter

def analyze_improved_positioning_for_streamlit(symbol: str, analysis_date: str = None, 
                                             use_reasoner: bool = False, days_back: int = 14) -> Dict[str, Any]:
    """
    Streamlitç³»ç»Ÿè°ƒç”¨çš„æ”¹è¿›ç‰ˆæŒä»“åˆ†ææ¥å£
    
    Args:
        symbol: å“ç§ä»£ç 
        analysis_date: åˆ†ææ—¥æœŸ
        use_reasoner: æ˜¯å¦ä½¿ç”¨reasoneræ¨¡å‹
        days_back: åˆ†æå¤©æ•°
        
    Returns:
        Dict: æ ¼å¼åŒ–çš„åˆ†æç»“æœ
    """
    adapter = get_improved_positioning_adapter()
    return adapter.analyze_positioning_for_streamlit(symbol, analysis_date, use_reasoner, days_back)

# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•Streamlitæ”¹è¿›ç‰ˆæŒä»“åˆ†æé€‚é…å™¨")
    print("=" * 60)
    
    # æµ‹è¯•åˆ†æ
    test_symbol = "RB"
    print(f"ğŸ“Š æµ‹è¯•åˆ†æå“ç§: {test_symbol}")
    
    result = analyze_improved_positioning_for_streamlit(test_symbol, use_reasoner=False, days_back=14)
    
    if result.get("success"):
        print("âœ… æµ‹è¯•æˆåŠŸ!")
        print(f"ğŸ“ˆ å“ç§: {result['symbol_name']}({result['symbol']})")
        print(f"ğŸ“… åˆ†ææ—¥æœŸ: {result['analysis_date']}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {result['model_used']}")
        print(f"ğŸ“Š æ•°æ®ç‚¹æ•°: {result['data_points']}")
        print(f"ğŸ¯ æ•°æ®è´¨é‡: {result['data_quality_score']:.1%}")
        
        # æ£€æŸ¥å››ä¸ªç­–ç•¥æ•°æ®
        supporting_data = result.get("supporting_data", {})
        print(f"\nğŸ“Š å››ä¸ªç­–ç•¥æ•°æ®æ£€æŸ¥:")
        
        strategies = [
            ("spider_web_analysis", "ğŸ•¸ï¸ èœ˜è››ç½‘ç­–ç•¥"),
            ("smart_money_analysis", "ğŸ§  èªæ˜é’±åˆ†æ"),
            ("retail_reverse_analysis", "ğŸ›ï¸ å®¶äººå¸­ä½åå‘æ“ä½œ"),
            ("concentration_analysis", "ğŸ“Š æŒä»“é›†ä¸­åº¦åˆ†æ")
        ]
        
        for key, name in strategies:
            if key in supporting_data:
                print(f"âœ… {name}: æ•°æ®å®Œæ•´")
                if key == "retail_reverse_analysis":
                    retail_data = supporting_data[key]
                    print(f"   åå‘ä¿¡å·: {retail_data.get('reverse_direction', 'æœªçŸ¥')}")
                    print(f"   å‘ç°å¸­ä½: {retail_data.get('retail_seats_found', 0)}ä¸ª")
            else:
                print(f"âŒ {name}: æ•°æ®ç¼ºå¤±")
        
        if "ai_analysis" in result:
            ai_length = len(result['ai_analysis'])
            print(f"\nğŸ¤– AIåˆ†æ: {ai_length} å­—ç¬¦")
            if ai_length > 0:
                print("âœ… AIåˆ†æåŒ…å«å…·ä½“å¸­ä½æ•°æ®")
        
        if "citations" in result:
            print(f"ğŸ”— å¤–éƒ¨å¼•ç”¨: {len(result['citations'])} æ¡")
            
    else:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")
