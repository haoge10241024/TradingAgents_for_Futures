#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
StreamlitåŸºå·®åˆ†æé€‚é…å™¨
å°†ä¸“ä¸šAIåŸºå·®åˆ†æç³»ç»Ÿé›†æˆåˆ°Streamlitç³»ç»Ÿä¸­
"""

import asyncio
from datetime import datetime
from typing import Dict, Any, Optional
from ä¸“ä¸šAIåŸºå·®åˆ†æç³»ç»Ÿ_å››ç»´åº¦æ¡†æ¶ import ProfessionalBasisAnalysisSystem

class StreamlitBasisAnalysisAdapter:
    """StreamlitåŸºå·®åˆ†æé€‚é…å™¨"""
    
    def __init__(self):
        self.basis_system = ProfessionalBasisAnalysisSystem()
    
    async def analyze_variety_for_streamlit(self, variety: str, analysis_date: str = None, 
                                          use_reasoner: bool = False) -> Dict[str, Any]:
        """
        ä¸ºStreamlitç³»ç»Ÿæä¾›åŸºå·®åˆ†æ
        
        Args:
            variety: å“ç§ä»£ç 
            analysis_date: åˆ†ææ—¥æœŸ
            use_reasoner: æ˜¯å¦ä½¿ç”¨æ·±åº¦æ¨ç†æ¨¡å¼
            
        Returns:
            ç¬¦åˆStreamlitç³»ç»Ÿæ ¼å¼çš„åˆ†æç»“æœ
        """
        
        try:
            # è°ƒç”¨ä¸“ä¸šåŸºå·®åˆ†æç³»ç»Ÿ
            result = self.basis_system.analyze_variety_comprehensive(
                variety=variety, 
                analysis_date=analysis_date, 
                use_reasoner=use_reasoner
            )
            
            if "error" in result:
                return {
                    "success": False,
                    "error": result["error"],
                    "analysis_mode": "basis_analysis",
                    "timestamp": datetime.now().isoformat()
                }
            
            # è½¬æ¢ä¸ºStreamlitç³»ç»Ÿå…¼å®¹çš„æ ¼å¼
            streamlit_result = self._convert_to_streamlit_format(result)
            
            return streamlit_result
            
        except Exception as e:
            return {
                "success": False,
                "error": f"åŸºå·®åˆ†æå¤±è´¥: {str(e)}",
                "analysis_mode": "basis_analysis",
                "timestamp": datetime.now().isoformat()
            }
    
    def _convert_to_streamlit_format(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """å°†ä¸“ä¸šåŸºå·®åˆ†æç»“æœè½¬æ¢ä¸ºStreamlitç³»ç»Ÿæ ¼å¼"""
        
        # æå–å…³é”®ä¿¡æ¯
        variety = result.get("variety", "")
        variety_name = result.get("variety_name", "")
        analysis_date = result.get("analysis_date", "")
        ai_analysis = result.get("ai_comprehensive_analysis", "")
        
        # æå–æ ¸å¿ƒæŒ‡æ ‡
        continuous_analysis = result.get("continuous_basis_analysis", {})
        seasonal_analysis = result.get("seasonal_analysis", {})
        inventory_analysis = result.get("inventory_basis_analysis", {})
        
        # æ„å»ºStreamlitå…¼å®¹çš„ç»“æœæ ¼å¼
        streamlit_result = {
            "success": True,
            "analysis_mode": "professional_four_dimension_basis",
            "analysis_version": "v2.0_professional",
            "model_used": result.get("analysis_mode", "deepseek-chat"),
            "search_enhanced": True,
            "timestamp": result.get("timestamp", datetime.now().isoformat()),
            
            # åŸºæœ¬ä¿¡æ¯
            "variety": variety,
            "variety_name": variety_name,
            "chinese_name": variety_name,
            "analysis_date": analysis_date,
            
            # AIåˆ†æå†…å®¹
            "ai_analysis": ai_analysis,
            
            # æ•°æ®è´¨é‡ä¿¡æ¯
            "data_quality": result.get("data_quality", {}),
            
            # æ ¸å¿ƒæŒ‡æ ‡æ‘˜è¦
            "metrics": {
                "continuous_basis": continuous_analysis.get("current_continuous_basis"),
                "main_basis": continuous_analysis.get("current_main_basis"),
                "seasonal_deviation": seasonal_analysis.get("seasonal_deviation"),
                "inventory_level": inventory_analysis.get("inventory_level"),
                "region_classification": inventory_analysis.get("region_classification"),
                "data_quality_level": self._assess_overall_data_quality(result.get("data_quality", {}))
            },
            
            # å››ç»´åº¦åˆ†æç»“æœ
            "four_dimension_analysis": {
                "continuous_basis": continuous_analysis,
                "seasonal_analysis": seasonal_analysis,
                "inventory_analysis": inventory_analysis,
                "spatial_analysis": result.get("spatial_analysis", {}),
                "quality_analysis": result.get("quality_analysis", {})
            },

            # ä¸“ä¸šå›¾è¡¨ - è½¬æ¢ä¸ºä¸»ç•Œé¢æœŸæœ›çš„æ ¼å¼
            "charts_html": None,  # å ä½ç¬¦ï¼Œåç»­å¤„ç†
            "professional_charts": result.get("professional_charts", {}),  # ä¿ç•™åŸå§‹å­—æ®µä»¥é˜²éœ€è¦

            # å¤–éƒ¨å¼•ç”¨
            "external_citations": result.get("external_citations", []),
            "reference_count": len(result.get("external_citations", [])),

            # å¸‚åœºèƒŒæ™¯
            "market_context": result.get("market_context", {}),

            # ç½®ä¿¡åº¦è¯„ä¼°
            "confidence_score": self._calculate_confidence_score(result)
        }

        # åœ¨å­—å…¸å¤–éƒ¨å¤„ç†å›¾è¡¨è½¬æ¢
        formatted_result = streamlit_result
        charts_dict = result.get("professional_charts", {})

        # æ­£ç¡®å¤„ç†å›¾è¡¨å¯¹è±¡æ ¼å¼
        if charts_dict:
            if len(charts_dict) == 1:
                # å•ä¸ªå›¾è¡¨ï¼Œç›´æ¥ä½¿ç”¨å›¾è¡¨å¯¹è±¡
                chart_key = list(charts_dict.keys())[0]
                formatted_result["charts_html"] = charts_dict[chart_key]
                print(f"âœ… åŸºå·®åˆ†æå›¾è¡¨å·²è½¬æ¢: å•ä¸ªå›¾è¡¨ '{chart_key}'")
            else:
                # å¤šä¸ªå›¾è¡¨ï¼Œä¿æŒå­—å…¸æ ¼å¼
                formatted_result["charts_html"] = charts_dict
                print(f"âœ… åŸºå·®åˆ†æå›¾è¡¨å·²è½¬æ¢: {len(charts_dict)}ä¸ªå›¾è¡¨")
        else:
            formatted_result["charts_html"] = None

        return streamlit_result
    
    def _assess_overall_data_quality(self, data_quality: Dict[str, str]) -> str:
        """è¯„ä¼°æ•´ä½“æ•°æ®è´¨é‡"""
        if not data_quality:
            return "æœªçŸ¥"
        
        available_count = sum(1 for status in data_quality.values() if status == "å¯ç”¨")
        total_count = len(data_quality)
        
        if total_count == 0:
            return "æœªçŸ¥"
        
        quality_ratio = available_count / total_count
        
        if quality_ratio >= 0.8:
            return "ä¼˜ç§€"
        elif quality_ratio >= 0.6:
            return "è‰¯å¥½"
        elif quality_ratio >= 0.4:
            return "ä¸€èˆ¬"
        else:
            return "è¾ƒå·®"
    
    def _calculate_confidence_score(self, result: Dict[str, Any]) -> float:
        """è®¡ç®—åˆ†æç½®ä¿¡åº¦"""
        try:
            # åŸºäºæ•°æ®è´¨é‡å’Œåˆ†æå®Œæ•´æ€§è®¡ç®—ç½®ä¿¡åº¦
            data_quality = result.get("data_quality", {})
            available_count = sum(1 for status in data_quality.values() if status == "å¯ç”¨")
            total_count = len(data_quality) if data_quality else 1
            
            data_quality_score = available_count / total_count
            
            # åŸºäºAIåˆ†æé•¿åº¦è¯„ä¼°
            ai_analysis = result.get("ai_comprehensive_analysis", "")
            analysis_length_score = min(len(ai_analysis) / 3000, 1.0) if ai_analysis else 0.5
            
            # åŸºäºå¤–éƒ¨å¼•ç”¨æ•°é‡è¯„ä¼°
            citations_count = len(result.get("external_citations", []))
            citation_score = min(citations_count / 10, 1.0)
            
            # ç»¼åˆè¯„åˆ†
            confidence = (data_quality_score * 0.4 + 
                         analysis_length_score * 0.4 + 
                         citation_score * 0.2)
            
            return round(confidence, 2)
            
        except Exception:
            return 0.75  # é»˜è®¤ç½®ä¿¡åº¦

# å¼‚æ­¥åŒ…è£…å‡½æ•°ï¼Œä¾›Streamlitç³»ç»Ÿè°ƒç”¨
async def analyze_basis_for_streamlit(variety: str, analysis_date: str = None, 
                                    use_reasoner: bool = False) -> Dict[str, Any]:
    """
    å¼‚æ­¥åŸºå·®åˆ†æå‡½æ•°ï¼Œä¾›Streamlitç³»ç»Ÿè°ƒç”¨
    
    Args:
        variety: å“ç§ä»£ç 
        analysis_date: åˆ†ææ—¥æœŸ
        use_reasoner: æ˜¯å¦ä½¿ç”¨æ·±åº¦æ¨ç†æ¨¡å¼
        
    Returns:
        Streamlitç³»ç»Ÿå…¼å®¹çš„åˆ†æç»“æœ
    """
    adapter = StreamlitBasisAnalysisAdapter()
    return await adapter.analyze_variety_for_streamlit(variety, analysis_date, use_reasoner)

# åŒæ­¥ç‰ˆæœ¬ï¼ˆå¦‚æœéœ€è¦ï¼‰
def analyze_basis_for_streamlit_sync(variety: str, analysis_date: str = None, 
                                   use_reasoner: bool = False) -> Dict[str, Any]:
    """
    åŒæ­¥åŸºå·®åˆ†æå‡½æ•°
    """
    adapter = StreamlitBasisAnalysisAdapter()
    # åœ¨åŒæ­¥ç¯å¢ƒä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
    return asyncio.run(adapter.analyze_variety_for_streamlit(variety, analysis_date, use_reasoner))

if __name__ == "__main__":
    # æµ‹è¯•é€‚é…å™¨
    print("ğŸ§ª æµ‹è¯•StreamlitåŸºå·®åˆ†æé€‚é…å™¨...")
    
    # æµ‹è¯•åŒæ­¥ç‰ˆæœ¬
    result = analyze_basis_for_streamlit_sync("JD", use_reasoner=False)
    
    if result.get("success"):
        print("âœ… é€‚é…å™¨æµ‹è¯•æˆåŠŸ")
        print(f"ğŸ“Š å“ç§: {result.get('variety_name')}")
        print(f"ğŸ¯ ç½®ä¿¡åº¦: {result.get('confidence_score')}")
        print(f"ğŸ“ˆ æ•°æ®è´¨é‡: {result.get('metrics', {}).get('data_quality_level')}")
    else:
        print(f"âŒ é€‚é…å™¨æµ‹è¯•å¤±è´¥: {result.get('error')}")
